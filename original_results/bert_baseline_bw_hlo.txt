HloModule cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_120__XlaNumResourceArgs_146_.3712

%max_half_.415 (x.416: f16[], y.417: f16[]) -> f16[] {
  %x.416 = f16[] parameter(0)
  %y.417 = f16[] parameter(1)
  ROOT %maximum.418 = f16[] maximum(f16[] %x.416, f16[] %y.417)
}

%add_float_.425 (x.426: f32[], y.427: f32[]) -> f32[] {
  %x.426 = f32[] parameter(0)
  %y.427 = f32[] parameter(1)
  ROOT %add.428 = f32[] add(f32[] %x.426, f32[] %y.427)
}

%max_half_.591 (x.592: f16[], y.593: f16[]) -> f16[] {
  %x.592 = f16[] parameter(0)
  %y.593 = f16[] parameter(1)
  ROOT %maximum.594 = f16[] maximum(f16[] %x.592, f16[] %y.593)
}

%add_float_.601 (x.602: f32[], y.603: f32[]) -> f32[] {
  %x.602 = f32[] parameter(0)
  %y.603 = f32[] parameter(1)
  ROOT %add.604 = f32[] add(f32[] %x.602, f32[] %y.603)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_softmax_Sum-reduction.1354 (x.1355: f32[], y.1356: f32[]) -> f32[] {
  %x.1355 = f32[] parameter(0)
  %y.1356 = f32[] parameter(1)
  ROOT %add.1357 = f32[] add(f32[] %x.1355, f32[] %y.1356)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_softmax_Sum-reduction.1612 (x.1613: f32[], y.1614: f32[]) -> f32[] {
  %x.1613 = f32[] parameter(0)
  %y.1614 = f32[] parameter(1)
  ROOT %add.1615 = f32[] add(f32[] %x.1613, f32[] %y.1614)
}

%Mean-reduction.1950 (x.1951: f32[], y.1952: f32[]) -> f32[] {
  %x.1951 = f32[] parameter(0)
  %y.1952 = f32[] parameter(1)
  ROOT %add.1953 = f32[] add(f32[] %x.1951, f32[] %y.1952)
}

%fused_computation (param_0: f32[], param_1.1656: f32[], param_2.1726: f32[], param_3.1122: f32[], param_4.703: f32[], param_5.452: f32[], param_6.798: f32[], param_7.834: f32[]) -> (f32[], f32[], f32[], f32[]) {
  %param_0 = f32[] parameter(0)
  %param_1.1656 = f32[] parameter(1)
  %constant_71 = f32[] constant(0.0625)
  %multiply.519 = f32[] multiply(f32[] %param_1.1656, f32[] %constant_71), metadata={op_type="Mean" op_name="model/bert_pretrain_loss_and_metric_layer/Mean"}
  %param_3.1122 = f32[] parameter(3)
  %constant_72 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %compare.116 = pred[] compare(f32[] %param_3.1122, f32[] %constant_72), direction=EQ, metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %param_2.1726 = f32[] parameter(2)
  %divide.77 = f32[] divide(f32[] %param_2.1726, f32[] %param_3.1122), metadata={op_type="DivNoNan" op_name="model/bert_pretrain_loss_and_metric_layer/div_no_nan"}
  %select.114 = f32[] select(pred[] %compare.116, f32[] %constant_72, f32[] %divide.77), metadata={op_type="DivNoNan" op_name="model/bert_pretrain_loss_and_metric_layer/div_no_nan"}
  %add.8 = f32[] add(f32[] %multiply.519, f32[] %select.114), metadata={op_type="AddV2" op_name="model/bert_pretrain_loss_and_metric_layer/add"}
  %broadcast.192 = f32[16]{0} broadcast(f32[] %add.8), dimensions={}
  %reduce.41 = f32[] reduce(f32[16]{0} %broadcast.192, f32[] %constant_72), dimensions={0}, to_apply=%Mean-reduction.1950, metadata={op_type="Mean" op_name="Mean"}
  %multiply.93 = f32[] multiply(f32[] %reduce.41, f32[] %constant_71), metadata={op_type="Mean" op_name="Mean"}
  %add.7 = f32[] add(f32[] %param_0, f32[] %multiply.93), metadata={op_type="AssignAddVariableOp" op_name="AssignAddVariableOp"}
  %param_4.703 = f32[] parameter(4)
  %add.600.clone.1 = f32[] add(f32[] %param_4.703, f32[] %select.114), metadata={op_type="AssignAddVariableOp" op_name="model/bert_pretrain_loss_and_metric_layer/AssignAddVariableOp_2"}
  %param_5.452 = f32[] parameter(5)
  %add.228.clone.1 = f32[] add(f32[] %param_5.452, f32[] %multiply.519), metadata={op_type="AssignAddVariableOp" op_name="model/bert_pretrain_loss_and_metric_layer/AssignAddVariableOp_6"}
  %param_6.798 = f32[] parameter(6)
  %param_7.834 = f32[] parameter(7)
  %constant_64_clone_1 = f32[] constant(1e-05), metadata={op_type="AddV2" op_name="model/bert_pretrain_loss_and_metric_layer/add_1"}
  %add.10.clone.1 = f32[] add(f32[] %param_3.1122, f32[] %constant_64_clone_1), metadata={op_type="AddV2" op_name="model/bert_pretrain_loss_and_metric_layer/add_1"}
  %divide.0.clone.1 = f32[] divide(f32[] %param_7.834, f32[] %add.10.clone.1), metadata={op_type="RealDiv" op_name="model/bert_pretrain_loss_and_metric_layer/truediv"}
  %add.9.clone.1 = f32[] add(f32[] %param_6.798, f32[] %divide.0.clone.1), metadata={op_type="AssignAddVariableOp" op_name="model/bert_pretrain_loss_and_metric_layer/AssignAddVariableOp"}
  ROOT %tuple.142 = (f32[], f32[], f32[], f32[]) tuple(f32[] %add.7, f32[] %add.600.clone.1, f32[] %add.228.clone.1, f32[] %add.9.clone.1)
}

%model_bert_pretrain_loss_and_metric_layer_Sum_2-reduction.1986 (x.1987: f32[], y.1988: f32[]) -> f32[] {
  %x.1987 = f32[] parameter(0)
  %y.1988 = f32[] parameter(1)
  ROOT %add.1989 = f32[] add(f32[] %x.1987, f32[] %y.1988)
}

%model_bert_pretrain_loss_and_metric_layer_Sum_3-reduction.195 (x.196: f32[], y.197: f32[]) -> f32[] {
  %x.196 = f32[] parameter(0)
  %y.197 = f32[] parameter(1)
  ROOT %add.198 = f32[] add(f32[] %x.196, f32[] %y.197)
}

%model_bert_pretrain_loss_and_metric_layer_Sum-reduction.1932 (x.1933: f32[], y.1934: f32[]) -> f32[] {
  %x.1933 = f32[] parameter(0)
  %y.1934 = f32[] parameter(1)
  ROOT %add.1935 = f32[] add(f32[] %x.1933, f32[] %y.1934)
}

%fused_computation.2 (param_0.1071: s32[16,76], param_1.1477: s64[16,76], param_2.1394: f32[16,76], param_3.1279: f32[1216]) -> (f32[], f32[], f32[]) {
  %param_0.1071 = s32[16,76]{1,0} parameter(0)
  %param_1.1477 = s64[16,76]{1,0} parameter(1)
  %convert.25 = s32[16,76]{1,0} convert(s64[16,76]{1,0} %param_1.1477), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_7"}
  %compare.0 = pred[16,76]{1,0} compare(s32[16,76]{1,0} %param_0.1071, s32[16,76]{1,0} %convert.25), direction=EQ, metadata={op_type="Equal" op_name="model/bert_pretrain_loss_and_metric_layer/Equal"}
  %param_2.1394 = f32[16,76]{1,0} parameter(2)
  %convert.461 = s32[16,76]{1,0} convert(f32[16,76]{1,0} %param_2.1394), metadata={op_type="Cast" op_name="model/Cast"}
  %convert.460 = f32[16,76]{1,0} convert(s32[16,76]{1,0} %convert.461), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast"}
  %constant_73 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %broadcast.193 = f32[16,76]{1,0} broadcast(f32[] %constant_73), dimensions={}
  %select.19 = f32[16,76]{1,0} select(pred[16,76]{1,0} %compare.0, f32[16,76]{1,0} %convert.460, f32[16,76]{1,0} %broadcast.193), metadata={op_type="Mul" op_name="model/bert_pretrain_loss_and_metric_layer/mul_1"}
  %bitcast.140 = f32[1216]{0} bitcast(f32[16,76]{1,0} %select.19)
  %reduce.42 = f32[] reduce(f32[1216]{0} %bitcast.140, f32[] %constant_73), dimensions={0}, to_apply=%model_bert_pretrain_loss_and_metric_layer_Sum_2-reduction.1986, metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_2"}
  %bitcast.238.clone.1 = f32[1216]{0} bitcast(f32[16,76]{1,0} %convert.460)
  %reduce.92.clone.1 = f32[] reduce(f32[1216]{0} %bitcast.238.clone.1, f32[] %constant_73), dimensions={0}, to_apply=%model_bert_pretrain_loss_and_metric_layer_Sum_3-reduction.195, metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %param_3.1279 = f32[1216]{0} parameter(3)
  %bitcast.143.clone.1 = f32[16,76]{1,0} bitcast(f32[1216]{0} %param_3.1279), metadata={op_type="Reshape" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/Reshape_2"}
  %multiply.94.clone.1 = f32[16,76]{1,0} multiply(f32[16,76]{1,0} %convert.460, f32[16,76]{1,0} %bitcast.143.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrain_loss_and_metric_layer/mul"}
  %bitcast.142.clone.1 = f32[1216]{0} bitcast(f32[16,76]{1,0} %multiply.94.clone.1)
  %reduce.44.clone.1 = f32[] reduce(f32[1216]{0} %bitcast.142.clone.1, f32[] %constant_73), dimensions={0}, to_apply=%model_bert_pretrain_loss_and_metric_layer_Sum-reduction.1932, metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum"}
  ROOT %tuple.144 = (f32[], f32[], f32[]) tuple(f32[] %reduce.42, f32[] %reduce.92.clone.1, f32[] %reduce.44.clone.1)
}

%min_S64.1974 (lhs.1975: s64[], rhs.1976: s64[]) -> s64[] {
  %lhs.1975 = s64[] parameter(0)
  %rhs.1976 = s64[] parameter(1)
  ROOT %minimum.1977 = s64[] minimum(s64[] %lhs.1975, s64[] %rhs.1976)
}

%fused_computation.3 (param_0.1224: f32[16,76], param_1.1667: f32[30522], param_2.1734: f16[1216,30528]) -> s64[16,76] {
  %param_2.1734 = f16[1216,30528]{1,0} parameter(2)
  %slice.45 = f16[1216,30522]{1,0} slice(f16[1216,30528]{1,0} %param_2.1734), slice={[0:1216], [0:30522]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}
  %param_1.1667 = f32[30522]{0} parameter(1)
  %convert.819 = f16[30522]{0} convert(f32[30522]{0} %param_1.1667), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/BiasAdd/Cast"}
  %broadcast.2104 = f16[1216,30522]{1,0} broadcast(f16[30522]{0} %convert.819), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %add.605 = f16[1216,30522]{1,0} add(f16[1216,30522]{1,0} %slice.45, f16[1216,30522]{1,0} %broadcast.2104), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %convert.818 = f32[1216,30522]{1,0} convert(f16[1216,30522]{1,0} %add.605), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast_1"}
  %bitcast.456 = f32[16,76,30522]{2,1,0} bitcast(f32[1216,30522]{1,0} %convert.818), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_1"}
  %param_0.1224 = f32[16,76]{1,0} parameter(0)
  %broadcast.195 = f32[16,76,30522]{2,1,0} broadcast(f32[16,76]{1,0} %param_0.1224), dimensions={0,1}, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
  %compare.1 = pred[16,76,30522]{2,1,0} compare(f32[16,76,30522]{2,1,0} %bitcast.456, f32[16,76,30522]{2,1,0} %broadcast.195), direction=EQ, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
  %iota.0 = s64[16,76,30522]{2,1,0} iota(), iota_dimension=2, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
  %constant_74 = s64[] constant(9223372036854775807), metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  %broadcast.194 = s64[16,76,30522]{2,1,0} broadcast(s64[] %constant_74), dimensions={}, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
  %select.20 = s64[16,76,30522]{2,1,0} select(pred[16,76,30522]{2,1,0} %compare.1, s64[16,76,30522]{2,1,0} %iota.0, s64[16,76,30522]{2,1,0} %broadcast.194), metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
  ROOT %reduce.43 = s64[16,76]{1,0} reduce(s64[16,76,30522]{2,1,0} %select.20, s64[] %constant_74), dimensions={2}, to_apply=%min_S64.1974, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
}

%add_float_.1037 (x.1038: f32[], y.1039: f32[]) -> f32[] {
  %x.1038 = f32[] parameter(0)
  %y.1039 = f32[] parameter(1)
  ROOT %add.1040 = f32[] add(f32[] %x.1038, f32[] %y.1039)
}

%fused_computation.7 (param_0.1063: f32[1216], param_1.1474: s32[16,76], param_2.1391: f32[1216], param_3.830: f32[30522], param_4.524: f16[1216,30528]) -> f32[1216] {
  %param_1.1474 = s32[16,76]{1,0} parameter(1)
  %convert.416 = f32[16,76]{1,0} convert(s32[16,76]{1,0} %param_1.1474), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_2"}
  %convert.415 = s64[16,76]{1,0} convert(f32[16,76]{1,0} %convert.416), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_3"}
  %bitcast.310 = s64[1216]{0} bitcast(s64[16,76]{1,0} %convert.415), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_3"}
  %broadcast.1484 = s64[1216,30522]{1,0} broadcast(s64[1216]{0} %bitcast.310), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %iota.10 = s64[1216,30522]{1,0} iota(), iota_dimension=1, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.74 = pred[1216,30522]{1,0} compare(s64[1216,30522]{1,0} %broadcast.1484, s64[1216,30522]{1,0} %iota.10), direction=EQ, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_976 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1483 = f32[1216,30522]{1,0} broadcast(f32[] %constant_976), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_77 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %broadcast.1482 = f32[1216,30522]{1,0} broadcast(f32[] %constant_77), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %select.78 = f32[1216,30522]{1,0} select(pred[1216,30522]{1,0} %compare.74, f32[1216,30522]{1,0} %broadcast.1483, f32[1216,30522]{1,0} %broadcast.1482), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_974 = s64[] constant(0), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1481 = s64[1216]{0} broadcast(s64[] %constant_974), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.73 = pred[1216]{0} compare(s64[1216]{0} %broadcast.1481, s64[1216]{0} %bitcast.310), direction=LE, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_973 = s64[] constant(30522), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1480 = s64[1216]{0} broadcast(s64[] %constant_973), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.72 = pred[1216]{0} compare(s64[1216]{0} %bitcast.310, s64[1216]{0} %broadcast.1480), direction=LT, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %and.7 = pred[1216]{0} and(pred[1216]{0} %compare.73, pred[1216]{0} %compare.72), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1478 = f32[1216]{0} broadcast(f32[] %constant_77), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_972 = f32[] constant(nan), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1477 = f32[1216]{0} broadcast(f32[] %constant_972), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %select.77 = f32[1216]{0} select(pred[1216]{0} %and.7, f32[1216]{0} %broadcast.1478, f32[1216]{0} %broadcast.1477), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1476 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %select.77), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %add.436 = f32[1216,30522]{1,0} add(f32[1216,30522]{1,0} %select.78, f32[1216,30522]{1,0} %broadcast.1476), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %negate.0 = f32[1216,30522]{1,0} negate(f32[1216,30522]{1,0} %add.436), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %param_4.524 = f16[1216,30528]{1,0} parameter(4)
  %slice.33 = f16[1216,30522]{1,0} slice(f16[1216,30528]{1,0} %param_4.524), slice={[0:1216], [0:30522]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}
  %param_3.830 = f32[30522]{0} parameter(3)
  %convert.440 = f16[30522]{0} convert(f32[30522]{0} %param_3.830), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/BiasAdd/Cast"}
  %broadcast.1559 = f16[1216,30522]{1,0} broadcast(f16[30522]{0} %convert.440), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %add.460 = f16[1216,30522]{1,0} add(f16[1216,30522]{1,0} %slice.33, f16[1216,30522]{1,0} %broadcast.1559), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %convert.439 = f32[1216,30522]{1,0} convert(f16[1216,30522]{1,0} %add.460), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast_1"}
  %param_2.1391 = f32[1216]{0} parameter(2)
  %broadcast.1558 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %param_2.1391), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.320 = f32[1216,30522]{1,0} subtract(f32[1216,30522]{1,0} %convert.439, f32[1216,30522]{1,0} %broadcast.1558), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %param_0.1063 = f32[1216]{0} parameter(0)
  %broadcast.196 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %param_0.1063), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.1 = f32[1216,30522]{1,0} subtract(f32[1216,30522]{1,0} %subtract.320, f32[1216,30522]{1,0} %broadcast.196), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %multiply.95 = f32[1216,30522]{1,0} multiply(f32[1216,30522]{1,0} %negate.0, f32[1216,30522]{1,0} %subtract.1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  ROOT %reduce.45 = f32[1216]{0} reduce(f32[1216,30522]{1,0} %multiply.95, f32[] %constant_77), dimensions={1}, to_apply=%add_float_.1037, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
}

%model_bert_pretrain_loss_and_metric_layer_Sum_6-reduction.789 (x.790: f32[], y.791: f32[]) -> f32[] {
  %x.790 = f32[] parameter(0)
  %y.791 = f32[] parameter(1)
  ROOT %add.792 = f32[] add(f32[] %x.790, f32[] %y.791)
}

%fused_computation.8 (param_0.13: f32[], param_1.933: s32[16,1], param_2.679: s64[16]) -> f32[] {
  %param_0.13 = f32[] parameter(0)
  %param_2.679 = s64[16]{0} parameter(2)
  %convert.28 = s32[16]{0} convert(s64[16]{0} %param_2.679), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_11"}
  %param_1.933 = s32[16,1]{1,0} parameter(1)
  %bitcast.144 = s32[16]{0} bitcast(s32[16,1]{1,0} %param_1.933), metadata={op_type="Squeeze" op_name="model/bert_pretrain_loss_and_metric_layer/Squeeze"}
  %compare.2 = pred[16]{0} compare(s32[16]{0} %convert.28, s32[16]{0} %bitcast.144), direction=EQ, metadata={op_type="Equal" op_name="model/bert_pretrain_loss_and_metric_layer/Equal_1"}
  %convert.27 = f32[16]{0} convert(pred[16]{0} %compare.2), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_12"}
  %constant_78 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.46 = f32[] reduce(f32[16]{0} %convert.27, f32[] %constant_78), dimensions={0}, to_apply=%model_bert_pretrain_loss_and_metric_layer_Sum_6-reduction.789, metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_6"}
  ROOT %add.11 = f32[] add(f32[] %param_0.13, f32[] %reduce.46), metadata={op_type="AssignAddVariableOp" op_name="model/bert_pretrain_loss_and_metric_layer/AssignAddVariableOp_4"}
}

%min_S64.778 (lhs.779: s64[], rhs.780: s64[]) -> s64[] {
  %lhs.779 = s64[] parameter(0)
  %rhs.780 = s64[] parameter(1)
  ROOT %minimum.781 = s64[] minimum(s64[] %lhs.779, s64[] %rhs.780)
}

%fused_computation.9 (param_0.1022: f32[16], param_1.1423: f32[2], param_2.1344: f16[16,8]) -> s64[16] {
  %param_2.1344 = f16[16,8]{1,0} parameter(2)
  %slice.17 = f16[16,2]{1,0} slice(f16[16,8]{1,0} %param_2.1344), slice={[0:16], [0:2]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}
  %param_1.1423 = f32[2]{0} parameter(1)
  %convert.402 = f16[2]{0} convert(f32[2]{0} %param_1.1423), metadata={op_type="Cast" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/Cast"}
  %broadcast.1447 = f16[16,2]{1,0} broadcast(f16[2]{0} %convert.402), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %add.423 = f16[16,2]{1,0} add(f16[16,2]{1,0} %slice.17, f16[16,2]{1,0} %broadcast.1447), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %convert.29 = f32[16,2]{1,0} convert(f16[16,2]{1,0} %add.423), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_4"}
  %param_0.1022 = f32[16]{0} parameter(0)
  %broadcast.342 = f32[16,2]{1,0} broadcast(f32[16]{0} %param_0.1022), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.3 = pred[16,2]{1,0} compare(f32[16,2]{1,0} %convert.29, f32[16,2]{1,0} %broadcast.342), direction=EQ, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  %iota.1 = s64[16,2]{1,0} iota(), iota_dimension=1, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  %constant_79 = s64[] constant(9223372036854775807), metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  %broadcast.197 = s64[16,2]{1,0} broadcast(s64[] %constant_79), dimensions={}, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  %select.22 = s64[16,2]{1,0} select(pred[16,2]{1,0} %compare.3, s64[16,2]{1,0} %iota.1, s64[16,2]{1,0} %broadcast.197), metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  ROOT %reduce.47 = s64[16]{0} reduce(s64[16,2]{1,0} %select.22, s64[] %constant_79), dimensions={1}, to_apply=%min_S64.778, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
}

%model_bert_pretrain_loss_and_metric_layer_Mean-reduction.898 (x.899: f32[], y.900: f32[]) -> f32[] {
  %x.899 = f32[] parameter(0)
  %y.900 = f32[] parameter(1)
  ROOT %add.901 = f32[] add(f32[] %x.899, f32[] %y.900)
}

%fused_computation.10 (param_0.1030: f32[16], param_1.1434: s32[16,1], param_2.1356: f32[16], param_3.805: f32[2], param_4.494: f16[16,8]) -> f32[] {
  %param_1.1434 = s32[16,1]{1,0} parameter(1)
  %convert.217 = f32[16,1]{1,0} convert(s32[16,1]{1,0} %param_1.1434), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_5"}
  %convert.216 = s64[16,1]{1,0} convert(f32[16,1]{1,0} %convert.217), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_6"}
  %bitcast.270 = s64[16]{0} bitcast(s64[16,1]{1,0} %convert.216), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_6"}
  %broadcast.802 = s64[16,2]{1,0} broadcast(s64[16]{0} %bitcast.270), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %iota.6 = s64[16,2]{1,0} iota(), iota_dimension=1, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.34 = pred[16,2]{1,0} compare(s64[16,2]{1,0} %broadcast.802, s64[16,2]{1,0} %iota.6), direction=EQ, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_510 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.800 = f32[16,2]{1,0} broadcast(f32[] %constant_510), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_81 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %broadcast.797 = f32[16,2]{1,0} broadcast(f32[] %constant_81), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %select.50 = f32[16,2]{1,0} select(pred[16,2]{1,0} %compare.34, f32[16,2]{1,0} %broadcast.800, f32[16,2]{1,0} %broadcast.797), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_508 = s64[] constant(0), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.796 = s64[16]{0} broadcast(s64[] %constant_508), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.33 = pred[16]{0} compare(s64[16]{0} %broadcast.796, s64[16]{0} %bitcast.270), direction=LE, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_506 = s64[] constant(2), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.795 = s64[16]{0} broadcast(s64[] %constant_506), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.32 = pred[16]{0} compare(s64[16]{0} %bitcast.270, s64[16]{0} %broadcast.795), direction=LT, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %and.3 = pred[16]{0} and(pred[16]{0} %compare.33, pred[16]{0} %compare.32), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.794 = f32[16]{0} broadcast(f32[] %constant_81), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_505 = f32[] constant(nan), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.793 = f32[16]{0} broadcast(f32[] %constant_505), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %select.49 = f32[16]{0} select(pred[16]{0} %and.3, f32[16]{0} %broadcast.794, f32[16]{0} %broadcast.793), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.792 = f32[16,2]{1,0} broadcast(f32[16]{0} %select.49), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %add.236 = f32[16,2]{1,0} add(f32[16,2]{1,0} %select.50, f32[16,2]{1,0} %broadcast.792), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %negate.1 = f32[16,2]{1,0} negate(f32[16,2]{1,0} %add.236), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_4.494 = f16[16,8]{1,0} parameter(4)
  %slice.23 = f16[16,2]{1,0} slice(f16[16,8]{1,0} %param_4.494), slice={[0:16], [0:2]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}
  %param_3.805 = f32[2]{0} parameter(3)
  %convert.412 = f16[2]{0} convert(f32[2]{0} %param_3.805), metadata={op_type="Cast" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/Cast"}
  %broadcast.1458 = f16[16,2]{1,0} broadcast(f16[2]{0} %convert.412), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %add.430 = f16[16,2]{1,0} add(f16[16,2]{1,0} %slice.23, f16[16,2]{1,0} %broadcast.1458), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %convert.411 = f32[16,2]{1,0} convert(f16[16,2]{1,0} %add.430), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_4"}
  %param_2.1356 = f32[16]{0} parameter(2)
  %broadcast.1456 = f32[16,2]{1,0} broadcast(f32[16]{0} %param_2.1356), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.311 = f32[16,2]{1,0} subtract(f32[16,2]{1,0} %convert.411, f32[16,2]{1,0} %broadcast.1456), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_0.1030 = f32[16]{0} parameter(0)
  %broadcast.198 = f32[16,2]{1,0} broadcast(f32[16]{0} %param_0.1030), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.2 = f32[16,2]{1,0} subtract(f32[16,2]{1,0} %subtract.311, f32[16,2]{1,0} %broadcast.198), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %multiply.96 = f32[16,2]{1,0} multiply(f32[16,2]{1,0} %negate.1, f32[16,2]{1,0} %subtract.2), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %bitcast.145 = f32[32]{0} bitcast(f32[16,2]{1,0} %multiply.96)
  ROOT %reduce.48 = f32[] reduce(f32[32]{0} %bitcast.145, f32[] %constant_81), dimensions={0}, to_apply=%model_bert_pretrain_loss_and_metric_layer_Mean-reduction.898, metadata={op_type="Mean" op_name="model/bert_pretrain_loss_and_metric_layer/Mean"}
}

%fused_computation.15 (param_0.23: f32[768], param_1.1669: f32[], param_2.1738: f32[768], param_3.1126: f32[], param_4.711: f32[768], param_5.469: f32[768], param_6.447: f32[], param_7.771: f32[768], param_8.435: f32[768], param_9.282: f32[768], param_10.196: f32[768], param_11.237: f32[768], param_12.174: f32[768], param_13.45: f32[768], param_14.31: f32[768], param_15.63: f32[768], param_16.51: f32[768], param_17.19: f32[768], param_18.18: f32[768], param_19.52: f32[768], param_20.41: f32[768], param_21.14: f32[768], param_22.14: f32[768], param_23.55: f32[768], param_24.45: f32[768], param_25.15: f32[768], param_26.18: f32[768], param_27.48: f32[768], param_28.35: f32[768], param_29.4: f32[768], param_30.4: f32[768], param_31.15: f32[768], param_32.13: f32[768], param_33.4: f32[768], param_34.4: f32[768], param_35.13: f32[768], param_36.12: f32[768], param_37.3: f32[768]) -> (f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768]) {
  %param_0.23 = f32[768]{0} parameter(0)
  %param_2.1738 = f32[768]{0} parameter(2)
  %param_4.711 = f32[768]{0} parameter(4)
  %convert.803.clone.1 = f16[768]{0} convert(f32[768]{0} %param_4.711), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd/BiasAddGrad"}
  %convert.802.clone.1 = f32[768]{0} convert(f16[768]{0} %convert.803.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd/Cast/Cast"}
  %constant_1518_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.2091.clone.1 = f32[768]{0} broadcast(f32[] %constant_1518_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_5"}
  %multiply.1389.clone.1 = f32[768]{0} multiply(f32[768]{0} %convert.802.clone.1, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_44"}
  %subtract.8.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.1389.clone.1, f32[768]{0} %param_2.1738), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %constant_87_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1126 = f32[] parameter(3)
  %subtract.168.clone.1 = f32[] subtract(f32[] %constant_87_clone_1, f32[] %param_3.1126), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.350.clone.1 = f32[768]{0} broadcast(f32[] %subtract.168.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.105.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.8.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %add.17.clone.1 = f32[768]{0} add(f32[768]{0} %param_2.1738, f32[768]{0} %multiply.105.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %param_1.1669 = f32[] parameter(1)
  %broadcast.348 = f32[768]{0} broadcast(f32[] %param_1.1669), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.102 = f32[768]{0} multiply(f32[768]{0} %add.17.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %param_5.469 = f32[768]{0} parameter(5)
  %multiply.104.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.1389.clone.1, f32[768]{0} %multiply.1389.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %subtract.7.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.104.clone.1, f32[768]{0} %param_5.469), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %param_6.447 = f32[] parameter(6)
  %subtract.169.clone.1 = f32[] subtract(f32[] %constant_87_clone_1, f32[] %param_6.447), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.351.clone.1 = f32[768]{0} broadcast(f32[] %subtract.169.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.103.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.7.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %add.16.clone.1 = f32[768]{0} add(f32[768]{0} %param_5.469, f32[768]{0} %multiply.103.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %sqrt.1 = f32[768]{0} sqrt(f32[768]{0} %add.16.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %constant_86 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.349 = f32[768]{0} broadcast(f32[] %constant_86), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %add.15 = f32[768]{0} add(f32[768]{0} %sqrt.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %divide.3 = f32[768]{0} divide(f32[768]{0} %multiply.102, f32[768]{0} %add.15), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %subtract.6 = f32[768]{0} subtract(f32[768]{0} %param_0.23, f32[768]{0} %divide.3), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %param_7.771 = f32[768]{0} parameter(7)
  %param_10.196 = f32[768]{0} parameter(10)
  %param_9.282 = f32[768]{0} parameter(9)
  %multiply.521.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_9.282, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_45"}
  %subtract.11.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.521.clone.1.clone.1, f32[768]{0} %param_10.196), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %multiply.110.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.11.clone.1.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %add.20.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_10.196, f32[768]{0} %multiply.110.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %multiply.107.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.20.clone.1.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %param_8.435 = f32[768]{0} parameter(8)
  %multiply.109.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.521.clone.1.clone.1, f32[768]{0} %multiply.521.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %subtract.10.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.109.clone.1.clone.1, f32[768]{0} %param_8.435), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %multiply.108.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.10.clone.1.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %add.19.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_8.435, f32[768]{0} %multiply.108.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %sqrt.2.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.19.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %add.18.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.2.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %divide.4.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.107.clone.1, f32[768]{0} %add.18.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %subtract.9.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_7.771, f32[768]{0} %divide.4.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_44/update_0/ResourceApplyAdam"}
  %param_11.237 = f32[768]{0} parameter(11)
  %param_14.31 = f32[768]{0} parameter(14)
  %param_13.45 = f32[768]{0} parameter(13)
  %multiply.524.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_13.45, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_46"}
  %subtract.14.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.524.clone.1.clone.1, f32[768]{0} %param_14.31), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %multiply.115.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.14.clone.1.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %add.23.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_14.31, f32[768]{0} %multiply.115.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %multiply.112.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.23.clone.1.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %param_12.174 = f32[768]{0} parameter(12)
  %multiply.114.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.524.clone.1.clone.1, f32[768]{0} %multiply.524.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %subtract.13.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.114.clone.1.clone.1, f32[768]{0} %param_12.174), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %multiply.113.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.13.clone.1.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %add.22.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_12.174, f32[768]{0} %multiply.113.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %sqrt.3.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.22.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %add.21.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.3.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %divide.5.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.112.clone.1, f32[768]{0} %add.21.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %subtract.12.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_11.237, f32[768]{0} %divide.5.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_45/update_0/ResourceApplyAdam"}
  %param_15.63 = f32[768]{0} parameter(15)
  %param_18.18 = f32[768]{0} parameter(18)
  %param_17.19 = f32[768]{0} parameter(17)
  %multiply.526.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_17.19, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_30"}
  %subtract.32.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.526.clone.1.clone.1, f32[768]{0} %param_18.18), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %multiply.144.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.32.clone.1.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %add.41.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_18.18, f32[768]{0} %multiply.144.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %multiply.141.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.41.clone.1.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %param_16.51 = f32[768]{0} parameter(16)
  %multiply.143.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.526.clone.1.clone.1, f32[768]{0} %multiply.526.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %subtract.31.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.143.clone.1.clone.1, f32[768]{0} %param_16.51), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %multiply.142.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.31.clone.1.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %add.40.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_16.51, f32[768]{0} %multiply.142.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %sqrt.9.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.40.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %add.39.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.9.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %divide.11.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.141.clone.1, f32[768]{0} %add.39.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %subtract.30.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_15.63, f32[768]{0} %divide.11.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_29/update_0/ResourceApplyAdam"}
  %param_19.52 = f32[768]{0} parameter(19)
  %param_22.14 = f32[768]{0} parameter(22)
  %param_21.14 = f32[768]{0} parameter(21)
  %multiply.528.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_21.14, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_31"}
  %subtract.35.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.528.clone.1.clone.1, f32[768]{0} %param_22.14), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %multiply.149.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.35.clone.1.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %add.44.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_22.14, f32[768]{0} %multiply.149.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %multiply.146.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.44.clone.1.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %param_20.41 = f32[768]{0} parameter(20)
  %multiply.148.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.528.clone.1.clone.1, f32[768]{0} %multiply.528.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %subtract.34.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.148.clone.1.clone.1, f32[768]{0} %param_20.41), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %multiply.147.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.34.clone.1.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %add.43.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_20.41, f32[768]{0} %multiply.147.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %sqrt.10.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.43.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %add.42.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.10.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %divide.12.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.146.clone.1, f32[768]{0} %add.42.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %subtract.33.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_19.52, f32[768]{0} %divide.12.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_30/update_0/ResourceApplyAdam"}
  %param_23.55 = f32[768]{0} parameter(23)
  %param_26.18 = f32[768]{0} parameter(26)
  %param_25.15 = f32[768]{0} parameter(25)
  %convert.739.clone.1.clone.1 = f16[768]{0} convert(f32[768]{0} %param_25.15), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add/Sum"}
  %convert.738.clone.1.clone.1 = f32[768]{0} convert(f16[768]{0} %convert.739.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add/Cast/Cast"}
  %multiply.1344.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %convert.738.clone.1.clone.1, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_29"}
  %subtract.59.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.1344.clone.1.clone.1, f32[768]{0} %param_26.18), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %multiply.188.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.59.clone.1.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %add.68.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_26.18, f32[768]{0} %multiply.188.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %multiply.185.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.68.clone.1.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %param_24.45 = f32[768]{0} parameter(24)
  %multiply.187.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.1344.clone.1.clone.1, f32[768]{0} %multiply.1344.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %subtract.58.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.187.clone.1.clone.1, f32[768]{0} %param_24.45), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %multiply.186.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.58.clone.1.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %add.67.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_24.45, f32[768]{0} %multiply.186.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %sqrt.18.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.67.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %add.66.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.18.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %divide.20.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.185.clone.1, f32[768]{0} %add.66.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %subtract.57.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_23.55, f32[768]{0} %divide.20.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_28/update_0/ResourceApplyAdam"}
  %param_27.48 = f32[768]{0} parameter(27)
  %param_30.4 = f32[768]{0} parameter(30)
  %param_29.4 = f32[768]{0} parameter(29)
  %multiply.530.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_29.4, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_36"}
  %subtract.62.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.530.clone.1.clone.1, f32[768]{0} %param_30.4), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %multiply.193.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.62.clone.1.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %add.71.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_30.4, f32[768]{0} %multiply.193.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %multiply.190.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.71.clone.1.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %param_28.35 = f32[768]{0} parameter(28)
  %multiply.192.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.530.clone.1.clone.1, f32[768]{0} %multiply.530.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %subtract.61.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.192.clone.1.clone.1, f32[768]{0} %param_28.35), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %multiply.191.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.61.clone.1.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %add.70.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_28.35, f32[768]{0} %multiply.191.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %sqrt.19.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.70.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %add.69.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.19.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %divide.21.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.190.clone.1, f32[768]{0} %add.69.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %subtract.60.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_27.48, f32[768]{0} %divide.21.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_35/update_0/ResourceApplyAdam"}
  %param_31.15 = f32[768]{0} parameter(31)
  %param_34.4 = f32[768]{0} parameter(34)
  %param_33.4 = f32[768]{0} parameter(33)
  %multiply.532.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_33.4, f32[768]{0} %broadcast.2091.clone.1), metadata={op_type="Mul" op_name="mul_37"}
  %subtract.65.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.532.clone.1.clone.1, f32[768]{0} %param_34.4), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %multiply.198.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.65.clone.1.clone.1, f32[768]{0} %broadcast.350.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %add.74.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_34.4, f32[768]{0} %multiply.198.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %multiply.195.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.74.clone.1.clone.1, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %param_32.13 = f32[768]{0} parameter(32)
  %multiply.197.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.532.clone.1.clone.1, f32[768]{0} %multiply.532.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %subtract.64.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.197.clone.1.clone.1, f32[768]{0} %param_32.13), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %multiply.196.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.64.clone.1.clone.1, f32[768]{0} %broadcast.351.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %add.73.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_32.13, f32[768]{0} %multiply.196.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %sqrt.20.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.73.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %add.72.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.20.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %divide.22.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.195.clone.1, f32[768]{0} %add.72.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %subtract.63.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_31.15, f32[768]{0} %divide.22.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_36/update_0/ResourceApplyAdam"}
  %param_35.13 = f32[768]{0} parameter(35)
  %param_37.3 = f32[768]{0} parameter(37)
  %multiply.340.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_37.3, f32[768]{0} %broadcast.348), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %param_36.12 = f32[768]{0} parameter(36)
  %sqrt.45.clone.1 = f32[768]{0} sqrt(f32[768]{0} %param_36.12), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %add.150.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.45.clone.1, f32[768]{0} %broadcast.349), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %divide.47.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.340.clone.1, f32[768]{0} %add.150.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %subtract.138.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_35.13, f32[768]{0} %divide.47.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  ROOT %tuple.114 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %subtract.6, f32[768]{0} %add.17.clone.1, f32[768]{0} %add.16.clone.1, f32[768]{0} %subtract.9.clone.1, f32[768]{0} %add.20.clone.1.clone.1, f32[768]{0} %add.19.clone.1.clone.1, f32[768]{0} %subtract.12.clone.1, f32[768]{0} %add.23.clone.1.clone.1, f32[768]{0} %add.22.clone.1.clone.1, f32[768]{0} %subtract.30.clone.1, f32[768]{0} %add.41.clone.1.clone.1, f32[768]{0} %add.40.clone.1.clone.1, f32[768]{0} %subtract.33.clone.1, f32[768]{0} %add.44.clone.1.clone.1, f32[768]{0} %add.43.clone.1.clone.1, f32[768]{0} %subtract.57.clone.1, f32[768]{0} %add.68.clone.1.clone.1, f32[768]{0} %add.67.clone.1.clone.1, f32[768]{0} %subtract.60.clone.1, f32[768]{0} %add.71.clone.1.clone.1, f32[768]{0} %add.70.clone.1.clone.1, f32[768]{0} %subtract.63.clone.1, f32[768]{0} %add.74.clone.1.clone.1, f32[768]{0} %add.73.clone.1.clone.1, f32[768]{0} %subtract.138.clone.1)
}

%add_float_.1141 (x.1142: f32[], y.1143: f32[]) -> f32[] {
  %x.1142 = f32[] parameter(0)
  %y.1143 = f32[] parameter(1)
  ROOT %add.1144 = f32[] add(f32[] %x.1142, f32[] %y.1143)
}

%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_sub_Sum-reduction.1917 (x.1918: f32[], y.1919: f32[]) -> f32[] {
  %x.1918 = f32[] parameter(0)
  %y.1919 = f32[] parameter(1)
  ROOT %add.1920 = f32[] add(f32[] %x.1918, f32[] %y.1919)
}

%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_mul_Sum_1-reduction.1908 (x.1909: f32[], y.1910: f32[]) -> f32[] {
  %x.1909 = f32[] parameter(0)
  %y.1910 = f32[] parameter(1)
  ROOT %add.1911 = f32[] add(f32[] %x.1909, f32[] %y.1910)
}

%fused_computation.19 (param_0.1230: f16[1216,768], param_1.1729: f16[1216,768], param_2.1858: f32[1216], param_3.1268: f32[1216], param_4.965: f16[1216,768], param_5.908: f32[1216], param_6.795: f32[768], param_7.832: f32[1216], param_8.510: f16[1216,768]) -> (f32[768], f16[1216,768], f32[768], f32[768]) {
  %constant_396_clone_1 = f16[] constant(0.13416), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/mul_1"}
  %broadcast.277.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_396_clone_1), dimensions={}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/mul_1"}
  %param_1.1729 = f16[1216,768]{1,0} parameter(1)
  %multiply.563.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %param_1.1729, f16[1216,768]{1,0} %param_1.1729), metadata={op_type="Square" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/Pow"}
  %param_8.510 = f16[1216,768]{1,0} parameter(8)
  %convert.135.clone.1 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %param_8.510), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast_1/Cast"}
  %constant_1014_clone_1 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1528.clone.1 = f32[1216]{0} broadcast(f32[] %constant_1014_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/add"}
  %param_7.832 = f32[1216]{0} parameter(7)
  %constant_1008_clone_1 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1527.clone.1 = f32[1216]{0} broadcast(f32[] %constant_1008_clone_1), dimensions={}
  %multiply.888.clone.1 = f32[1216]{0} multiply(f32[1216]{0} %param_7.832, f32[1216]{0} %broadcast.1527.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/variance"}
  %add.441.clone.1 = f32[1216]{0} add(f32[1216]{0} %broadcast.1528.clone.1, f32[1216]{0} %multiply.888.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/add"}
  %rsqrt.85.clone.1 = f32[1216]{0} rsqrt(f32[1216]{0} %add.441.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/Rsqrt"}
  %broadcast.698.clone.1 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %rsqrt.85.clone.1), dimensions={0}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %param_6.795 = f32[768]{0} parameter(6)
  %broadcast.696.clone.1 = f32[1216,768]{1,0} broadcast(f32[768]{0} %param_6.795), dimensions={1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %multiply.561.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %broadcast.698.clone.1, f32[1216,768]{1,0} %broadcast.696.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %multiply.451.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %convert.135.clone.1, f32[1216,768]{1,0} %multiply.561.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_1/Mul"}
  %constant_397_clone_1 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.276.clone.1 = f32[1216,1]{1,0} broadcast(f32[] %constant_397_clone_1), dimensions={}
  %broadcast.275.clone.1 = f32[1216,1]{1,0} broadcast(f32[] %constant_1008_clone_1), dimensions={}
  %bitcast.235.clone.1 = f32[1216,1]{1,0} bitcast(f32[1216]{0} %rsqrt.85.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/Rsqrt"}
  %multiply.450.clone.1 = f32[1216,1]{1,0} multiply(f32[1216,1]{1,0} %bitcast.235.clone.1, f32[1216,1]{1,0} %bitcast.235.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/RsqrtGrad"}
  %multiply.449.clone.1 = f32[1216,1]{1,0} multiply(f32[1216,1]{1,0} %multiply.450.clone.1, f32[1216,1]{1,0} %bitcast.235.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/RsqrtGrad"}
  %param_5.908 = f32[1216]{0} parameter(5)
  %constant_398_clone_1 = f32[] constant(-0.5)
  %broadcast.274.clone.1 = f32[1216]{0} broadcast(f32[] %constant_398_clone_1), dimensions={}
  %multiply.448.clone.1 = f32[1216]{0} multiply(f32[1216]{0} %param_5.908, f32[1216]{0} %broadcast.274.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/RsqrtGrad"}
  %bitcast.234.clone.1 = f32[1216,1]{1,0} bitcast(f32[1216]{0} %multiply.448.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/RsqrtGrad"}
  %multiply.447.clone.1 = f32[1216,1]{1,0} multiply(f32[1216,1]{1,0} %multiply.449.clone.1, f32[1216,1]{1,0} %bitcast.234.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/RsqrtGrad"}
  %multiply.446.clone.1 = f32[1216,1]{1,0} multiply(f32[1216,1]{1,0} %broadcast.275.clone.1, f32[1216,1]{1,0} %multiply.447.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv"}
  %multiply.445.clone.1 = f32[1216,1]{1,0} multiply(f32[1216,1]{1,0} %broadcast.276.clone.1, f32[1216,1]{1,0} %multiply.446.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %bitcast.233.clone.1 = f32[1216]{0} bitcast(f32[1216,1]{1,0} %multiply.445.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.273.clone.1 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %bitcast.233.clone.1), dimensions={0}
  %param_4.965 = f16[1216,768]{1,0} parameter(4)
  %convert.425.clone.1 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %param_4.965), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast"}
  %param_3.1268 = f32[1216]{0} parameter(3)
  %multiply.886.clone.1 = f32[1216]{0} multiply(f32[1216]{0} %param_3.1268, f32[1216]{0} %broadcast.1527.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/mean"}
  %broadcast.1523.clone.1 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %multiply.886.clone.1), dimensions={0}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/SquaredDifference"}
  %subtract.316.clone.1 = f32[1216,768]{1,0} subtract(f32[1216,768]{1,0} %convert.425.clone.1, f32[1216,768]{1,0} %broadcast.1523.clone.1), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/SquaredDifference"}
  %multiply.443.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %broadcast.273.clone.1, f32[1216,768]{1,0} %subtract.316.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/mul_1"}
  %add.185.clone.1 = f32[1216,768]{1,0} add(f32[1216,768]{1,0} %multiply.451.clone.1, f32[1216,768]{1,0} %multiply.443.clone.1), metadata={op_type="AddN" op_name="AddN_1"}
  %param_2.1858 = f32[1216]{0} parameter(2)
  %multiply.442.clone.1 = f32[1216]{0} multiply(f32[1216]{0} %broadcast.1527.clone.1, f32[1216]{0} %param_2.1858), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.272.clone.1 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %multiply.442.clone.1), dimensions={0}
  %add.184.clone.1 = f32[1216,768]{1,0} add(f32[1216,768]{1,0} %add.185.clone.1, f32[1216,768]{1,0} %broadcast.272.clone.1), metadata={op_type="AddN" op_name="AddN_1"}
  %convert.134.clone.1 = f16[1216,768]{1,0} convert(f32[1216,768]{1,0} %add.184.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast/Cast"}
  %constant_399_clone_1 = f16[] constant(0.5), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %broadcast.700.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_399_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul"}
  %multiply.562.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %param_1.1729, f16[1216,768]{1,0} %broadcast.700.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul"}
  %multiply.441.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %convert.134.clone.1, f16[1216,768]{1,0} %multiply.562.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_3/Mul_1"}
  %constant_401_clone_1 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.702.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_401_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/add_1"}
  %param_0.1230 = f16[1216,768]{1,0} parameter(0)
  %multiply.440.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %param_0.1230, f16[1216,768]{1,0} %param_0.1230), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/TanhGrad"}
  %subtract.150.clone.1 = f16[1216,768]{1,0} subtract(f16[1216,768]{1,0} %broadcast.702.clone.1, f16[1216,768]{1,0} %multiply.440.clone.1), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/TanhGrad"}
  %multiply.439.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %multiply.441.clone.1, f16[1216,768]{1,0} %subtract.150.clone.1), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/TanhGrad"}
  %constant_400_clone_1 = f16[] constant(0.79785), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %broadcast.701.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_400_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_2"}
  %multiply.438.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %multiply.439.clone.1, f16[1216,768]{1,0} %broadcast.701.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_2/Mul"}
  %multiply.437.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %multiply.563.clone.1, f16[1216,768]{1,0} %multiply.438.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/mul"}
  %multiply.436.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %broadcast.277.clone.1, f16[1216,768]{1,0} %multiply.437.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/mul_1"}
  %multiply.435.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %convert.134.clone.1, f16[1216,768]{1,0} %broadcast.700.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_3/Mul"}
  %add.231.clone.1 = f16[1216,768]{1,0} add(f16[1216,768]{1,0} %broadcast.702.clone.1, f16[1216,768]{1,0} %param_0.1230), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/add_1"}
  %multiply.434.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %multiply.435.clone.1, f16[1216,768]{1,0} %add.231.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul/Mul"}
  %add.183.clone.1 = f16[1216,768]{1,0} add(f16[1216,768]{1,0} %multiply.436.clone.1, f16[1216,768]{1,0} %multiply.434.clone.1), metadata={op_type="AddN" op_name="AddN_2"}
  %add.181.clone.1 = f16[1216,768]{1,0} add(f16[1216,768]{1,0} %add.183.clone.1, f16[1216,768]{1,0} %multiply.438.clone.1), metadata={op_type="AddN" op_name="AddN_2"}
  %convert.33 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %add.181.clone.1), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd/BiasAddGrad"}
  %constant_90 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.49 = f32[768]{0} reduce(f32[1216,768]{1,0} %convert.33, f32[] %constant_90), dimensions={0}, to_apply=%add_float_.1141, metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd/BiasAddGrad"}
  %reduce.51.clone.1 = f32[768]{0} reduce(f32[1216,768]{1,0} %convert.135.clone.1, f32[] %constant_90), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_sub_Sum-reduction.1917, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/sub/Sum"}
  %multiply.914.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %convert.135.clone.1, f32[1216,768]{1,0} %convert.425.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_1/Mul_1"}
  %negate.18.clone.1 = f32[1216,768]{1,0} negate(f32[1216,768]{1,0} %convert.135.clone.1), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/sub/Neg"}
  %multiply.912.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %negate.18.clone.1, f32[1216,768]{1,0} %broadcast.1523.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_2/Mul_1"}
  %add.468.clone.1 = f32[1216,768]{1,0} add(f32[1216,768]{1,0} %multiply.914.clone.1, f32[1216,768]{1,0} %multiply.912.clone.1), metadata={op_type="AddN" op_name="AddN"}
  %multiply.111.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %add.468.clone.1, f32[1216,768]{1,0} %broadcast.698.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul/Mul_1"}
  %reduce.50.clone.1 = f32[768]{0} reduce(f32[1216,768]{1,0} %multiply.111.clone.1, f32[] %constant_90), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_mul_Sum_1-reduction.1908, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul/Sum_1"}
  ROOT %tuple.140 = (f32[768]{0}, f16[1216,768]{1,0}, f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %reduce.49, f16[1216,768]{1,0} %add.181.clone.1, f32[768]{0} %reduce.51.clone.1, f32[768]{0} %reduce.50.clone.1)
}

%fused_computation.28 (param_0.40: f32[30522,768], param_1.1672: f32[], param_2.1744: f32[30522,768], param_3.1132: f32[], param_4.723: f32[30522,768], param_5.490: f32[30522,768], param_6.465: f32[]) -> (f32[30522,768], f32[30522,768], f32[30522,768]) {
  %param_0.40 = f32[30522,768]{1,0} parameter(0)
  %param_2.1744 = f32[30522,768]{1,0} parameter(2)
  %param_4.723 = f32[30522,768]{1,0} parameter(4)
  %constant_1511_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.2086.clone.1 = f32[30522,768]{1,0} broadcast(f32[] %constant_1511_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_1"}
  %multiply.1384.clone.1 = f32[30522,768]{1,0} multiply(f32[30522,768]{1,0} %param_4.723, f32[30522,768]{1,0} %broadcast.2086.clone.1), metadata={op_type="Mul" op_name="mul_1"}
  %subtract.17.clone.1 = f32[30522,768]{1,0} subtract(f32[30522,768]{1,0} %multiply.1384.clone.1, f32[30522,768]{1,0} %param_2.1744), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %constant_104_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1132 = f32[] parameter(3)
  %subtract.174.clone.1 = f32[] subtract(f32[] %constant_104_clone_1, f32[] %param_3.1132), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.202.clone.1 = f32[30522,768]{1,0} broadcast(f32[] %subtract.174.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %multiply.119.clone.1 = f32[30522,768]{1,0} multiply(f32[30522,768]{1,0} %subtract.17.clone.1, f32[30522,768]{1,0} %broadcast.202.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %add.26.clone.1 = f32[30522,768]{1,0} add(f32[30522,768]{1,0} %param_2.1744, f32[30522,768]{1,0} %multiply.119.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %param_1.1672 = f32[] parameter(1)
  %broadcast.200 = f32[30522,768]{1,0} broadcast(f32[] %param_1.1672), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %multiply.116 = f32[30522,768]{1,0} multiply(f32[30522,768]{1,0} %add.26.clone.1, f32[30522,768]{1,0} %broadcast.200), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %param_5.490 = f32[30522,768]{1,0} parameter(5)
  %multiply.118.clone.1 = f32[30522,768]{1,0} multiply(f32[30522,768]{1,0} %multiply.1384.clone.1, f32[30522,768]{1,0} %multiply.1384.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %subtract.16.clone.1 = f32[30522,768]{1,0} subtract(f32[30522,768]{1,0} %multiply.118.clone.1, f32[30522,768]{1,0} %param_5.490), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %param_6.465 = f32[] parameter(6)
  %subtract.175.clone.1 = f32[] subtract(f32[] %constant_104_clone_1, f32[] %param_6.465), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.201.clone.1 = f32[30522,768]{1,0} broadcast(f32[] %subtract.175.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %multiply.117.clone.1 = f32[30522,768]{1,0} multiply(f32[30522,768]{1,0} %subtract.16.clone.1, f32[30522,768]{1,0} %broadcast.201.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %add.25.clone.1 = f32[30522,768]{1,0} add(f32[30522,768]{1,0} %param_5.490, f32[30522,768]{1,0} %multiply.117.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %sqrt.4 = f32[30522,768]{1,0} sqrt(f32[30522,768]{1,0} %add.25.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %constant_103 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.199 = f32[30522,768]{1,0} broadcast(f32[] %constant_103), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %add.24 = f32[30522,768]{1,0} add(f32[30522,768]{1,0} %sqrt.4, f32[30522,768]{1,0} %broadcast.199), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %divide.6 = f32[30522,768]{1,0} divide(f32[30522,768]{1,0} %multiply.116, f32[30522,768]{1,0} %add.24), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %subtract.15 = f32[30522,768]{1,0} subtract(f32[30522,768]{1,0} %param_0.40, f32[30522,768]{1,0} %divide.6), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  ROOT %tuple.11 = (f32[30522,768]{1,0}, f32[30522,768]{1,0}, f32[30522,768]{1,0}) tuple(f32[30522,768]{1,0} %subtract.15, f32[30522,768]{1,0} %add.26.clone.1, f32[30522,768]{1,0} %add.25.clone.1)
}

%scatter-combiner.1765 (p0.1766: f32[], p1.1767: f32[]) -> f32[] {
  %p0.1766 = f32[] parameter(0)
  %p1.1767 = f32[] parameter(1)
  ROOT %add.1768 = f32[] add(f32[] %p0.1766, f32[] %p1.1767)
}

%fused_computation.32 (param_0.670: f16[30528,768], param_1.958: f16[16,512,768], param_2.721: s32[16,512]) -> f32[30522,768] {
  %param_0.670 = f16[30528,768]{1,0} parameter(0)
  %slice.8 = f16[30522,768]{1,0} slice(f16[30528,768]{1,0} %param_0.670), slice={[0:30522], [0:768]}, metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/MatMul/MatMul_1"}
  %convert.36 = f32[30522,768]{1,0} convert(f16[30522,768]{1,0} %slice.8), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/MatMul/Cast/Cast"}
  %param_2.721 = s32[16,512]{1,0} parameter(2)
  %bitcast.259 = s32[8192]{0} bitcast(s32[16,512]{1,0} %param_2.721), metadata={op_type="Reshape" op_name="model/bert_pretrainer/bert_encoder_1/word_embeddings/Reshape"}
  %param_1.958 = f16[16,512,768]{2,1,0} parameter(1)
  %bitcast.258 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %param_1.958), metadata={op_type="Reshape" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/word_embeddings/Reshape"}
  %convert.35 = f32[8192,768]{1,0} convert(f16[8192,768]{1,0} %bitcast.258), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/word_embeddings/GatherV2/Cast/Cast"}
  ROOT %scatter.0 = f32[30522,768]{1,0} scatter(f32[30522,768]{1,0} %convert.36, s32[8192]{0} %bitcast.259, f32[8192,768]{1,0} %convert.35), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%scatter-combiner.1765, metadata={op_type="UnsortedSegmentSum" op_name="AddN_20/inputs_1"}
}

%fused_computation.33 (param_0.46: f32[30522], param_1.1673: f32[], param_2.1746: f32[30522], param_3.1134: f32[], param_4.727: f32[30522], param_5.499: f32[30522], param_6.471: f32[]) -> (f32[30522], f32[30522], f32[30522]) {
  %param_0.46 = f32[30522]{0} parameter(0)
  %param_2.1746 = f32[30522]{0} parameter(2)
  %param_4.727 = f32[30522]{0} parameter(4)
  %convert.795.clone.1 = f16[30522]{0} convert(f32[30522]{0} %param_4.727), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/BiasAdd/BiasAddGrad"}
  %convert.793.clone.1 = f32[30522]{0} convert(f16[30522]{0} %convert.795.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/BiasAdd/Cast/Cast"}
  %constant_1503_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.2082.clone.1 = f32[30522]{0} broadcast(f32[] %constant_1503_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_42"}
  %multiply.1380.clone.1 = f32[30522]{0} multiply(f32[30522]{0} %convert.793.clone.1, f32[30522]{0} %broadcast.2082.clone.1), metadata={op_type="Mul" op_name="mul_42"}
  %subtract.20.clone.1 = f32[30522]{0} subtract(f32[30522]{0} %multiply.1380.clone.1, f32[30522]{0} %param_2.1746), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %constant_108_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1134 = f32[] parameter(3)
  %subtract.176.clone.1 = f32[] subtract(f32[] %constant_108_clone_1, f32[] %param_3.1134), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.208.clone.1 = f32[30522]{0} broadcast(f32[] %subtract.176.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %multiply.124.clone.1 = f32[30522]{0} multiply(f32[30522]{0} %subtract.20.clone.1, f32[30522]{0} %broadcast.208.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %add.29.clone.1 = f32[30522]{0} add(f32[30522]{0} %param_2.1746, f32[30522]{0} %multiply.124.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %param_1.1673 = f32[] parameter(1)
  %broadcast.206 = f32[30522]{0} broadcast(f32[] %param_1.1673), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %multiply.121 = f32[30522]{0} multiply(f32[30522]{0} %add.29.clone.1, f32[30522]{0} %broadcast.206), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %param_5.499 = f32[30522]{0} parameter(5)
  %multiply.123.clone.1 = f32[30522]{0} multiply(f32[30522]{0} %multiply.1380.clone.1, f32[30522]{0} %multiply.1380.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %subtract.19.clone.1 = f32[30522]{0} subtract(f32[30522]{0} %multiply.123.clone.1, f32[30522]{0} %param_5.499), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %param_6.471 = f32[] parameter(6)
  %subtract.177.clone.1 = f32[] subtract(f32[] %constant_108_clone_1, f32[] %param_6.471), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.207.clone.1 = f32[30522]{0} broadcast(f32[] %subtract.177.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %multiply.122.clone.1 = f32[30522]{0} multiply(f32[30522]{0} %subtract.19.clone.1, f32[30522]{0} %broadcast.207.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %add.28.clone.1 = f32[30522]{0} add(f32[30522]{0} %param_5.499, f32[30522]{0} %multiply.122.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %sqrt.5 = f32[30522]{0} sqrt(f32[30522]{0} %add.28.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %constant_107 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.204 = f32[30522]{0} broadcast(f32[] %constant_107), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %add.27 = f32[30522]{0} add(f32[30522]{0} %sqrt.5, f32[30522]{0} %broadcast.204), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %divide.7 = f32[30522]{0} divide(f32[30522]{0} %multiply.121, f32[30522]{0} %add.27), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %subtract.18 = f32[30522]{0} subtract(f32[30522]{0} %param_0.46, f32[30522]{0} %divide.7), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  ROOT %tuple.13 = (f32[30522]{0}, f32[30522]{0}, f32[30522]{0}) tuple(f32[30522]{0} %subtract.18, f32[30522]{0} %add.29.clone.1, f32[30522]{0} %add.28.clone.1)
}

%add_float_.1052 (x.1053: f32[], y.1054: f32[]) -> f32[] {
  %x.1053 = f32[] parameter(0)
  %y.1054 = f32[] parameter(1)
  ROOT %add.1055 = f32[] add(f32[] %x.1053, f32[] %y.1054)
}

%fused_computation.37 (param_0.1075: s32[16,76], param_1.1482: f32[1216,30522], param_2.1404: f32[1216], param_3.845: f32[16,76], param_4.542: f32[]) -> f32[30522] {
  %param_4.542 = f32[] parameter(4)
  %constant_111 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %compare.88 = pred[] compare(f32[] %param_4.542, f32[] %constant_111), direction=EQ, metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %constant_1055 = f32[] constant(1024), metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %divide.69 = f32[] divide(f32[] %constant_1055, f32[] %param_4.542), metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %select.88 = f32[] select(pred[] %compare.88, f32[] %constant_111, f32[] %divide.69), metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %broadcast.1588 = f32[16,76]{1,0} broadcast(f32[] %select.88), dimensions={}, metadata={op_type="Tile" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/Tile_1"}
  %param_3.845 = f32[16,76]{1,0} parameter(3)
  %convert.473 = s32[16,76]{1,0} convert(f32[16,76]{1,0} %param_3.845), metadata={op_type="Cast" op_name="model/Cast"}
  %convert.472 = f32[16,76]{1,0} convert(s32[16,76]{1,0} %convert.473), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast"}
  %multiply.898 = f32[16,76]{1,0} multiply(f32[16,76]{1,0} %broadcast.1588, f32[16,76]{1,0} %convert.472), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/mul/Mul"}
  %bitcast.316 = f32[1216]{0} bitcast(f32[16,76]{1,0} %multiply.898), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/mul"}
  %broadcast.1586 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %bitcast.316), dimensions={0}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/mul"}
  %param_1.1482 = f32[1216,30522]{1,0} parameter(1)
  %param_2.1404 = f32[1216]{0} parameter(2)
  %broadcast.1585 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %param_2.1404), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %divide.68 = f32[1216,30522]{1,0} divide(f32[1216,30522]{1,0} %param_1.1482, f32[1216,30522]{1,0} %broadcast.1585), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %param_0.1075 = s32[16,76]{1,0} parameter(0)
  %convert.471 = f32[16,76]{1,0} convert(s32[16,76]{1,0} %param_0.1075), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_2"}
  %convert.470 = s64[16,76]{1,0} convert(f32[16,76]{1,0} %convert.471), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_3"}
  %bitcast.315 = s64[1216]{0} bitcast(s64[16,76]{1,0} %convert.470), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_3"}
  %broadcast.1584 = s64[1216,30522]{1,0} broadcast(s64[1216]{0} %bitcast.315), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %iota.14 = s64[1216,30522]{1,0} iota(), iota_dimension=1, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.87 = pred[1216,30522]{1,0} compare(s64[1216,30522]{1,0} %broadcast.1584, s64[1216,30522]{1,0} %iota.14), direction=EQ, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1054 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1583 = f32[1216,30522]{1,0} broadcast(f32[] %constant_1054), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1582 = f32[1216,30522]{1,0} broadcast(f32[] %constant_111), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %select.87 = f32[1216,30522]{1,0} select(pred[1216,30522]{1,0} %compare.87, f32[1216,30522]{1,0} %broadcast.1583, f32[1216,30522]{1,0} %broadcast.1582), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1052 = s64[] constant(0), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1581 = s64[1216]{0} broadcast(s64[] %constant_1052), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.86 = pred[1216]{0} compare(s64[1216]{0} %broadcast.1581, s64[1216]{0} %bitcast.315), direction=LE, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1050 = s64[] constant(30522), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1579 = s64[1216]{0} broadcast(s64[] %constant_1050), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.85 = pred[1216]{0} compare(s64[1216]{0} %bitcast.315, s64[1216]{0} %broadcast.1579), direction=LT, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %and.11 = pred[1216]{0} and(pred[1216]{0} %compare.86, pred[1216]{0} %compare.85), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1578 = f32[1216]{0} broadcast(f32[] %constant_111), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1049 = f32[] constant(nan), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1576 = f32[1216]{0} broadcast(f32[] %constant_1049), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %select.86 = f32[1216]{0} select(pred[1216]{0} %and.11, f32[1216]{0} %broadcast.1578, f32[1216]{0} %broadcast.1576), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1575 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %select.86), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %add.462 = f32[1216,30522]{1,0} add(f32[1216,30522]{1,0} %select.87, f32[1216,30522]{1,0} %broadcast.1575), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.322 = f32[1216,30522]{1,0} subtract(f32[1216,30522]{1,0} %divide.68, f32[1216,30522]{1,0} %add.462), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %multiply.897 = f32[1216,30522]{1,0} multiply(f32[1216,30522]{1,0} %broadcast.1586, f32[1216,30522]{1,0} %subtract.322), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/mul"}
  %convert.469 = f16[1216,30522]{1,0} convert(f32[1216,30522]{1,0} %multiply.897), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/Cast_1/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast"}
  %convert.39 = f32[1216,30522]{1,0} convert(f16[1216,30522]{1,0} %convert.469), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/BiasAdd/BiasAddGrad"}
  ROOT %reduce.52 = f32[30522]{0} reduce(f32[1216,30522]{1,0} %convert.39, f32[] %constant_111), dimensions={0}, to_apply=%add_float_.1052, metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/BiasAdd/BiasAddGrad"}
}

%fused_computation.38 (param_0.53: f32[768,2], param_1.1674: f32[], param_2.1748: f32[768,2], param_3.1136: f32[], param_4.731: f16[768,8], param_5.508: f32[768,2], param_6.477: f32[]) -> (f32[768,2], f32[768,2], f32[768,2]) {
  %param_0.53 = f32[768,2]{1,0} parameter(0)
  %param_2.1748 = f32[768,2]{1,0} parameter(2)
  %param_4.731 = f16[768,8]{1,0} parameter(4)
  %slice.39.clone.1 = f16[768,2]{1,0} slice(f16[768,8]{1,0} %param_4.731), slice={[0:768], [0:2]}, metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/MatMul_1"}
  %convert.787.clone.1 = f32[768,2]{1,0} convert(f16[768,2]{1,0} %slice.39.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/MatMul/Cast/Cast"}
  %constant_1496_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.2077.clone.1 = f32[768,2]{1,0} broadcast(f32[] %constant_1496_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_40"}
  %multiply.1376.clone.1 = f32[768,2]{1,0} multiply(f32[768,2]{1,0} %convert.787.clone.1, f32[768,2]{1,0} %broadcast.2077.clone.1), metadata={op_type="Mul" op_name="mul_40"}
  %subtract.23.clone.1 = f32[768,2]{1,0} subtract(f32[768,2]{1,0} %multiply.1376.clone.1, f32[768,2]{1,0} %param_2.1748), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %constant_113_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1136 = f32[] parameter(3)
  %subtract.178.clone.1 = f32[] subtract(f32[] %constant_113_clone_1, f32[] %param_3.1136), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.215.clone.1 = f32[768,2]{1,0} broadcast(f32[] %subtract.178.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %multiply.129.clone.1 = f32[768,2]{1,0} multiply(f32[768,2]{1,0} %subtract.23.clone.1, f32[768,2]{1,0} %broadcast.215.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %add.32.clone.1 = f32[768,2]{1,0} add(f32[768,2]{1,0} %param_2.1748, f32[768,2]{1,0} %multiply.129.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %param_1.1674 = f32[] parameter(1)
  %broadcast.213 = f32[768,2]{1,0} broadcast(f32[] %param_1.1674), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %multiply.126 = f32[768,2]{1,0} multiply(f32[768,2]{1,0} %add.32.clone.1, f32[768,2]{1,0} %broadcast.213), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %param_5.508 = f32[768,2]{1,0} parameter(5)
  %multiply.128.clone.1 = f32[768,2]{1,0} multiply(f32[768,2]{1,0} %multiply.1376.clone.1, f32[768,2]{1,0} %multiply.1376.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %subtract.22.clone.1 = f32[768,2]{1,0} subtract(f32[768,2]{1,0} %multiply.128.clone.1, f32[768,2]{1,0} %param_5.508), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %param_6.477 = f32[] parameter(6)
  %subtract.179.clone.1 = f32[] subtract(f32[] %constant_113_clone_1, f32[] %param_6.477), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.214.clone.1 = f32[768,2]{1,0} broadcast(f32[] %subtract.179.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %multiply.127.clone.1 = f32[768,2]{1,0} multiply(f32[768,2]{1,0} %subtract.22.clone.1, f32[768,2]{1,0} %broadcast.214.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %add.31.clone.1 = f32[768,2]{1,0} add(f32[768,2]{1,0} %param_5.508, f32[768,2]{1,0} %multiply.127.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %sqrt.6 = f32[768,2]{1,0} sqrt(f32[768,2]{1,0} %add.31.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %constant_112 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.212 = f32[768,2]{1,0} broadcast(f32[] %constant_112), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %add.30 = f32[768,2]{1,0} add(f32[768,2]{1,0} %sqrt.6, f32[768,2]{1,0} %broadcast.212), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %divide.8 = f32[768,2]{1,0} divide(f32[768,2]{1,0} %multiply.126, f32[768,2]{1,0} %add.30), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %subtract.21 = f32[768,2]{1,0} subtract(f32[768,2]{1,0} %param_0.53, f32[768,2]{1,0} %divide.8), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  ROOT %tuple.15 = (f32[768,2]{1,0}, f32[768,2]{1,0}, f32[768,2]{1,0}) tuple(f32[768,2]{1,0} %subtract.21, f32[768,2]{1,0} %add.32.clone.1, f32[768,2]{1,0} %add.31.clone.1)
}

%add_float_.857 (x.858: f32[], y.859: f32[]) -> f32[] {
  %x.858 = f32[] parameter(0)
  %y.859 = f32[] parameter(1)
  ROOT %add.860 = f32[] add(f32[] %x.858, f32[] %y.859)
}

%fused_computation.42 (param_0.58: f32[2], param_1.1675: f32[], param_2.1750: f32[2], param_3.1138: f32[], param_4.736: f32[2], param_5.515: f32[], param_6.486: f16[16,2]) -> (f32[2], f32[2], f32[2]) {
  %param_0.58 = f32[2]{0} parameter(0)
  %param_2.1750 = f32[2]{0} parameter(2)
  %param_6.486 = f16[16,2]{1,0} parameter(6)
  %convert.43.clone.1 = f32[16,2]{1,0} convert(f16[16,2]{1,0} %param_6.486), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/BiasAddGrad"}
  %constant_120_clone_1 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.53.clone.1 = f32[2]{0} reduce(f32[16,2]{1,0} %convert.43.clone.1, f32[] %constant_120_clone_1), dimensions={0}, to_apply=%add_float_.857, metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/BiasAddGrad"}
  %convert.42.clone.1 = f16[2]{0} convert(f32[2]{0} %reduce.53.clone.1), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/BiasAddGrad"}
  %convert.41.clone.1 = f32[2]{0} convert(f16[2]{0} %convert.42.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/Cast/Cast"}
  %constant_119_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.222.clone.1 = f32[2]{0} broadcast(f32[] %constant_119_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_41"}
  %multiply.135.clone.1 = f32[2]{0} multiply(f32[2]{0} %convert.41.clone.1, f32[2]{0} %broadcast.222.clone.1), metadata={op_type="Mul" op_name="mul_41"}
  %subtract.26.clone.1 = f32[2]{0} subtract(f32[2]{0} %multiply.135.clone.1, f32[2]{0} %param_2.1750), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %constant_117_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1138 = f32[] parameter(3)
  %subtract.180.clone.1 = f32[] subtract(f32[] %constant_117_clone_1, f32[] %param_3.1138), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.220.clone.1 = f32[2]{0} broadcast(f32[] %subtract.180.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %multiply.134.clone.1 = f32[2]{0} multiply(f32[2]{0} %subtract.26.clone.1, f32[2]{0} %broadcast.220.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %add.35.clone.1 = f32[2]{0} add(f32[2]{0} %param_2.1750, f32[2]{0} %multiply.134.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %param_1.1675 = f32[] parameter(1)
  %broadcast.218 = f32[2]{0} broadcast(f32[] %param_1.1675), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %multiply.131 = f32[2]{0} multiply(f32[2]{0} %add.35.clone.1, f32[2]{0} %broadcast.218), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %param_4.736 = f32[2]{0} parameter(4)
  %multiply.133.clone.1 = f32[2]{0} multiply(f32[2]{0} %multiply.135.clone.1, f32[2]{0} %multiply.135.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %subtract.25.clone.1 = f32[2]{0} subtract(f32[2]{0} %multiply.133.clone.1, f32[2]{0} %param_4.736), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %param_5.515 = f32[] parameter(5)
  %subtract.181.clone.1 = f32[] subtract(f32[] %constant_117_clone_1, f32[] %param_5.515), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.219.clone.1 = f32[2]{0} broadcast(f32[] %subtract.181.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %multiply.132.clone.1 = f32[2]{0} multiply(f32[2]{0} %subtract.25.clone.1, f32[2]{0} %broadcast.219.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %add.34.clone.1 = f32[2]{0} add(f32[2]{0} %param_4.736, f32[2]{0} %multiply.132.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %sqrt.7 = f32[2]{0} sqrt(f32[2]{0} %add.34.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %constant_116 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.217 = f32[2]{0} broadcast(f32[] %constant_116), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %add.33 = f32[2]{0} add(f32[2]{0} %sqrt.7, f32[2]{0} %broadcast.217), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %divide.9 = f32[2]{0} divide(f32[2]{0} %multiply.131, f32[2]{0} %add.33), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %subtract.24 = f32[2]{0} subtract(f32[2]{0} %param_0.58, f32[2]{0} %divide.9), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  ROOT %tuple.17 = (f32[2]{0}, f32[2]{0}, f32[2]{0}) tuple(f32[2]{0} %subtract.24, f32[2]{0} %add.35.clone.1, f32[2]{0} %add.34.clone.1)
}

%fused_computation.46 (param_0.63: f32[2,768], param_1.1676: f32[], param_2.1752: f32[2,768], param_3.1140: f32[], param_4.740: f16[8,768], param_5.524: f32[2,768], param_6.492: f32[]) -> (f32[2,768], f32[2,768], f32[2,768]) {
  %param_0.63 = f32[2,768]{1,0} parameter(0)
  %param_2.1752 = f32[2,768]{1,0} parameter(2)
  %param_4.740 = f16[8,768]{1,0} parameter(4)
  %slice.35.clone.1 = f16[2,768]{1,0} slice(f16[8,768]{1,0} %param_4.740), slice={[0:2], [0:768]}, metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul/MatMul"}
  %convert.780.clone.1 = f32[2,768]{1,0} convert(f16[2,768]{1,0} %slice.35.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul/Cast/Cast"}
  %constant_1489_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.2071.clone.1 = f32[2,768]{1,0} broadcast(f32[] %constant_1489_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_3"}
  %multiply.1372.clone.1 = f32[2,768]{1,0} multiply(f32[2,768]{1,0} %convert.780.clone.1, f32[2,768]{1,0} %broadcast.2071.clone.1), metadata={op_type="Mul" op_name="mul_3"}
  %subtract.29.clone.1 = f32[2,768]{1,0} subtract(f32[2,768]{1,0} %multiply.1372.clone.1, f32[2,768]{1,0} %param_2.1752), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %constant_122_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1140 = f32[] parameter(3)
  %subtract.182.clone.1 = f32[] subtract(f32[] %constant_122_clone_1, f32[] %param_3.1140), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.227.clone.1 = f32[2,768]{1,0} broadcast(f32[] %subtract.182.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %multiply.139.clone.1 = f32[2,768]{1,0} multiply(f32[2,768]{1,0} %subtract.29.clone.1, f32[2,768]{1,0} %broadcast.227.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %add.38.clone.1 = f32[2,768]{1,0} add(f32[2,768]{1,0} %param_2.1752, f32[2,768]{1,0} %multiply.139.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %param_1.1676 = f32[] parameter(1)
  %broadcast.225 = f32[2,768]{1,0} broadcast(f32[] %param_1.1676), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %multiply.136 = f32[2,768]{1,0} multiply(f32[2,768]{1,0} %add.38.clone.1, f32[2,768]{1,0} %broadcast.225), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %param_5.524 = f32[2,768]{1,0} parameter(5)
  %multiply.138.clone.1 = f32[2,768]{1,0} multiply(f32[2,768]{1,0} %multiply.1372.clone.1, f32[2,768]{1,0} %multiply.1372.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %subtract.28.clone.1 = f32[2,768]{1,0} subtract(f32[2,768]{1,0} %multiply.138.clone.1, f32[2,768]{1,0} %param_5.524), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %param_6.492 = f32[] parameter(6)
  %subtract.183.clone.1 = f32[] subtract(f32[] %constant_122_clone_1, f32[] %param_6.492), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.226.clone.1 = f32[2,768]{1,0} broadcast(f32[] %subtract.183.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %multiply.137.clone.1 = f32[2,768]{1,0} multiply(f32[2,768]{1,0} %subtract.28.clone.1, f32[2,768]{1,0} %broadcast.226.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %add.37.clone.1 = f32[2,768]{1,0} add(f32[2,768]{1,0} %param_5.524, f32[2,768]{1,0} %multiply.137.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %sqrt.8 = f32[2,768]{1,0} sqrt(f32[2,768]{1,0} %add.37.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %constant_121 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.223 = f32[2,768]{1,0} broadcast(f32[] %constant_121), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %add.36 = f32[2,768]{1,0} add(f32[2,768]{1,0} %sqrt.8, f32[2,768]{1,0} %broadcast.223), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %divide.10 = f32[2,768]{1,0} divide(f32[2,768]{1,0} %multiply.136, f32[2,768]{1,0} %add.36), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %subtract.27 = f32[2,768]{1,0} subtract(f32[2,768]{1,0} %param_0.63, f32[2,768]{1,0} %divide.10), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  ROOT %tuple.19 = (f32[2,768]{1,0}, f32[2,768]{1,0}, f32[2,768]{1,0}) tuple(f32[2,768]{1,0} %subtract.27, f32[2,768]{1,0} %add.38.clone.1, f32[2,768]{1,0} %add.37.clone.1)
}

%fused_computation.62 (param_0.88: f16[16,12,64,512]) -> f16[768,8192] {
  %param_0.88 = f16[16,12,64,512]{3,2,1,0} parameter(0)
  %transpose.121 = f16[12,64,16,512]{3,1,0,2} transpose(f16[16,12,64,512]{3,2,1,0} %param_0.88), dimensions={1,2,0,3}
  %copy.83 = f16[12,64,16,512]{3,2,1,0} copy(f16[12,64,16,512]{3,1,0,2} %transpose.121)
  ROOT %bitcast.149 = f16[768,8192]{1,0} bitcast(f16[12,64,16,512]{3,2,1,0} %copy.83)
}

%fused_computation.72 (param_0.106: f16[16,12,512,64]) -> f16[768,8192] {
  %param_0.106 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.123 = f16[12,64,16,512]{1,3,0,2} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.106), dimensions={1,3,0,2}
  %copy.85 = f16[12,64,16,512]{3,2,1,0} copy(f16[12,64,16,512]{1,3,0,2} %transpose.123)
  ROOT %bitcast.152 = f16[768,8192]{1,0} bitcast(f16[12,64,16,512]{3,2,1,0} %copy.85)
}

%fused_computation.82 (param_0.124: f16[16,12,512,64]) -> f16[768,8192] {
  %param_0.124 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.125 = f16[12,64,16,512]{1,3,0,2} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.124), dimensions={1,3,0,2}
  %copy.87 = f16[12,64,16,512]{3,2,1,0} copy(f16[12,64,16,512]{1,3,0,2} %transpose.125)
  ROOT %bitcast.155 = f16[768,8192]{1,0} bitcast(f16[12,64,16,512]{3,2,1,0} %copy.87)
}

%fused_computation.92 (param_0.141: f16[16,512,768]) -> f16[768,8192] {
  %param_0.141 = f16[16,512,768]{2,1,0} parameter(0)
  %transpose.127 = f16[768,16,512]{0,2,1} transpose(f16[16,512,768]{2,1,0} %param_0.141), dimensions={2,0,1}
  ROOT %bitcast.158 = f16[768,8192]{0,1} bitcast(f16[768,16,512]{0,2,1} %transpose.127)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_attention_output_add_Sum-reduction.1335 (x.1336: f32[], y.1337: f32[]) -> f32[] {
  %x.1336 = f32[] parameter(0)
  %y.1337 = f32[] parameter(1)
  ROOT %add.1338 = f32[] add(f32[] %x.1336, f32[] %y.1337)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_sub_Sum-reduction.1866 (x.1867: f32[], y.1868: f32[]) -> f32[] {
  %x.1867 = f32[] parameter(0)
  %y.1868 = f32[] parameter(1)
  ROOT %add.1869 = f32[] add(f32[] %x.1867, f32[] %y.1868)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_Sum_1-reduction.1857 (x.1858: f32[], y.1859: f32[]) -> f32[] {
  %x.1858 = f32[] parameter(0)
  %y.1859 = f32[] parameter(1)
  ROOT %add.1860 = f32[] add(f32[] %x.1858, f32[] %y.1859)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_mul_Sum_1-reduction.1884 (x.1885: f32[], y.1886: f32[]) -> f32[] {
  %x.1885 = f32[] parameter(0)
  %y.1886 = f32[] parameter(1)
  ROOT %add.1887 = f32[] add(f32[] %x.1885, f32[] %y.1886)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_sub_Sum-reduction.1893 (x.1894: f32[], y.1895: f32[]) -> f32[] {
  %x.1894 = f32[] parameter(0)
  %y.1895 = f32[] parameter(1)
  ROOT %add.1896 = f32[] add(f32[] %x.1894, f32[] %y.1895)
}

%fused_computation.97 (param_0.690: f16[16,512,768], param_1.1772: f32[16,512,768], param_2.1906: f32[16,512], param_3.1319: f32[16,512], param_4.1011: f32[16,512], param_5.952: f32[768], param_6.836: f32[768], param_7.869: f32[16,512], param_8.540: f16[16,512,768], param_9.400: f16[8192,768], param_10.325: f32[768], param_11.358: f16[16,512,768], param_12.279: f16[16,768], param_13.135: f16[8192,768]) -> (f32[768], f32[768], f32[768], f32[768], f32[768]) {
  %param_0.690 = f16[16,512,768]{2,1,0} parameter(0)
  %convert.60 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_0.690), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add/Sum"}
  %bitcast.159 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %convert.60)
  %constant_171 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.58 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.159, f32[] %constant_171), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_attention_output_add_Sum-reduction.1335, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add/Sum"}
  %param_13.135 = f16[8192,768]{1,0} parameter(13)
  %convert.518.clone.1 = f32[8192,768]{1,0} convert(f16[8192,768]{1,0} %param_13.135), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %bitcast.336.clone.1 = f32[16,512,768]{2,1,0} bitcast(f32[8192,768]{1,0} %convert.518.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %param_12.279 = f16[16,768]{1,0} parameter(12)
  %convert.517.clone.1 = f32[16,768]{1,0} convert(f16[16,768]{1,0} %param_12.279), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_3/Cast"}
  %bitcast.335.clone.1 = f32[16,1,768]{2,1,0} bitcast(f32[16,768]{1,0} %convert.517.clone.1), metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %pad.29.clone.1 = f32[16,512,768]{2,1,0} pad(f32[16,1,768]{2,1,0} %bitcast.335.clone.1, f32[] %constant_171), padding=0_0x0_511x0_0, metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %add.477.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %bitcast.336.clone.1, f32[16,512,768]{2,1,0} %pad.29.clone.1), metadata={op_type="AddN" op_name="AddN_3"}
  %bitcast.161.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %add.477.clone.1)
  %reduce.60.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.161.clone.1, f32[] %constant_171), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_sub_Sum-reduction.1893, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/sub/Sum"}
  %param_11.358 = f16[16,512,768]{2,1,0} parameter(11)
  %constant_1133_clone_1_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1673.clone.1.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1133_clone_1_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.100.clone.1.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_11.358, f16[16,512,768]{2,1,0} %broadcast.1673.clone.1.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/GreaterEqual"}
  %constant_1132_clone_1_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1672.clone.1.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1132_clone_1_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_1131_clone_1_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1671.clone.1.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1131_clone_1_clone_1), dimensions={}
  %select.98.clone.1.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.100.clone.1.clone.1, f16[16,512,768]{2,1,0} %broadcast.1672.clone.1.clone.1, f16[16,512,768]{2,1,0} %broadcast.1671.clone.1.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %param_10.325 = f32[768]{0} parameter(10)
  %convert.541.clone.1.clone.1 = f16[768]{0} convert(f32[768]{0} %param_10.325), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Cast"}
  %broadcast.1670.clone.1.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.541.clone.1.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %param_9.400 = f16[8192,768]{1,0} parameter(9)
  %bitcast.346.clone.1.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_9.400), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum"}
  %add.503.clone.1.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1670.clone.1.clone.1, f16[16,512,768]{2,1,0} %bitcast.346.clone.1.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %multiply.956.clone.1.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.98.clone.1.clone.1, f16[16,512,768]{2,1,0} %add.503.clone.1.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
  %convert.540.clone.1.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.956.clone.1.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_2"}
  %param_8.540 = f16[16,512,768]{2,1,0} parameter(8)
  %convert.539.clone.1.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_8.540), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_7.869 = f32[16,512]{1,0} parameter(7)
  %constant_905_clone_1_clone_1 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1669.clone.1.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_905_clone_1_clone_1), dimensions={}
  %multiply.954.clone.1.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_7.869, f32[16,512]{1,0} %broadcast.1669.clone.1.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_904_clone_1_clone_1 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1668.clone.1.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_904_clone_1_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.502.clone.1.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.954.clone.1.clone.1, f32[16,512]{1,0} %broadcast.1668.clone.1.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.95.clone.1.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.502.clone.1.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1667.clone.1.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.95.clone.1.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_6.836 = f32[768]{0} parameter(6)
  %broadcast.1666.clone.1.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_6.836), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.953.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1667.clone.1.clone.1, f32[16,512,768]{2,1,0} %broadcast.1666.clone.1.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.952.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.539.clone.1.clone.1, f32[16,512,768]{2,1,0} %multiply.953.clone.1.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1"}
  %param_5.952 = f32[768]{0} parameter(5)
  %broadcast.1665.clone.1.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_5.952), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %param_4.1011 = f32[16,512]{1,0} parameter(4)
  %multiply.951.clone.1.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.1011, f32[16,512]{1,0} %broadcast.1669.clone.1.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1663.clone.1.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.951.clone.1.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.950.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.953.clone.1.clone.1, f32[16,512,768]{2,1,0} %broadcast.1663.clone.1.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.328.clone.1.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1665.clone.1.clone.1, f32[16,512,768]{2,1,0} %multiply.950.clone.1.clone.1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %add.501.clone.1.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.952.clone.1.clone.1, f32[16,512,768]{2,1,0} %subtract.328.clone.1.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1"}
  %add.500.clone.1.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.540.clone.1.clone.1, f32[16,512,768]{2,1,0} %add.501.clone.1.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/add_1"}
  %multiply.949.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.477.clone.1, f32[16,512,768]{2,1,0} %add.500.clone.1.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_1/Mul_1"}
  %negate.22.clone.1.clone.1 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %add.477.clone.1), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/sub/Neg"}
  %param_3.1319 = f32[16,512]{1,0} parameter(3)
  %multiply.948.clone.1.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.1319, f32[16,512]{1,0} %broadcast.1669.clone.1.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mean"}
  %broadcast.1661.clone.1.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.948.clone.1.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/SquaredDifference"}
  %multiply.947.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.22.clone.1.clone.1, f32[16,512,768]{2,1,0} %broadcast.1661.clone.1.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.499.clone.1.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.949.clone.1.clone.1, f32[16,512,768]{2,1,0} %multiply.947.clone.1.clone.1), metadata={op_type="AddN" op_name="AddN_4"}
  %param_2.1906 = f32[16,512]{1,0} parameter(2)
  %multiply.826.clone.1.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1906, f32[16,512]{1,0} %broadcast.1669.clone.1.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  %add.389.clone.1.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.826.clone.1.clone.1, f32[16,512]{1,0} %broadcast.1668.clone.1.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add"}
  %rsqrt.73.clone.1.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.389.clone.1.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.440.clone.1.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.73.clone.1.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.194.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.499.clone.1.clone.1, f32[16,512,768]{2,1,0} %broadcast.440.clone.1.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul/Mul_1"}
  %bitcast.160.clone.1.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %multiply.194.clone.1.clone.1)
  %reduce.59.clone.1.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.160.clone.1.clone.1, f32[] %constant_171), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_mul_Sum_1-reduction.1884, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul/Sum_1"}
  %param_1.1772 = f32[16,512,768]{2,1,0} parameter(1)
  %multiply.1015.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %param_1.1772, f32[16,512,768]{2,1,0} %convert.539.clone.1.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1/Mul_1"}
  %negate.26.clone.1.clone.1 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %param_1.1772), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub/Neg"}
  %multiply.1013.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.26.clone.1.clone.1, f32[16,512,768]{2,1,0} %broadcast.1663.clone.1.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.528.clone.1.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1015.clone.1.clone.1, f32[16,512,768]{2,1,0} %multiply.1013.clone.1.clone.1), metadata={op_type="AddN" op_name="AddN_8"}
  %multiply.145.clone.1.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.528.clone.1.clone.1, f32[16,512,768]{2,1,0} %broadcast.1667.clone.1.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/Mul_1"}
  %bitcast.146.clone.1.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %multiply.145.clone.1.clone.1)
  %reduce.54.clone.1.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.146.clone.1.clone.1, f32[] %constant_171), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_Sum_1-reduction.1857, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/Sum_1"}
  %bitcast.147.clone.1.clone.1.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %param_1.1772)
  %reduce.55.clone.1.clone.1.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.147.clone.1.clone.1.clone.1, f32[] %constant_171), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_sub_Sum-reduction.1866, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub/Sum"}
  ROOT %tuple.156 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %reduce.58, f32[768]{0} %reduce.60.clone.1, f32[768]{0} %reduce.59.clone.1.clone.1, f32[768]{0} %reduce.54.clone.1.clone.1, f32[768]{0} %reduce.55.clone.1.clone.1.clone.1)
}

%fused_computation.110 (param_0.165: f16[16,512,768]) -> f16[768,8192] {
  %param_0.165 = f16[16,512,768]{2,1,0} parameter(0)
  %transpose.128 = f16[768,16,512]{0,2,1} transpose(f16[16,512,768]{2,1,0} %param_0.165), dimensions={2,0,1}
  ROOT %bitcast.162 = f16[768,8192]{0,1} bitcast(f16[768,16,512]{0,2,1} %transpose.128)
}

%add_float_.875 (x.876: f32[], y.877: f32[]) -> f32[] {
  %x.876 = f32[] parameter(0)
  %y.877 = f32[] parameter(1)
  ROOT %add.878 = f32[] add(f32[] %x.876, f32[] %y.877)
}

%fused_computation.111 (param_0.166: f32[768], param_1.1690: f32[], param_2.1780: f32[768], param_3.1168: f32[], param_4.798: f32[768], param_5.645: f32[768], param_6.580: f32[], param_7.774: f32[768], param_8.439: f32[768], param_9.287: f32[768], param_10.201: f32[768], param_11.253: f32[768], param_12.188: f32[768], param_13.50: f32[768], param_14.36: f32[768], param_15.79: f32[768], param_16.65: f32[768], param_17.24: f32[768], param_18.23: f32[768], param_19.70: f32[768], param_20.57: f32[768], param_21.19: f32[768], param_22.19: f32[768], param_23.71: f32[768], param_24.59: f32[768], param_25.20: f32[768], param_26.23: f32[768], param_27.64: f32[768], param_28.49: f32[768], param_29.9: f32[768], param_30.9: f32[768], param_31.33: f32[768], param_32.29: f32[768], param_33.10: f32[768], param_34.14: f16[16,768]) -> (f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768]) {
  %param_0.166 = f32[768]{0} parameter(0)
  %param_2.1780 = f32[768]{0} parameter(2)
  %param_4.798 = f32[768]{0} parameter(4)
  %convert.725.clone.1 = f16[768]{0} convert(f32[768]{0} %param_4.798), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Sum"}
  %convert.724.clone.1 = f32[768]{0} convert(f16[768]{0} %convert.725.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Cast/Cast"}
  %constant_1431_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.2032.clone.1 = f32[768]{0} broadcast(f32[] %constant_1431_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_5"}
  %multiply.1336.clone.1 = f32[768]{0} multiply(f32[768]{0} %convert.724.clone.1, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_35"}
  %subtract.71.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.1336.clone.1, f32[768]{0} %param_2.1780), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %constant_191_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1168 = f32[] parameter(3)
  %subtract.210.clone.1 = f32[] subtract(f32[] %constant_191_clone_1, f32[] %param_3.1168), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.455.clone.1 = f32[768]{0} broadcast(f32[] %subtract.210.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.207.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.71.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %add.80.clone.1 = f32[768]{0} add(f32[768]{0} %param_2.1780, f32[768]{0} %multiply.207.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %param_1.1690 = f32[] parameter(1)
  %broadcast.453 = f32[768]{0} broadcast(f32[] %param_1.1690), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.204 = f32[768]{0} multiply(f32[768]{0} %add.80.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %param_5.645 = f32[768]{0} parameter(5)
  %multiply.206.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.1336.clone.1, f32[768]{0} %multiply.1336.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %subtract.70.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.206.clone.1, f32[768]{0} %param_5.645), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %param_6.580 = f32[] parameter(6)
  %subtract.211.clone.1 = f32[] subtract(f32[] %constant_191_clone_1, f32[] %param_6.580), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.456.clone.1 = f32[768]{0} broadcast(f32[] %subtract.211.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.205.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.70.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %add.79.clone.1 = f32[768]{0} add(f32[768]{0} %param_5.645, f32[768]{0} %multiply.205.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %sqrt.22 = f32[768]{0} sqrt(f32[768]{0} %add.79.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %constant_190 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.454 = f32[768]{0} broadcast(f32[] %constant_190), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %add.78 = f32[768]{0} add(f32[768]{0} %sqrt.22, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %divide.24 = f32[768]{0} divide(f32[768]{0} %multiply.204, f32[768]{0} %add.78), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %subtract.69 = f32[768]{0} subtract(f32[768]{0} %param_0.166, f32[768]{0} %divide.24), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %param_7.774 = f32[768]{0} parameter(7)
  %param_10.201 = f32[768]{0} parameter(10)
  %param_9.287 = f32[768]{0} parameter(9)
  %multiply.534.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_9.287, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_14"}
  %subtract.80.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.534.clone.1.clone.1, f32[768]{0} %param_10.201), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %multiply.223.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.80.clone.1.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %add.89.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_10.201, f32[768]{0} %multiply.223.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %multiply.220.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.89.clone.1.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %param_8.439 = f32[768]{0} parameter(8)
  %multiply.222.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.534.clone.1.clone.1, f32[768]{0} %multiply.534.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %subtract.79.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.222.clone.1.clone.1, f32[768]{0} %param_8.439), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %multiply.221.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.79.clone.1.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %add.88.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_8.439, f32[768]{0} %multiply.221.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %sqrt.25.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.88.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %add.87.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.25.clone.1, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %divide.27.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.220.clone.1, f32[768]{0} %add.87.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %subtract.78.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_7.774, f32[768]{0} %divide.27.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_13/update_0/ResourceApplyAdam"}
  %param_11.253 = f32[768]{0} parameter(11)
  %param_14.36 = f32[768]{0} parameter(14)
  %param_13.50 = f32[768]{0} parameter(13)
  %multiply.536.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_13.50, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_15"}
  %subtract.83.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.536.clone.1.clone.1, f32[768]{0} %param_14.36), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %multiply.228.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.83.clone.1.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %add.92.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_14.36, f32[768]{0} %multiply.228.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %multiply.225.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.92.clone.1.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %param_12.188 = f32[768]{0} parameter(12)
  %multiply.227.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.536.clone.1.clone.1, f32[768]{0} %multiply.536.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %subtract.82.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.227.clone.1.clone.1, f32[768]{0} %param_12.188), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %multiply.226.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.82.clone.1.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %add.91.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_12.188, f32[768]{0} %multiply.226.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %sqrt.26.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.91.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %add.90.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.26.clone.1, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %divide.28.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.225.clone.1, f32[768]{0} %add.90.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %subtract.81.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_11.253, f32[768]{0} %divide.28.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_14/update_0/ResourceApplyAdam"}
  %param_15.79 = f32[768]{0} parameter(15)
  %param_18.23 = f32[768]{0} parameter(18)
  %param_17.24 = f32[768]{0} parameter(17)
  %convert.667.clone.1.clone.1 = f16[768]{0} convert(f32[768]{0} %param_17.24), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/add/Sum"}
  %convert.666.clone.1.clone.1 = f32[768]{0} convert(f16[768]{0} %convert.667.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/add/Cast/Cast"}
  %multiply.1296.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %convert.666.clone.1.clone.1, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_13"}
  %subtract.107.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.1296.clone.1.clone.1, f32[768]{0} %param_18.23), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %multiply.271.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.107.clone.1.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %add.116.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_18.23, f32[768]{0} %multiply.271.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %multiply.268.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.116.clone.1.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %param_16.65 = f32[768]{0} parameter(16)
  %multiply.270.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.1296.clone.1.clone.1, f32[768]{0} %multiply.1296.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %subtract.106.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.270.clone.1.clone.1, f32[768]{0} %param_16.65), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %multiply.269.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.106.clone.1.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %add.115.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_16.65, f32[768]{0} %multiply.269.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %sqrt.34.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.115.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %add.114.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.34.clone.1, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %divide.36.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.268.clone.1, f32[768]{0} %add.114.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %subtract.105.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_15.79, f32[768]{0} %divide.36.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_12/update_0/ResourceApplyAdam"}
  %param_19.70 = f32[768]{0} parameter(19)
  %param_22.19 = f32[768]{0} parameter(22)
  %param_21.19 = f32[768]{0} parameter(21)
  %multiply.538.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_21.19, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_20"}
  %subtract.110.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.538.clone.1.clone.1, f32[768]{0} %param_22.19), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %multiply.277.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.110.clone.1.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %add.119.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_22.19, f32[768]{0} %multiply.277.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %multiply.274.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.119.clone.1.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %param_20.57 = f32[768]{0} parameter(20)
  %multiply.276.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.538.clone.1.clone.1, f32[768]{0} %multiply.538.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %subtract.109.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.276.clone.1.clone.1, f32[768]{0} %param_20.57), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %multiply.275.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.109.clone.1.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %add.118.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_20.57, f32[768]{0} %multiply.275.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %sqrt.35.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.118.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %add.117.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.35.clone.1, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %divide.37.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.274.clone.1, f32[768]{0} %add.117.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %subtract.108.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_19.70, f32[768]{0} %divide.37.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_19/update_0/ResourceApplyAdam"}
  %param_23.71 = f32[768]{0} parameter(23)
  %param_26.23 = f32[768]{0} parameter(26)
  %param_25.20 = f32[768]{0} parameter(25)
  %multiply.540.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_25.20, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_21"}
  %subtract.113.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.540.clone.1.clone.1, f32[768]{0} %param_26.23), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %multiply.282.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.113.clone.1.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %add.122.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_26.23, f32[768]{0} %multiply.282.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %multiply.279.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.122.clone.1.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %param_24.59 = f32[768]{0} parameter(24)
  %multiply.281.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.540.clone.1.clone.1, f32[768]{0} %multiply.540.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %subtract.112.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.281.clone.1.clone.1, f32[768]{0} %param_24.59), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %multiply.280.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.112.clone.1.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %add.121.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_24.59, f32[768]{0} %multiply.280.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %sqrt.36.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.121.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %add.120.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.36.clone.1, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %divide.38.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.279.clone.1, f32[768]{0} %add.120.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %subtract.111.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_23.71, f32[768]{0} %divide.38.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_20/update_0/ResourceApplyAdam"}
  %param_27.64 = f32[768]{0} parameter(27)
  %param_30.9 = f32[768]{0} parameter(30)
  %param_29.9 = f32[768]{0} parameter(29)
  %convert.655.clone.1.clone.1 = f16[768]{0} convert(f32[768]{0} %param_29.9), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Sum"}
  %convert.654.clone.1.clone.1 = f32[768]{0} convert(f16[768]{0} %convert.655.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Cast/Cast"}
  %multiply.1285.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %convert.654.clone.1.clone.1, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_19"}
  %subtract.119.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.1285.clone.1.clone.1, f32[768]{0} %param_30.9), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %multiply.292.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.119.clone.1.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %add.128.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_30.9, f32[768]{0} %multiply.292.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %multiply.288.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.128.clone.1.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %param_28.49 = f32[768]{0} parameter(28)
  %multiply.291.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.1285.clone.1.clone.1, f32[768]{0} %multiply.1285.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %subtract.118.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.291.clone.1.clone.1, f32[768]{0} %param_28.49), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %multiply.290.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.118.clone.1.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %add.127.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_28.49, f32[768]{0} %multiply.290.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %sqrt.38.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.127.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %add.126.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.38.clone.1, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %divide.40.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.288.clone.1, f32[768]{0} %add.126.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %subtract.117.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_27.64, f32[768]{0} %divide.40.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_18/update_0/ResourceApplyAdam"}
  %param_31.33 = f32[768]{0} parameter(31)
  %param_33.10 = f32[768]{0} parameter(33)
  %param_34.14 = f16[16,768]{1,0} parameter(34)
  %convert.102.clone.1.clone.1 = f32[16,768]{1,0} convert(f16[16,768]{1,0} %param_34.14), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd/BiasAddGrad"}
  %constant_324_clone_1_clone_1 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.75.clone.1.clone.1 = f32[768]{0} reduce(f32[16,768]{1,0} %convert.102.clone.1.clone.1, f32[] %constant_324_clone_1_clone_1), dimensions={0}, to_apply=%add_float_.875, metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd/BiasAddGrad"}
  %convert.101.clone.1.clone.1 = f16[768]{0} convert(f32[768]{0} %reduce.75.clone.1.clone.1), metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd/BiasAddGrad"}
  %convert.100.clone.1.clone.1 = f32[768]{0} convert(f16[768]{0} %convert.101.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd/Cast/Cast"}
  %multiply.332.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %convert.100.clone.1.clone.1, f32[768]{0} %broadcast.2032.clone.1), metadata={op_type="Mul" op_name="mul_39"}
  %subtract.134.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.332.clone.1.clone.1, f32[768]{0} %param_33.10), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %multiply.331.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.134.clone.1.clone.1, f32[768]{0} %broadcast.455.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %add.145.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_33.10, f32[768]{0} %multiply.331.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %multiply.328.clone.1 = f32[768]{0} multiply(f32[768]{0} %add.145.clone.1.clone.1, f32[768]{0} %broadcast.453), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %param_32.29 = f32[768]{0} parameter(32)
  %multiply.330.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.332.clone.1.clone.1, f32[768]{0} %multiply.332.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %subtract.133.clone.1.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.330.clone.1.clone.1, f32[768]{0} %param_32.29), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %multiply.329.clone.1.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.133.clone.1.clone.1, f32[768]{0} %broadcast.456.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %add.144.clone.1.clone.1 = f32[768]{0} add(f32[768]{0} %param_32.29, f32[768]{0} %multiply.329.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %sqrt.43.clone.1 = f32[768]{0} sqrt(f32[768]{0} %add.144.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %add.143.clone.1 = f32[768]{0} add(f32[768]{0} %sqrt.43.clone.1, f32[768]{0} %broadcast.454), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %divide.45.clone.1 = f32[768]{0} divide(f32[768]{0} %multiply.328.clone.1, f32[768]{0} %add.143.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  %subtract.132.clone.1 = f32[768]{0} subtract(f32[768]{0} %param_31.33, f32[768]{0} %divide.45.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_38/update_0/ResourceApplyAdam"}
  ROOT %tuple.121 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %subtract.69, f32[768]{0} %add.80.clone.1, f32[768]{0} %add.79.clone.1, f32[768]{0} %subtract.78.clone.1, f32[768]{0} %add.89.clone.1.clone.1, f32[768]{0} %add.88.clone.1.clone.1, f32[768]{0} %subtract.81.clone.1, f32[768]{0} %add.92.clone.1.clone.1, f32[768]{0} %add.91.clone.1.clone.1, f32[768]{0} %subtract.105.clone.1, f32[768]{0} %add.116.clone.1.clone.1, f32[768]{0} %add.115.clone.1.clone.1, f32[768]{0} %subtract.108.clone.1, f32[768]{0} %add.119.clone.1.clone.1, f32[768]{0} %add.118.clone.1.clone.1, f32[768]{0} %subtract.111.clone.1, f32[768]{0} %add.122.clone.1.clone.1, f32[768]{0} %add.121.clone.1.clone.1, f32[768]{0} %subtract.117.clone.1, f32[768]{0} %add.128.clone.1.clone.1, f32[768]{0} %add.127.clone.1.clone.1, f32[768]{0} %subtract.132.clone.1, f32[768]{0} %add.145.clone.1.clone.1, f32[768]{0} %add.144.clone.1.clone.1)
}

%fused_computation.120 (param_0.179: f16[16,512,3072]) -> f16[3072,8192] {
  %param_0.179 = f16[16,512,3072]{2,1,0} parameter(0)
  %transpose.129 = f16[3072,16,512]{0,2,1} transpose(f16[16,512,3072]{2,1,0} %param_0.179), dimensions={2,0,1}
  ROOT %bitcast.164 = f16[3072,8192]{0,1} bitcast(f16[3072,16,512]{0,2,1} %transpose.129)
}

%fused_computation.138 (param_0.207: f16[16,12,64,512]) -> f16[768,8192] {
  %param_0.207 = f16[16,12,64,512]{3,2,1,0} parameter(0)
  %transpose.131 = f16[12,64,16,512]{3,1,0,2} transpose(f16[16,12,64,512]{3,2,1,0} %param_0.207), dimensions={1,2,0,3}
  %copy.90 = f16[12,64,16,512]{3,2,1,0} copy(f16[12,64,16,512]{3,1,0,2} %transpose.131)
  ROOT %bitcast.169 = f16[768,8192]{1,0} bitcast(f16[12,64,16,512]{3,2,1,0} %copy.90)
}

%fused_computation.148 (param_0.225: f16[16,12,512,64]) -> f16[768,8192] {
  %param_0.225 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.133 = f16[12,64,16,512]{1,3,0,2} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.225), dimensions={1,3,0,2}
  %copy.92 = f16[12,64,16,512]{3,2,1,0} copy(f16[12,64,16,512]{1,3,0,2} %transpose.133)
  ROOT %bitcast.172 = f16[768,8192]{1,0} bitcast(f16[12,64,16,512]{3,2,1,0} %copy.92)
}

%fused_computation.154 (param_0.233: f32[768,12,64], param_1.1699: f32[], param_2.1798: f32[768,12,64], param_3.1186: f32[], param_4.835: f16[768,768], param_5.725: f32[768,12,64], param_6.636: f32[], param_7.768: f32[768,12,64], param_8.431: f32[768,12,64], param_9.277: f16[768,768], param_10.191: f32[768,12,64], param_11.221: f32[768,12,64], param_12.160: f32[768,12,64], param_13.40: f16[768,768], param_14.26: f32[768,12,64], param_15.47: f32[768,12,64], param_16.37: f32[768,12,64], param_17.14: f16[768,768], param_18.13: f32[768,12,64], param_19.36: f32[768,12,64], param_20.27: f32[768,12,64], param_21.9: f16[768,768], param_22.9: f32[768,12,64], param_23.39: f32[768,12,64], param_24.31: f32[768,12,64], param_25.10: f16[768,768], param_26.13: f32[768,12,64]) -> (f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64]) {
  %param_0.233 = f32[768,12,64]{2,1,0} parameter(0)
  %param_2.1798 = f32[768,12,64]{2,1,0} parameter(2)
  %param_4.835 = f16[768,768]{1,0} parameter(4)
  %convert.680.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_4.835), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/einsum/Einsum/Cast/Cast"}
  %constant_1391_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.2003.clone.1 = f32[768,768]{1,0} broadcast(f32[] %constant_1391_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_38"}
  %multiply.1304.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.680.clone.1, f32[768,768]{1,0} %broadcast.2003.clone.1), metadata={op_type="Mul" op_name="mul_8"}
  %copy.147.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1304.clone.1), metadata={op_type="Mul" op_name="mul_8"}
  %bitcast.416.clone.1 = f32[12,64,768]{1,0,2} bitcast(f32[768,768]{0,1} %copy.147.clone.1), metadata={op_type="Mul" op_name="mul_8"}
  %transpose.185.clone.1 = f32[768,12,64]{2,1,0} transpose(f32[12,64,768]{1,0,2} %bitcast.416.clone.1), dimensions={2,0,1}, metadata={op_type="Mul" op_name="mul_8"}
  %subtract.98.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %transpose.185.clone.1, f32[768,12,64]{2,1,0} %param_2.1798), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %constant_244_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1186 = f32[] parameter(3)
  %subtract.228.clone.1 = f32[] subtract(f32[] %constant_244_clone_1, f32[] %param_3.1186), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.517.clone.1 = f32[768,12,64]{2,1,0} broadcast(f32[] %subtract.228.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %multiply.255.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.98.clone.1, f32[768,12,64]{2,1,0} %broadcast.517.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %add.107.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_2.1798, f32[768,12,64]{2,1,0} %multiply.255.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %param_1.1699 = f32[] parameter(1)
  %broadcast.514 = f32[768,12,64]{2,1,0} broadcast(f32[] %param_1.1699), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %multiply.251 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %add.107.clone.1, f32[768,12,64]{2,1,0} %broadcast.514), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %param_5.725 = f32[768,12,64]{2,1,0} parameter(5)
  %multiply.254.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %transpose.185.clone.1, f32[768,12,64]{2,1,0} %transpose.185.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %subtract.97.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %multiply.254.clone.1, f32[768,12,64]{2,1,0} %param_5.725), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %param_6.636 = f32[] parameter(6)
  %subtract.229.clone.1 = f32[] subtract(f32[] %constant_244_clone_1, f32[] %param_6.636), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.518.clone.1 = f32[768,12,64]{2,1,0} broadcast(f32[] %subtract.229.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %multiply.253.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.97.clone.1, f32[768,12,64]{2,1,0} %broadcast.518.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %add.106.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_5.725, f32[768,12,64]{2,1,0} %multiply.253.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %sqrt.31 = f32[768,12,64]{2,1,0} sqrt(f32[768,12,64]{2,1,0} %add.106.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %constant_243 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.516 = f32[768,12,64]{2,1,0} broadcast(f32[] %constant_243), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %add.105 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %sqrt.31, f32[768,12,64]{2,1,0} %broadcast.516), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %divide.33 = f32[768,12,64]{2,1,0} divide(f32[768,12,64]{2,1,0} %multiply.251, f32[768,12,64]{2,1,0} %add.105), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %subtract.96 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %param_0.233, f32[768,12,64]{2,1,0} %divide.33), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %param_7.768 = f32[768,12,64]{2,1,0} parameter(7)
  %param_10.191 = f32[768,12,64]{2,1,0} parameter(10)
  %param_9.277 = f16[768,768]{1,0} parameter(9)
  %convert.776.clone.1.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_9.277), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/einsum/Einsum/Cast/Cast"}
  %multiply.1368.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.776.clone.1.clone.1, f32[768,768]{1,0} %broadcast.2003.clone.1), metadata={op_type="Mul" op_name="mul_26"}
  %copy.171.clone.1.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1368.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_26"}
  %bitcast.450.clone.1.clone.1 = f32[12,64,768]{1,0,2} bitcast(f32[768,768]{0,1} %copy.171.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_26"}
  %transpose.219.clone.1.clone.1 = f32[768,12,64]{2,1,0} transpose(f32[12,64,768]{1,0,2} %bitcast.450.clone.1.clone.1), dimensions={2,0,1}, metadata={op_type="Mul" op_name="mul_26"}
  %subtract.38.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %transpose.219.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_10.191), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %multiply.153.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.38.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.517.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %add.47.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_10.191, f32[768,12,64]{2,1,0} %multiply.153.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %multiply.150.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %add.47.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.514), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %param_8.431 = f32[768,12,64]{2,1,0} parameter(8)
  %multiply.152.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %transpose.219.clone.1.clone.1, f32[768,12,64]{2,1,0} %transpose.219.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %subtract.37.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %multiply.152.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_8.431), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %multiply.151.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.37.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.518.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %add.46.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_8.431, f32[768,12,64]{2,1,0} %multiply.151.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %sqrt.11.clone.1 = f32[768,12,64]{2,1,0} sqrt(f32[768,12,64]{2,1,0} %add.46.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %add.45.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %sqrt.11.clone.1, f32[768,12,64]{2,1,0} %broadcast.516), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %divide.13.clone.1 = f32[768,12,64]{2,1,0} divide(f32[768,12,64]{2,1,0} %multiply.150.clone.1, f32[768,12,64]{2,1,0} %add.45.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %subtract.36.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %param_7.768, f32[768,12,64]{2,1,0} %divide.13.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_25/update_0/ResourceApplyAdam"}
  %param_11.221 = f32[768,12,64]{2,1,0} parameter(11)
  %param_14.26 = f32[768,12,64]{2,1,0} parameter(14)
  %param_13.40 = f16[768,768]{1,0} parameter(13)
  %convert.761.clone.1.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_13.40), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/einsum/Einsum/Cast/Cast"}
  %multiply.1359.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.761.clone.1.clone.1, f32[768,768]{1,0} %broadcast.2003.clone.1), metadata={op_type="Mul" op_name="mul_22"}
  %copy.167.clone.1.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1359.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_22"}
  %bitcast.444.clone.1.clone.1 = f32[12,64,768]{1,0,2} bitcast(f32[768,768]{0,1} %copy.167.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_22"}
  %transpose.213.clone.1.clone.1 = f32[768,12,64]{2,1,0} transpose(f32[12,64,768]{1,0,2} %bitcast.444.clone.1.clone.1), dimensions={2,0,1}, metadata={op_type="Mul" op_name="mul_22"}
  %subtract.44.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %transpose.213.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_14.26), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %multiply.163.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.44.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.517.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %add.53.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_14.26, f32[768,12,64]{2,1,0} %multiply.163.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %multiply.160.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %add.53.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.514), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %param_12.160 = f32[768,12,64]{2,1,0} parameter(12)
  %multiply.162.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %transpose.213.clone.1.clone.1, f32[768,12,64]{2,1,0} %transpose.213.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %subtract.43.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %multiply.162.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_12.160), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %multiply.161.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.43.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.518.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %add.52.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_12.160, f32[768,12,64]{2,1,0} %multiply.161.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %sqrt.13.clone.1 = f32[768,12,64]{2,1,0} sqrt(f32[768,12,64]{2,1,0} %add.52.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %add.51.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %sqrt.13.clone.1, f32[768,12,64]{2,1,0} %broadcast.516), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %divide.15.clone.1 = f32[768,12,64]{2,1,0} divide(f32[768,12,64]{2,1,0} %multiply.160.clone.1, f32[768,12,64]{2,1,0} %add.51.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %subtract.42.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %param_11.221, f32[768,12,64]{2,1,0} %divide.15.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_21/update_0/ResourceApplyAdam"}
  %param_15.47 = f32[768,12,64]{2,1,0} parameter(15)
  %param_18.13 = f32[768,12,64]{2,1,0} parameter(18)
  %param_17.14 = f16[768,768]{1,0} parameter(17)
  %convert.752.clone.1.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_17.14), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/einsum/Einsum/Cast/Cast"}
  %multiply.1355.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.752.clone.1.clone.1, f32[768,768]{1,0} %broadcast.2003.clone.1), metadata={op_type="Mul" op_name="mul_24"}
  %copy.163.clone.1.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1355.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_24"}
  %bitcast.438.clone.1.clone.1 = f32[12,64,768]{1,0,2} bitcast(f32[768,768]{0,1} %copy.163.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_24"}
  %transpose.207.clone.1.clone.1 = f32[768,12,64]{2,1,0} transpose(f32[12,64,768]{1,0,2} %bitcast.438.clone.1.clone.1), dimensions={2,0,1}, metadata={op_type="Mul" op_name="mul_24"}
  %subtract.50.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %transpose.207.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_18.13), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %multiply.173.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.50.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.517.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %add.59.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_18.13, f32[768,12,64]{2,1,0} %multiply.173.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %multiply.170.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %add.59.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.514), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %param_16.37 = f32[768,12,64]{2,1,0} parameter(16)
  %multiply.172.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %transpose.207.clone.1.clone.1, f32[768,12,64]{2,1,0} %transpose.207.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %subtract.49.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %multiply.172.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_16.37), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %multiply.171.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.49.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.518.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %add.58.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_16.37, f32[768,12,64]{2,1,0} %multiply.171.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %sqrt.15.clone.1 = f32[768,12,64]{2,1,0} sqrt(f32[768,12,64]{2,1,0} %add.58.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %add.57.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %sqrt.15.clone.1, f32[768,12,64]{2,1,0} %broadcast.516), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %divide.17.clone.1 = f32[768,12,64]{2,1,0} divide(f32[768,12,64]{2,1,0} %multiply.170.clone.1, f32[768,12,64]{2,1,0} %add.57.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %subtract.48.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %param_15.47, f32[768,12,64]{2,1,0} %divide.17.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_23/update_0/ResourceApplyAdam"}
  %param_19.36 = f32[768,12,64]{2,1,0} parameter(19)
  %param_22.9 = f32[768,12,64]{2,1,0} parameter(22)
  %param_21.9 = f16[768,768]{1,0} parameter(21)
  %convert.701.clone.1.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_21.9), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/einsum/Einsum/Cast/Cast"}
  %multiply.1321.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.701.clone.1.clone.1, f32[768,768]{1,0} %broadcast.2003.clone.1), metadata={op_type="Mul" op_name="mul_10"}
  %copy.155.clone.1.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1321.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_10"}
  %bitcast.428.clone.1.clone.1 = f32[12,64,768]{1,0,2} bitcast(f32[768,768]{0,1} %copy.155.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_10"}
  %transpose.197.clone.1.clone.1 = f32[768,12,64]{2,1,0} transpose(f32[12,64,768]{1,0,2} %bitcast.428.clone.1.clone.1), dimensions={2,0,1}, metadata={op_type="Mul" op_name="mul_10"}
  %subtract.86.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %transpose.197.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_22.9), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %multiply.233.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.86.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.517.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %add.95.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_22.9, f32[768,12,64]{2,1,0} %multiply.233.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %multiply.230.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %add.95.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.514), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %param_20.27 = f32[768,12,64]{2,1,0} parameter(20)
  %multiply.232.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %transpose.197.clone.1.clone.1, f32[768,12,64]{2,1,0} %transpose.197.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %subtract.85.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %multiply.232.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_20.27), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %multiply.231.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.85.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.518.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %add.94.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_20.27, f32[768,12,64]{2,1,0} %multiply.231.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %sqrt.27.clone.1 = f32[768,12,64]{2,1,0} sqrt(f32[768,12,64]{2,1,0} %add.94.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %add.93.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %sqrt.27.clone.1, f32[768,12,64]{2,1,0} %broadcast.516), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %divide.29.clone.1 = f32[768,12,64]{2,1,0} divide(f32[768,12,64]{2,1,0} %multiply.230.clone.1, f32[768,12,64]{2,1,0} %add.93.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %subtract.84.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %param_19.36, f32[768,12,64]{2,1,0} %divide.29.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_9/update_0/ResourceApplyAdam"}
  %param_23.39 = f32[768,12,64]{2,1,0} parameter(23)
  %param_26.13 = f32[768,12,64]{2,1,0} parameter(26)
  %param_25.10 = f16[768,768]{1,0} parameter(25)
  %convert.686.clone.1.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_25.10), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/einsum/Einsum/Cast/Cast"}
  %multiply.1308.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.686.clone.1.clone.1, f32[768,768]{1,0} %broadcast.2003.clone.1), metadata={op_type="Mul" op_name="mul_6"}
  %copy.151.clone.1.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1308.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_6"}
  %bitcast.422.clone.1.clone.1 = f32[12,64,768]{1,0,2} bitcast(f32[768,768]{0,1} %copy.151.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_6"}
  %transpose.191.clone.1.clone.1 = f32[768,12,64]{2,1,0} transpose(f32[12,64,768]{1,0,2} %bitcast.422.clone.1.clone.1), dimensions={2,0,1}, metadata={op_type="Mul" op_name="mul_6"}
  %subtract.92.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %transpose.191.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_26.13), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %multiply.244.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.92.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.517.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %add.101.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_26.13, f32[768,12,64]{2,1,0} %multiply.244.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %multiply.240.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %add.101.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.514), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %param_24.31 = f32[768,12,64]{2,1,0} parameter(24)
  %multiply.243.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %transpose.191.clone.1.clone.1, f32[768,12,64]{2,1,0} %transpose.191.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %subtract.91.clone.1.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %multiply.243.clone.1.clone.1, f32[768,12,64]{2,1,0} %param_24.31), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %multiply.242.clone.1.clone.1 = f32[768,12,64]{2,1,0} multiply(f32[768,12,64]{2,1,0} %subtract.91.clone.1.clone.1, f32[768,12,64]{2,1,0} %broadcast.518.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %add.100.clone.1.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %param_24.31, f32[768,12,64]{2,1,0} %multiply.242.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %sqrt.29.clone.1 = f32[768,12,64]{2,1,0} sqrt(f32[768,12,64]{2,1,0} %add.100.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %add.99.clone.1 = f32[768,12,64]{2,1,0} add(f32[768,12,64]{2,1,0} %sqrt.29.clone.1, f32[768,12,64]{2,1,0} %broadcast.516), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %divide.31.clone.1 = f32[768,12,64]{2,1,0} divide(f32[768,12,64]{2,1,0} %multiply.240.clone.1, f32[768,12,64]{2,1,0} %add.99.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  %subtract.90.clone.1 = f32[768,12,64]{2,1,0} subtract(f32[768,12,64]{2,1,0} %param_23.39, f32[768,12,64]{2,1,0} %divide.31.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_5/update_0/ResourceApplyAdam"}
  ROOT %tuple.106 = (f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) tuple(f32[768,12,64]{2,1,0} %subtract.96, f32[768,12,64]{2,1,0} %add.107.clone.1, f32[768,12,64]{2,1,0} %add.106.clone.1, f32[768,12,64]{2,1,0} %subtract.36.clone.1, f32[768,12,64]{2,1,0} %add.47.clone.1.clone.1, f32[768,12,64]{2,1,0} %add.46.clone.1.clone.1, f32[768,12,64]{2,1,0} %subtract.42.clone.1, f32[768,12,64]{2,1,0} %add.53.clone.1.clone.1, f32[768,12,64]{2,1,0} %add.52.clone.1.clone.1, f32[768,12,64]{2,1,0} %subtract.48.clone.1, f32[768,12,64]{2,1,0} %add.59.clone.1.clone.1, f32[768,12,64]{2,1,0} %add.58.clone.1.clone.1, f32[768,12,64]{2,1,0} %subtract.84.clone.1, f32[768,12,64]{2,1,0} %add.95.clone.1.clone.1, f32[768,12,64]{2,1,0} %add.94.clone.1.clone.1, f32[768,12,64]{2,1,0} %subtract.90.clone.1, f32[768,12,64]{2,1,0} %add.101.clone.1.clone.1, f32[768,12,64]{2,1,0} %add.100.clone.1.clone.1)
}

%fused_computation.158 (param_0.243: f16[16,12,512,64]) -> f16[768,8192] {
  %param_0.243 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.135 = f16[12,64,16,512]{1,3,0,2} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.243), dimensions={1,3,0,2}
  %copy.94 = f16[12,64,16,512]{3,2,1,0} copy(f16[12,64,16,512]{1,3,0,2} %transpose.135)
  ROOT %bitcast.175 = f16[768,8192]{1,0} bitcast(f16[12,64,16,512]{3,2,1,0} %copy.94)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_key_add_Sum-reduction.1628 (x.1629: f32[], y.1630: f32[]) -> f32[] {
  %x.1629 = f32[] parameter(0)
  %y.1630 = f32[] parameter(1)
  ROOT %add.1631 = f32[] add(f32[] %x.1629, f32[] %y.1630)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_query_add_Sum-reduction.1390 (x.1391: f32[], y.1392: f32[]) -> f32[] {
  %x.1391 = f32[] parameter(0)
  %y.1392 = f32[] parameter(1)
  ROOT %add.1393 = f32[] add(f32[] %x.1391, f32[] %y.1392)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_key_add_Sum-reduction.1370 (x.1371: f32[], y.1372: f32[]) -> f32[] {
  %x.1371 = f32[] parameter(0)
  %y.1372 = f32[] parameter(1)
  ROOT %add.1373 = f32[] add(f32[] %x.1371, f32[] %y.1372)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_query_add_Sum-reduction.1648 (x.1649: f32[], y.1650: f32[]) -> f32[] {
  %x.1649 = f32[] parameter(0)
  %y.1650 = f32[] parameter(1)
  ROOT %add.1651 = f32[] add(f32[] %x.1649, f32[] %y.1650)
}

%fused_computation.159 (param_0.244: f32[12,64], param_1.1700: f32[], param_2.1800: f32[12,64], param_3.1188: f32[], param_4.840: f32[12,64], param_5.732: f32[], param_6.644: f32[16,12,64], param_7.765: f32[12,64], param_8.427: f32[12,64], param_9.272: f32[12,64], param_10.186: f32[12,64], param_11.199: f32[12,64], param_12.144: f32[12,64], param_13.35: f32[12,64], param_14.21: f32[16,12,64], param_15.25: f32[12,64], param_16.21: f32[12,64], param_17.9: f32[12,64], param_18.8: f32[16,12,64], param_19.14: f32[12,64], param_20.11: f32[12,64], param_21.4: f32[12,64], param_22.4: f32[12,64], param_23.17: f32[12,64], param_24.15: f32[12,64], param_25.5: f32[12,64], param_26.8: f32[16,12,64]) -> (f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64], f32[12,64]) {
  %param_0.244 = f32[12,64]{1,0} parameter(0)
  %param_2.1800 = f32[12,64]{1,0} parameter(2)
  %param_6.644 = f32[16,12,64]{2,1,0} parameter(6)
  %constant_254_clone_1 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.66.clone.1 = f32[12,64]{1,0} reduce(f32[16,12,64]{2,1,0} %param_6.644, f32[] %constant_254_clone_1), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_key_add_Sum-reduction.1628, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Sum"}
  %convert.79.clone.1 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %reduce.66.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Sum"}
  %convert.78.clone.1 = f32[12,64]{1,0} convert(f16[12,64]{1,0} %convert.79.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Cast/Cast"}
  %constant_252_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.525.clone.1 = f32[12,64]{1,0} broadcast(f32[] %constant_252_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_9"}
  %multiply.262.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %convert.78.clone.1, f32[12,64]{1,0} %broadcast.525.clone.1), metadata={op_type="Mul" op_name="mul_9"}
  %subtract.101.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.262.clone.1, f32[12,64]{1,0} %param_2.1800), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %constant_249_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1188 = f32[] parameter(3)
  %subtract.230.clone.1 = f32[] subtract(f32[] %constant_249_clone_1, f32[] %param_3.1188), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.523.clone.1 = f32[12,64]{1,0} broadcast(f32[] %subtract.230.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %multiply.261.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.101.clone.1, f32[12,64]{1,0} %broadcast.523.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %add.110.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_2.1800, f32[12,64]{1,0} %multiply.261.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %param_1.1700 = f32[] parameter(1)
  %broadcast.520 = f32[12,64]{1,0} broadcast(f32[] %param_1.1700), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %multiply.257 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %add.110.clone.1, f32[12,64]{1,0} %broadcast.520), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %param_4.840 = f32[12,64]{1,0} parameter(4)
  %multiply.260.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %multiply.262.clone.1, f32[12,64]{1,0} %multiply.262.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %subtract.100.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.260.clone.1, f32[12,64]{1,0} %param_4.840), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %param_5.732 = f32[] parameter(5)
  %subtract.231.clone.1 = f32[] subtract(f32[] %constant_249_clone_1, f32[] %param_5.732), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.524.clone.1 = f32[12,64]{1,0} broadcast(f32[] %subtract.231.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %multiply.258.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.100.clone.1, f32[12,64]{1,0} %broadcast.524.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %add.109.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_4.840, f32[12,64]{1,0} %multiply.258.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %sqrt.32 = f32[12,64]{1,0} sqrt(f32[12,64]{1,0} %add.109.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %constant_248 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.522 = f32[12,64]{1,0} broadcast(f32[] %constant_248), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %add.108 = f32[12,64]{1,0} add(f32[12,64]{1,0} %sqrt.32, f32[12,64]{1,0} %broadcast.522), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %divide.34 = f32[12,64]{1,0} divide(f32[12,64]{1,0} %multiply.257, f32[12,64]{1,0} %add.108), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %subtract.99 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %param_0.244, f32[12,64]{1,0} %divide.34), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %param_7.765 = f32[12,64]{1,0} parameter(7)
  %param_10.186 = f32[12,64]{1,0} parameter(10)
  %param_9.272 = f32[12,64]{1,0} parameter(9)
  %convert.770.clone.1.clone.1 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_9.272), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add/Sum"}
  %convert.769.clone.1.clone.1 = f32[12,64]{1,0} convert(f16[12,64]{1,0} %convert.770.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add/Cast/Cast"}
  %multiply.1363.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %convert.769.clone.1.clone.1, f32[12,64]{1,0} %broadcast.525.clone.1), metadata={op_type="Mul" op_name="mul_27"}
  %subtract.41.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.1363.clone.1.clone.1, f32[12,64]{1,0} %param_10.186), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %multiply.158.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.41.clone.1.clone.1, f32[12,64]{1,0} %broadcast.523.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %add.50.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_10.186, f32[12,64]{1,0} %multiply.158.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %multiply.155.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %add.50.clone.1.clone.1, f32[12,64]{1,0} %broadcast.520), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %param_8.427 = f32[12,64]{1,0} parameter(8)
  %multiply.157.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %multiply.1363.clone.1.clone.1, f32[12,64]{1,0} %multiply.1363.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %subtract.40.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.157.clone.1.clone.1, f32[12,64]{1,0} %param_8.427), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %multiply.156.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.40.clone.1.clone.1, f32[12,64]{1,0} %broadcast.524.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %add.49.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_8.427, f32[12,64]{1,0} %multiply.156.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %sqrt.12.clone.1 = f32[12,64]{1,0} sqrt(f32[12,64]{1,0} %add.49.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %add.48.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %sqrt.12.clone.1, f32[12,64]{1,0} %broadcast.522), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %divide.14.clone.1 = f32[12,64]{1,0} divide(f32[12,64]{1,0} %multiply.155.clone.1, f32[12,64]{1,0} %add.48.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %subtract.39.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %param_7.765, f32[12,64]{1,0} %divide.14.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_26/update_0/ResourceApplyAdam"}
  %param_11.199 = f32[12,64]{1,0} parameter(11)
  %param_13.35 = f32[12,64]{1,0} parameter(13)
  %param_14.21 = f32[16,12,64]{2,1,0} parameter(14)
  %reduce.56.clone.1.clone.1 = f32[12,64]{1,0} reduce(f32[16,12,64]{2,1,0} %param_14.21, f32[] %constant_254_clone_1), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_query_add_Sum-reduction.1390, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Sum"}
  %convert.51.clone.1.clone.1 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %reduce.56.clone.1.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Sum"}
  %convert.50.clone.1.clone.1 = f32[12,64]{1,0} convert(f16[12,64]{1,0} %convert.51.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Cast/Cast"}
  %multiply.169.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %convert.50.clone.1.clone.1, f32[12,64]{1,0} %broadcast.525.clone.1), metadata={op_type="Mul" op_name="mul_23"}
  %subtract.47.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.169.clone.1.clone.1, f32[12,64]{1,0} %param_13.35), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %multiply.168.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.47.clone.1.clone.1, f32[12,64]{1,0} %broadcast.523.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %add.56.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_13.35, f32[12,64]{1,0} %multiply.168.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %multiply.165.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %add.56.clone.1.clone.1, f32[12,64]{1,0} %broadcast.520), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %param_12.144 = f32[12,64]{1,0} parameter(12)
  %multiply.167.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %multiply.169.clone.1.clone.1, f32[12,64]{1,0} %multiply.169.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %subtract.46.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.167.clone.1.clone.1, f32[12,64]{1,0} %param_12.144), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %multiply.166.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.46.clone.1.clone.1, f32[12,64]{1,0} %broadcast.524.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %add.55.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_12.144, f32[12,64]{1,0} %multiply.166.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %sqrt.14.clone.1 = f32[12,64]{1,0} sqrt(f32[12,64]{1,0} %add.55.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %add.54.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %sqrt.14.clone.1, f32[12,64]{1,0} %broadcast.522), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %divide.16.clone.1 = f32[12,64]{1,0} divide(f32[12,64]{1,0} %multiply.165.clone.1, f32[12,64]{1,0} %add.54.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %subtract.45.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %param_11.199, f32[12,64]{1,0} %divide.16.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_22/update_0/ResourceApplyAdam"}
  %param_15.25 = f32[12,64]{1,0} parameter(15)
  %param_17.9 = f32[12,64]{1,0} parameter(17)
  %param_18.8 = f32[16,12,64]{2,1,0} parameter(18)
  %reduce.57.clone.1.clone.1 = f32[12,64]{1,0} reduce(f32[16,12,64]{2,1,0} %param_18.8, f32[] %constant_254_clone_1), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_key_add_Sum-reduction.1370, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add/Sum"}
  %convert.55.clone.1.clone.1 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %reduce.57.clone.1.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add/Sum"}
  %convert.54.clone.1.clone.1 = f32[12,64]{1,0} convert(f16[12,64]{1,0} %convert.55.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add/Cast/Cast"}
  %multiply.179.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %convert.54.clone.1.clone.1, f32[12,64]{1,0} %broadcast.525.clone.1), metadata={op_type="Mul" op_name="mul_25"}
  %subtract.53.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.179.clone.1.clone.1, f32[12,64]{1,0} %param_17.9), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %multiply.178.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.53.clone.1.clone.1, f32[12,64]{1,0} %broadcast.523.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %add.62.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_17.9, f32[12,64]{1,0} %multiply.178.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %multiply.175.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %add.62.clone.1.clone.1, f32[12,64]{1,0} %broadcast.520), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %param_16.21 = f32[12,64]{1,0} parameter(16)
  %multiply.177.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %multiply.179.clone.1.clone.1, f32[12,64]{1,0} %multiply.179.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %subtract.52.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.177.clone.1.clone.1, f32[12,64]{1,0} %param_16.21), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %multiply.176.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.52.clone.1.clone.1, f32[12,64]{1,0} %broadcast.524.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %add.61.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_16.21, f32[12,64]{1,0} %multiply.176.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %sqrt.16.clone.1 = f32[12,64]{1,0} sqrt(f32[12,64]{1,0} %add.61.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %add.60.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %sqrt.16.clone.1, f32[12,64]{1,0} %broadcast.522), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %divide.18.clone.1 = f32[12,64]{1,0} divide(f32[12,64]{1,0} %multiply.175.clone.1, f32[12,64]{1,0} %add.60.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %subtract.51.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %param_15.25, f32[12,64]{1,0} %divide.18.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_24/update_0/ResourceApplyAdam"}
  %param_19.14 = f32[12,64]{1,0} parameter(19)
  %param_22.4 = f32[12,64]{1,0} parameter(22)
  %param_21.4 = f32[12,64]{1,0} parameter(21)
  %convert.694.clone.1.clone.1 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_21.4), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Sum"}
  %convert.693.clone.1.clone.1 = f32[12,64]{1,0} convert(f16[12,64]{1,0} %convert.694.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Cast/Cast"}
  %multiply.1315.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %convert.693.clone.1.clone.1, f32[12,64]{1,0} %broadcast.525.clone.1), metadata={op_type="Mul" op_name="mul_11"}
  %subtract.89.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.1315.clone.1.clone.1, f32[12,64]{1,0} %param_22.4), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %multiply.238.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.89.clone.1.clone.1, f32[12,64]{1,0} %broadcast.523.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %add.98.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_22.4, f32[12,64]{1,0} %multiply.238.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %multiply.235.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %add.98.clone.1.clone.1, f32[12,64]{1,0} %broadcast.520), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %param_20.11 = f32[12,64]{1,0} parameter(20)
  %multiply.237.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %multiply.1315.clone.1.clone.1, f32[12,64]{1,0} %multiply.1315.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %subtract.88.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.237.clone.1.clone.1, f32[12,64]{1,0} %param_20.11), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %multiply.236.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.88.clone.1.clone.1, f32[12,64]{1,0} %broadcast.524.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %add.97.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_20.11, f32[12,64]{1,0} %multiply.236.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %sqrt.28.clone.1 = f32[12,64]{1,0} sqrt(f32[12,64]{1,0} %add.97.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %add.96.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %sqrt.28.clone.1, f32[12,64]{1,0} %broadcast.522), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %divide.30.clone.1 = f32[12,64]{1,0} divide(f32[12,64]{1,0} %multiply.235.clone.1, f32[12,64]{1,0} %add.96.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %subtract.87.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %param_19.14, f32[12,64]{1,0} %divide.30.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_10/update_0/ResourceApplyAdam"}
  %param_23.17 = f32[12,64]{1,0} parameter(23)
  %param_25.5 = f32[12,64]{1,0} parameter(25)
  %param_26.8 = f32[16,12,64]{2,1,0} parameter(26)
  %reduce.65.clone.1.clone.1 = f32[12,64]{1,0} reduce(f32[16,12,64]{2,1,0} %param_26.8, f32[] %constant_254_clone_1), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_query_add_Sum-reduction.1648, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Sum"}
  %convert.75.clone.1.clone.1 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %reduce.65.clone.1.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Sum"}
  %convert.74.clone.1.clone.1 = f32[12,64]{1,0} convert(f16[12,64]{1,0} %convert.75.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Cast/Cast"}
  %multiply.250.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %convert.74.clone.1.clone.1, f32[12,64]{1,0} %broadcast.525.clone.1), metadata={op_type="Mul" op_name="mul_7"}
  %subtract.95.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.250.clone.1.clone.1, f32[12,64]{1,0} %param_25.5), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %multiply.249.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.95.clone.1.clone.1, f32[12,64]{1,0} %broadcast.523.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %add.104.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_25.5, f32[12,64]{1,0} %multiply.249.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %multiply.246.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %add.104.clone.1.clone.1, f32[12,64]{1,0} %broadcast.520), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %param_24.15 = f32[12,64]{1,0} parameter(24)
  %multiply.248.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %multiply.250.clone.1.clone.1, f32[12,64]{1,0} %multiply.250.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %subtract.94.clone.1.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %multiply.248.clone.1.clone.1, f32[12,64]{1,0} %param_24.15), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %multiply.247.clone.1.clone.1 = f32[12,64]{1,0} multiply(f32[12,64]{1,0} %subtract.94.clone.1.clone.1, f32[12,64]{1,0} %broadcast.524.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %add.103.clone.1.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %param_24.15, f32[12,64]{1,0} %multiply.247.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %sqrt.30.clone.1 = f32[12,64]{1,0} sqrt(f32[12,64]{1,0} %add.103.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %add.102.clone.1 = f32[12,64]{1,0} add(f32[12,64]{1,0} %sqrt.30.clone.1, f32[12,64]{1,0} %broadcast.522), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %divide.32.clone.1 = f32[12,64]{1,0} divide(f32[12,64]{1,0} %multiply.246.clone.1, f32[12,64]{1,0} %add.102.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  %subtract.93.clone.1 = f32[12,64]{1,0} subtract(f32[12,64]{1,0} %param_23.17, f32[12,64]{1,0} %divide.32.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_6/update_0/ResourceApplyAdam"}
  ROOT %tuple.101 = (f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) tuple(f32[12,64]{1,0} %subtract.99, f32[12,64]{1,0} %add.110.clone.1, f32[12,64]{1,0} %add.109.clone.1, f32[12,64]{1,0} %subtract.39.clone.1, f32[12,64]{1,0} %add.50.clone.1.clone.1, f32[12,64]{1,0} %add.49.clone.1.clone.1, f32[12,64]{1,0} %subtract.45.clone.1, f32[12,64]{1,0} %add.56.clone.1.clone.1, f32[12,64]{1,0} %add.55.clone.1.clone.1, f32[12,64]{1,0} %subtract.51.clone.1, f32[12,64]{1,0} %add.62.clone.1.clone.1, f32[12,64]{1,0} %add.61.clone.1.clone.1, f32[12,64]{1,0} %subtract.87.clone.1, f32[12,64]{1,0} %add.98.clone.1.clone.1, f32[12,64]{1,0} %add.97.clone.1.clone.1, f32[12,64]{1,0} %subtract.93.clone.1, f32[12,64]{1,0} %add.104.clone.1.clone.1, f32[12,64]{1,0} %add.103.clone.1.clone.1)
}

%fused_computation.164 (param_0.251: f32[12,64,768], param_1.1701: f32[], param_2.1802: f32[12,64,768], param_3.1190: f32[], param_4.844: f16[768,768], param_5.743: f32[12,64,768], param_6.650: f32[], param_7.762: f32[12,64,768], param_8.423: f32[12,64,768], param_9.267: f16[768,768], param_10.181: f32[12,64,768]) -> (f32[12,64,768], f32[12,64,768], f32[12,64,768], f32[12,64,768], f32[12,64,768], f32[12,64,768]) {
  %param_0.251 = f32[12,64,768]{2,1,0} parameter(0)
  %param_2.1802 = f32[12,64,768]{2,1,0} parameter(2)
  %param_4.844 = f16[768,768]{1,0} parameter(4)
  %convert.674.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_4.844), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/einsum/Einsum/Cast/Cast"}
  %constant_1382_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.1999.clone.1 = f32[768,768]{1,0} broadcast(f32[] %constant_1382_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_38"}
  %multiply.1300.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.674.clone.1, f32[768,768]{1,0} %broadcast.1999.clone.1), metadata={op_type="Mul" op_name="mul_12"}
  %copy.143.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1300.clone.1), metadata={op_type="Mul" op_name="mul_12"}
  %bitcast.410.clone.1 = f32[768,12,64]{0,2,1} bitcast(f32[768,768]{0,1} %copy.143.clone.1), metadata={op_type="Mul" op_name="mul_12"}
  %transpose.179.clone.1 = f32[12,64,768]{2,1,0} transpose(f32[768,12,64]{0,2,1} %bitcast.410.clone.1), dimensions={1,2,0}, metadata={op_type="Mul" op_name="mul_12"}
  %subtract.104.clone.1 = f32[12,64,768]{2,1,0} subtract(f32[12,64,768]{2,1,0} %transpose.179.clone.1, f32[12,64,768]{2,1,0} %param_2.1802), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %constant_256_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1190 = f32[] parameter(3)
  %subtract.232.clone.1 = f32[] subtract(f32[] %constant_256_clone_1, f32[] %param_3.1190), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.528.clone.1 = f32[12,64,768]{2,1,0} broadcast(f32[] %subtract.232.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %multiply.266.clone.1 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %subtract.104.clone.1, f32[12,64,768]{2,1,0} %broadcast.528.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %add.113.clone.1 = f32[12,64,768]{2,1,0} add(f32[12,64,768]{2,1,0} %param_2.1802, f32[12,64,768]{2,1,0} %multiply.266.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %param_1.1701 = f32[] parameter(1)
  %broadcast.526 = f32[12,64,768]{2,1,0} broadcast(f32[] %param_1.1701), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %multiply.263 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %add.113.clone.1, f32[12,64,768]{2,1,0} %broadcast.526), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %param_5.743 = f32[12,64,768]{2,1,0} parameter(5)
  %multiply.265.clone.1 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %transpose.179.clone.1, f32[12,64,768]{2,1,0} %transpose.179.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %subtract.103.clone.1 = f32[12,64,768]{2,1,0} subtract(f32[12,64,768]{2,1,0} %multiply.265.clone.1, f32[12,64,768]{2,1,0} %param_5.743), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %param_6.650 = f32[] parameter(6)
  %subtract.233.clone.1 = f32[] subtract(f32[] %constant_256_clone_1, f32[] %param_6.650), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.529.clone.1 = f32[12,64,768]{2,1,0} broadcast(f32[] %subtract.233.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %multiply.264.clone.1 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %subtract.103.clone.1, f32[12,64,768]{2,1,0} %broadcast.529.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %add.112.clone.1 = f32[12,64,768]{2,1,0} add(f32[12,64,768]{2,1,0} %param_5.743, f32[12,64,768]{2,1,0} %multiply.264.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %sqrt.33 = f32[12,64,768]{2,1,0} sqrt(f32[12,64,768]{2,1,0} %add.112.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %constant_255 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.527 = f32[12,64,768]{2,1,0} broadcast(f32[] %constant_255), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %add.111 = f32[12,64,768]{2,1,0} add(f32[12,64,768]{2,1,0} %sqrt.33, f32[12,64,768]{2,1,0} %broadcast.527), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %divide.35 = f32[12,64,768]{2,1,0} divide(f32[12,64,768]{2,1,0} %multiply.263, f32[12,64,768]{2,1,0} %add.111), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %subtract.102 = f32[12,64,768]{2,1,0} subtract(f32[12,64,768]{2,1,0} %param_0.251, f32[12,64,768]{2,1,0} %divide.35), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %param_7.762 = f32[12,64,768]{2,1,0} parameter(7)
  %param_10.181 = f32[12,64,768]{2,1,0} parameter(10)
  %param_9.267 = f16[768,768]{1,0} parameter(9)
  %convert.745.clone.1.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_9.267), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/einsum/Einsum/Cast/Cast"}
  %multiply.1351.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.745.clone.1.clone.1, f32[768,768]{1,0} %broadcast.1999.clone.1), metadata={op_type="Mul" op_name="mul_28"}
  %copy.159.clone.1.clone.1 = f32[768,768]{0,1} copy(f32[768,768]{1,0} %multiply.1351.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_28"}
  %bitcast.432.clone.1.clone.1 = f32[768,12,64]{0,2,1} bitcast(f32[768,768]{0,1} %copy.159.clone.1.clone.1), metadata={op_type="Mul" op_name="mul_28"}
  %transpose.201.clone.1.clone.1 = f32[12,64,768]{2,1,0} transpose(f32[768,12,64]{0,2,1} %bitcast.432.clone.1.clone.1), dimensions={1,2,0}, metadata={op_type="Mul" op_name="mul_28"}
  %subtract.56.clone.1.clone.1 = f32[12,64,768]{2,1,0} subtract(f32[12,64,768]{2,1,0} %transpose.201.clone.1.clone.1, f32[12,64,768]{2,1,0} %param_10.181), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %multiply.183.clone.1.clone.1 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %subtract.56.clone.1.clone.1, f32[12,64,768]{2,1,0} %broadcast.528.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %add.65.clone.1.clone.1 = f32[12,64,768]{2,1,0} add(f32[12,64,768]{2,1,0} %param_10.181, f32[12,64,768]{2,1,0} %multiply.183.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %multiply.180.clone.1 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %add.65.clone.1.clone.1, f32[12,64,768]{2,1,0} %broadcast.526), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %param_8.423 = f32[12,64,768]{2,1,0} parameter(8)
  %multiply.182.clone.1.clone.1 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %transpose.201.clone.1.clone.1, f32[12,64,768]{2,1,0} %transpose.201.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %subtract.55.clone.1.clone.1 = f32[12,64,768]{2,1,0} subtract(f32[12,64,768]{2,1,0} %multiply.182.clone.1.clone.1, f32[12,64,768]{2,1,0} %param_8.423), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %multiply.181.clone.1.clone.1 = f32[12,64,768]{2,1,0} multiply(f32[12,64,768]{2,1,0} %subtract.55.clone.1.clone.1, f32[12,64,768]{2,1,0} %broadcast.529.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %add.64.clone.1.clone.1 = f32[12,64,768]{2,1,0} add(f32[12,64,768]{2,1,0} %param_8.423, f32[12,64,768]{2,1,0} %multiply.181.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %sqrt.17.clone.1 = f32[12,64,768]{2,1,0} sqrt(f32[12,64,768]{2,1,0} %add.64.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %add.63.clone.1 = f32[12,64,768]{2,1,0} add(f32[12,64,768]{2,1,0} %sqrt.17.clone.1, f32[12,64,768]{2,1,0} %broadcast.527), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %divide.19.clone.1 = f32[12,64,768]{2,1,0} divide(f32[12,64,768]{2,1,0} %multiply.180.clone.1, f32[12,64,768]{2,1,0} %add.63.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  %subtract.54.clone.1 = f32[12,64,768]{2,1,0} subtract(f32[12,64,768]{2,1,0} %param_7.762, f32[12,64,768]{2,1,0} %divide.19.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_27/update_0/ResourceApplyAdam"}
  ROOT %tuple.96 = (f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) tuple(f32[12,64,768]{2,1,0} %subtract.102, f32[12,64,768]{2,1,0} %add.113.clone.1, f32[12,64,768]{2,1,0} %add.112.clone.1, f32[12,64,768]{2,1,0} %subtract.54.clone.1, f32[12,64,768]{2,1,0} %add.65.clone.1.clone.1, f32[12,64,768]{2,1,0} %add.64.clone.1.clone.1)
}

%fused_computation.168 (param_0.260: f16[16,512,768]) -> f16[768,8192] {
  %param_0.260 = f16[16,512,768]{2,1,0} parameter(0)
  %transpose.137 = f16[768,16,512]{0,2,1} transpose(f16[16,512,768]{2,1,0} %param_0.260), dimensions={2,0,1}
  ROOT %bitcast.178 = f16[768,8192]{0,1} bitcast(f16[768,16,512]{0,2,1} %transpose.137)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_sub_Sum-reduction.1839 (x.1840: f32[], y.1841: f32[]) -> f32[] {
  %x.1840 = f32[] parameter(0)
  %y.1841 = f32[] parameter(1)
  ROOT %add.1842 = f32[] add(f32[] %x.1840, f32[] %y.1841)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_mul_Sum_1-reduction.1830 (x.1831: f32[], y.1832: f32[]) -> f32[] {
  %x.1831 = f32[] parameter(0)
  %y.1832 = f32[] parameter(1)
  ROOT %add.1833 = f32[] add(f32[] %x.1831, f32[] %y.1832)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_sub_Sum-reduction.1812 (x.1813: f32[], y.1814: f32[]) -> f32[] {
  %x.1813 = f32[] parameter(0)
  %y.1814 = f32[] parameter(1)
  ROOT %add.1815 = f32[] add(f32[] %x.1813, f32[] %y.1814)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_Sum_1-reduction.1803 (x.1804: f32[], y.1805: f32[]) -> f32[] {
  %x.1804 = f32[] parameter(0)
  %y.1805 = f32[] parameter(1)
  ROOT %add.1806 = f32[] add(f32[] %x.1804, f32[] %y.1805)
}

%fused_computation.181 (param_0.714: f16[16,512,768], param_1.1721: f32[16,512], param_2.1842: f32[16,512], param_3.1244: f32[16,512], param_4.930: f32[768], param_5.867: f32[768], param_6.757: f32[16,512], param_7.800: f16[16,512,768], param_8.475: f16[8192,768], param_9.333: f32[768], param_10.247: f16[16,512,768], param_11.345: f32[16,512,768]) -> (f32[768], f32[768], f32[768], f32[768]) {
  %param_0.714 = f16[16,512,768]{2,1,0} parameter(0)
  %convert.85 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_0.714), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_2/Cast"}
  %bitcast.181 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %convert.85)
  %constant_278 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.69 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.181, f32[] %constant_278), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_sub_Sum-reduction.1839, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/sub/Sum"}
  %param_10.247 = f16[16,512,768]{2,1,0} parameter(10)
  %constant_1255_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1849.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1255_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.108.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_10.247, f16[16,512,768]{2,1,0} %broadcast.1849.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/GreaterEqual"}
  %constant_1254_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1848.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1254_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_1253_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1847.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1253_clone_1), dimensions={}
  %select.106.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.108.clone.1, f16[16,512,768]{2,1,0} %broadcast.1848.clone.1, f16[16,512,768]{2,1,0} %broadcast.1847.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul"}
  %param_9.333 = f32[768]{0} parameter(9)
  %convert.591.clone.1 = f16[768]{0} convert(f32[768]{0} %param_9.333), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Cast"}
  %broadcast.1846.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.591.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %param_8.475 = f16[8192,768]{1,0} parameter(8)
  %bitcast.384.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_8.475), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum"}
  %add.563.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1846.clone.1, f16[16,512,768]{2,1,0} %bitcast.384.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %multiply.1117.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.106.clone.1, f16[16,512,768]{2,1,0} %add.563.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul_1"}
  %convert.590.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.1117.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_2"}
  %param_7.800 = f16[16,512,768]{2,1,0} parameter(7)
  %convert.589.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_7.800), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_6.757 = f32[16,512]{1,0} parameter(6)
  %constant_736_clone_1 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1845.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_736_clone_1), dimensions={}
  %multiply.1115.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_6.757, f32[16,512]{1,0} %broadcast.1845.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %constant_735_clone_1 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1844.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_735_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.562.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1115.clone.1, f32[16,512]{1,0} %broadcast.1844.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.107.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.562.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1843.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.107.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_5.867 = f32[768]{0} parameter(5)
  %broadcast.1842.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_5.867), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1114.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1843.clone.1, f32[16,512,768]{2,1,0} %broadcast.1842.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1113.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.589.clone.1, f32[16,512,768]{2,1,0} %multiply.1114.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1"}
  %param_4.930 = f32[768]{0} parameter(4)
  %broadcast.1841.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_4.930), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %param_3.1244 = f32[16,512]{1,0} parameter(3)
  %multiply.1111.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.1244, f32[16,512]{1,0} %broadcast.1845.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.1839.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1111.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1110.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.1114.clone.1, f32[16,512,768]{2,1,0} %broadcast.1839.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.336.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1841.clone.1, f32[16,512,768]{2,1,0} %multiply.1110.clone.1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %add.561.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1113.clone.1, f32[16,512,768]{2,1,0} %subtract.336.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1"}
  %add.559.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.590.clone.1, f32[16,512,768]{2,1,0} %add.561.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/add_1"}
  %multiply.1108.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.85, f32[16,512,768]{2,1,0} %add.559.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_1/Mul_1"}
  %negate.34.clone.1 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %convert.85), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/sub/Neg"}
  %param_2.1842 = f32[16,512]{1,0} parameter(2)
  %multiply.1107.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1842, f32[16,512]{1,0} %broadcast.1845.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mean"}
  %broadcast.1837.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1107.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/SquaredDifference"}
  %multiply.1106.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.34.clone.1, f32[16,512,768]{2,1,0} %broadcast.1837.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.558.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1108.clone.1, f32[16,512,768]{2,1,0} %multiply.1106.clone.1), metadata={op_type="AddN" op_name="AddN_11"}
  %param_1.1721 = f32[16,512]{1,0} parameter(1)
  %multiply.718.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1721, f32[16,512]{1,0} %broadcast.1845.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/variance"}
  %add.314.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.718.clone.1, f32[16,512]{1,0} %broadcast.1844.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/add"}
  %rsqrt.45.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.314.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.544.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.45.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.278.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.558.clone.1, f32[16,512,768]{2,1,0} %broadcast.544.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul/Mul_1"}
  %bitcast.180.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %multiply.278.clone.1)
  %reduce.68.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.180.clone.1, f32[] %constant_278), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_mul_Sum_1-reduction.1830, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul/Sum_1"}
  %param_11.345 = f32[16,512,768]{2,1,0} parameter(11)
  %multiply.1186.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %param_11.345, f32[16,512,768]{2,1,0} %convert.589.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1/Mul_1"}
  %negate.38.clone.1 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %param_11.345), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub/Neg"}
  %multiply.1183.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.38.clone.1, f32[16,512,768]{2,1,0} %broadcast.1839.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.582.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1186.clone.1, f32[16,512,768]{2,1,0} %multiply.1183.clone.1), metadata={op_type="AddN" op_name="AddN_15"}
  %multiply.224.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.582.clone.1, f32[16,512,768]{2,1,0} %broadcast.1843.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/Mul_1"}
  %bitcast.166.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %multiply.224.clone.1)
  %reduce.63.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.166.clone.1, f32[] %constant_278), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_Sum_1-reduction.1803, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/Sum_1"}
  %bitcast.167.clone.1.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %param_11.345)
  %reduce.64.clone.1.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.167.clone.1.clone.1, f32[] %constant_278), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_sub_Sum-reduction.1812, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub/Sum"}
  ROOT %tuple.153 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %reduce.69, f32[768]{0} %reduce.68.clone.1, f32[768]{0} %reduce.63.clone.1, f32[768]{0} %reduce.64.clone.1.clone.1)
}

%fused_computation.182 (param_0.278: f32[3072,768], param_1.1705: f32[], param_2.1810: f32[3072,768], param_3.1198: f32[], param_4.860: f16[3072,768], param_5.774: f32[3072,768], param_6.674: f32[], param_7.759: f32[3072,768], param_8.419: f32[3072,768], param_9.262: f16[3072,768], param_10.176: f32[3072,768]) -> (f32[3072,768], f32[3072,768], f32[3072,768], f32[3072,768], f32[3072,768], f32[3072,768]) {
  %param_0.278 = f32[3072,768]{1,0} parameter(0)
  %param_2.1810 = f32[3072,768]{1,0} parameter(2)
  %param_4.860 = f16[3072,768]{1,0} parameter(4)
  %convert.661.clone.1 = f32[3072,768]{1,0} convert(f16[3072,768]{1,0} %param_4.860), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum/Cast/Cast"}
  %constant_1370_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.1990.clone.1 = f32[3072,768]{1,0} broadcast(f32[] %constant_1370_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_18"}
  %multiply.1290.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %convert.661.clone.1, f32[3072,768]{1,0} %broadcast.1990.clone.1), metadata={op_type="Mul" op_name="mul_18"}
  %subtract.116.clone.1 = f32[3072,768]{1,0} subtract(f32[3072,768]{1,0} %multiply.1290.clone.1, f32[3072,768]{1,0} %param_2.1810), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %constant_281_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1198 = f32[] parameter(3)
  %subtract.240.clone.1 = f32[] subtract(f32[] %constant_281_clone_1, f32[] %param_3.1198), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.553.clone.1 = f32[3072,768]{1,0} broadcast(f32[] %subtract.240.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %multiply.286.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %subtract.116.clone.1, f32[3072,768]{1,0} %broadcast.553.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %add.125.clone.1 = f32[3072,768]{1,0} add(f32[3072,768]{1,0} %param_2.1810, f32[3072,768]{1,0} %multiply.286.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %param_1.1705 = f32[] parameter(1)
  %broadcast.551 = f32[3072,768]{1,0} broadcast(f32[] %param_1.1705), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %multiply.283 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %add.125.clone.1, f32[3072,768]{1,0} %broadcast.551), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %param_5.774 = f32[3072,768]{1,0} parameter(5)
  %multiply.285.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %multiply.1290.clone.1, f32[3072,768]{1,0} %multiply.1290.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %subtract.115.clone.1 = f32[3072,768]{1,0} subtract(f32[3072,768]{1,0} %multiply.285.clone.1, f32[3072,768]{1,0} %param_5.774), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %param_6.674 = f32[] parameter(6)
  %subtract.241.clone.1 = f32[] subtract(f32[] %constant_281_clone_1, f32[] %param_6.674), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.555.clone.1 = f32[3072,768]{1,0} broadcast(f32[] %subtract.241.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %multiply.284.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %subtract.115.clone.1, f32[3072,768]{1,0} %broadcast.555.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %add.124.clone.1 = f32[3072,768]{1,0} add(f32[3072,768]{1,0} %param_5.774, f32[3072,768]{1,0} %multiply.284.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %sqrt.37 = f32[3072,768]{1,0} sqrt(f32[3072,768]{1,0} %add.124.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %constant_280 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.552 = f32[3072,768]{1,0} broadcast(f32[] %constant_280), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %add.123 = f32[3072,768]{1,0} add(f32[3072,768]{1,0} %sqrt.37, f32[3072,768]{1,0} %broadcast.552), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %divide.39 = f32[3072,768]{1,0} divide(f32[3072,768]{1,0} %multiply.283, f32[3072,768]{1,0} %add.123), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %subtract.114 = f32[3072,768]{1,0} subtract(f32[3072,768]{1,0} %param_0.278, f32[3072,768]{1,0} %divide.39), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %param_7.759 = f32[3072,768]{1,0} parameter(7)
  %param_10.176 = f32[3072,768]{1,0} parameter(10)
  %param_9.262 = f16[3072,768]{1,0} parameter(9)
  %convert.733.clone.1.clone.1 = f32[3072,768]{1,0} convert(f16[3072,768]{1,0} %param_9.262), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum/Cast/Cast"}
  %multiply.1340.clone.1.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %convert.733.clone.1.clone.1, f32[3072,768]{1,0} %broadcast.1990.clone.1), metadata={op_type="Mul" op_name="mul_34"}
  %subtract.68.clone.1.clone.1 = f32[3072,768]{1,0} subtract(f32[3072,768]{1,0} %multiply.1340.clone.1.clone.1, f32[3072,768]{1,0} %param_10.176), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %multiply.202.clone.1.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %subtract.68.clone.1.clone.1, f32[3072,768]{1,0} %broadcast.553.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %add.77.clone.1.clone.1 = f32[3072,768]{1,0} add(f32[3072,768]{1,0} %param_10.176, f32[3072,768]{1,0} %multiply.202.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %multiply.199.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %add.77.clone.1.clone.1, f32[3072,768]{1,0} %broadcast.551), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %param_8.419 = f32[3072,768]{1,0} parameter(8)
  %multiply.201.clone.1.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %multiply.1340.clone.1.clone.1, f32[3072,768]{1,0} %multiply.1340.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %subtract.67.clone.1.clone.1 = f32[3072,768]{1,0} subtract(f32[3072,768]{1,0} %multiply.201.clone.1.clone.1, f32[3072,768]{1,0} %param_8.419), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %multiply.200.clone.1.clone.1 = f32[3072,768]{1,0} multiply(f32[3072,768]{1,0} %subtract.67.clone.1.clone.1, f32[3072,768]{1,0} %broadcast.555.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %add.76.clone.1.clone.1 = f32[3072,768]{1,0} add(f32[3072,768]{1,0} %param_8.419, f32[3072,768]{1,0} %multiply.200.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %sqrt.21.clone.1 = f32[3072,768]{1,0} sqrt(f32[3072,768]{1,0} %add.76.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %add.75.clone.1 = f32[3072,768]{1,0} add(f32[3072,768]{1,0} %sqrt.21.clone.1, f32[3072,768]{1,0} %broadcast.552), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %divide.23.clone.1 = f32[3072,768]{1,0} divide(f32[3072,768]{1,0} %multiply.199.clone.1, f32[3072,768]{1,0} %add.75.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  %subtract.66.clone.1 = f32[3072,768]{1,0} subtract(f32[3072,768]{1,0} %param_7.759, f32[3072,768]{1,0} %divide.23.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_33/update_0/ResourceApplyAdam"}
  ROOT %tuple.95 = (f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) tuple(f32[3072,768]{1,0} %subtract.114, f32[3072,768]{1,0} %add.125.clone.1, f32[3072,768]{1,0} %add.124.clone.1, f32[3072,768]{1,0} %subtract.66.clone.1, f32[3072,768]{1,0} %add.77.clone.1.clone.1, f32[3072,768]{1,0} %add.76.clone.1.clone.1)
}

%fused_computation.186 (param_0.284: f16[16,512,768]) -> f16[768,8192] {
  %param_0.284 = f16[16,512,768]{2,1,0} parameter(0)
  %transpose.138 = f16[768,16,512]{0,2,1} transpose(f16[16,512,768]{2,1,0} %param_0.284), dimensions={2,0,1}
  ROOT %bitcast.182 = f16[768,8192]{0,1} bitcast(f16[768,16,512]{0,2,1} %transpose.138)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_add_Sum-reduction.1485 (x.1486: f32[], y.1487: f32[]) -> f32[] {
  %x.1486 = f32[] parameter(0)
  %y.1487 = f32[] parameter(1)
  ROOT %add.1488 = f32[] add(f32[] %x.1486, f32[] %y.1487)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_attention_output_add_Sum-reduction.1593 (x.1594: f32[], y.1595: f32[]) -> f32[] {
  %x.1594 = f32[] parameter(0)
  %y.1595 = f32[] parameter(1)
  ROOT %add.1596 = f32[] add(f32[] %x.1594, f32[] %y.1595)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_add_Sum-reduction.1227 (x.1228: f32[], y.1229: f32[]) -> f32[] {
  %x.1228 = f32[] parameter(0)
  %y.1229 = f32[] parameter(1)
  ROOT %add.1230 = f32[] add(f32[] %x.1228, f32[] %y.1229)
}

%fused_computation.191 (param_0.717: f16[16,512,768], param_1.1775: f16[16,512,768], param_2.1910: f16[16,512,768]) -> (f32[768], f32[768], f32[768]) {
  %param_0.717 = f16[16,512,768]{2,1,0} parameter(0)
  %convert.89 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_0.717), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Sum"}
  %bitcast.183 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %convert.89)
  %constant_291 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.70 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.183, f32[] %constant_291), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_add_Sum-reduction.1485, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Sum"}
  %param_1.1775 = f16[16,512,768]{2,1,0} parameter(1)
  %convert.84.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_1.1775), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/add/Sum"}
  %bitcast.179.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %convert.84.clone.1)
  %reduce.67.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.179.clone.1, f32[] %constant_291), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_attention_output_add_Sum-reduction.1593, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/add/Sum"}
  %param_2.1910 = f16[16,512,768]{2,1,0} parameter(2)
  %convert.64.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_2.1910), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Sum"}
  %bitcast.163.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %convert.64.clone.1)
  %reduce.61.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.163.clone.1, f32[] %constant_291), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_add_Sum-reduction.1227, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Sum"}
  ROOT %tuple.158 = (f32[768]{0}, f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %reduce.70, f32[768]{0} %reduce.67.clone.1, f32[768]{0} %reduce.61.clone.1)
}

%fused_computation.192 (param_0.292: f32[768,3072], param_1.1707: f32[], param_2.1814: f32[768,3072], param_3.1202: f32[], param_4.868: f16[768,3072], param_5.791: f32[768,3072], param_6.686: f32[], param_7.756: f32[768,3072], param_8.415: f32[768,3072], param_9.257: f16[768,3072], param_10.171: f32[768,3072]) -> (f32[768,3072], f32[768,3072], f32[768,3072], f32[768,3072], f32[768,3072], f32[768,3072]) {
  %param_0.292 = f32[768,3072]{1,0} parameter(0)
  %param_2.1814 = f32[768,3072]{1,0} parameter(2)
  %param_4.868 = f16[768,3072]{1,0} parameter(4)
  %convert.647.clone.1 = f32[768,3072]{1,0} convert(f16[768,3072]{1,0} %param_4.868), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/einsum/Einsum/Cast/Cast"}
  %constant_1357_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.1982.clone.1 = f32[768,3072]{1,0} broadcast(f32[] %constant_1357_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_16"}
  %multiply.1281.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %convert.647.clone.1, f32[768,3072]{1,0} %broadcast.1982.clone.1), metadata={op_type="Mul" op_name="mul_16"}
  %subtract.122.clone.1 = f32[768,3072]{1,0} subtract(f32[768,3072]{1,0} %multiply.1281.clone.1, f32[768,3072]{1,0} %param_2.1814), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %constant_293_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1202 = f32[] parameter(3)
  %subtract.244.clone.1 = f32[] subtract(f32[] %constant_293_clone_1, f32[] %param_3.1202), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.567.clone.1 = f32[768,3072]{1,0} broadcast(f32[] %subtract.244.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %multiply.298.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %subtract.122.clone.1, f32[768,3072]{1,0} %broadcast.567.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %add.131.clone.1 = f32[768,3072]{1,0} add(f32[768,3072]{1,0} %param_2.1814, f32[768,3072]{1,0} %multiply.298.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %param_1.1707 = f32[] parameter(1)
  %broadcast.565 = f32[768,3072]{1,0} broadcast(f32[] %param_1.1707), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %multiply.294 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %add.131.clone.1, f32[768,3072]{1,0} %broadcast.565), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %param_5.791 = f32[768,3072]{1,0} parameter(5)
  %multiply.297.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %multiply.1281.clone.1, f32[768,3072]{1,0} %multiply.1281.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %subtract.121.clone.1 = f32[768,3072]{1,0} subtract(f32[768,3072]{1,0} %multiply.297.clone.1, f32[768,3072]{1,0} %param_5.791), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %param_6.686 = f32[] parameter(6)
  %subtract.245.clone.1 = f32[] subtract(f32[] %constant_293_clone_1, f32[] %param_6.686), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.569.clone.1 = f32[768,3072]{1,0} broadcast(f32[] %subtract.245.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %multiply.295.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %subtract.121.clone.1, f32[768,3072]{1,0} %broadcast.569.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %add.130.clone.1 = f32[768,3072]{1,0} add(f32[768,3072]{1,0} %param_5.791, f32[768,3072]{1,0} %multiply.295.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %sqrt.39 = f32[768,3072]{1,0} sqrt(f32[768,3072]{1,0} %add.130.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %constant_292 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.566 = f32[768,3072]{1,0} broadcast(f32[] %constant_292), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %add.129 = f32[768,3072]{1,0} add(f32[768,3072]{1,0} %sqrt.39, f32[768,3072]{1,0} %broadcast.566), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %divide.41 = f32[768,3072]{1,0} divide(f32[768,3072]{1,0} %multiply.294, f32[768,3072]{1,0} %add.129), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %subtract.120 = f32[768,3072]{1,0} subtract(f32[768,3072]{1,0} %param_0.292, f32[768,3072]{1,0} %divide.41), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %param_7.756 = f32[768,3072]{1,0} parameter(7)
  %param_10.171 = f32[768,3072]{1,0} parameter(10)
  %param_9.257 = f16[768,3072]{1,0} parameter(9)
  %convert.717.clone.1.clone.1 = f32[768,3072]{1,0} convert(f16[768,3072]{1,0} %param_9.257), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/einsum/Einsum/Cast/Cast"}
  %multiply.1332.clone.1.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %convert.717.clone.1.clone.1, f32[768,3072]{1,0} %broadcast.1982.clone.1), metadata={op_type="Mul" op_name="mul_32"}
  %subtract.74.clone.1.clone.1 = f32[768,3072]{1,0} subtract(f32[768,3072]{1,0} %multiply.1332.clone.1.clone.1, f32[768,3072]{1,0} %param_10.171), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %multiply.213.clone.1.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %subtract.74.clone.1.clone.1, f32[768,3072]{1,0} %broadcast.567.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %add.83.clone.1.clone.1 = f32[768,3072]{1,0} add(f32[768,3072]{1,0} %param_10.171, f32[768,3072]{1,0} %multiply.213.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %multiply.209.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %add.83.clone.1.clone.1, f32[768,3072]{1,0} %broadcast.565), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %param_8.415 = f32[768,3072]{1,0} parameter(8)
  %multiply.211.clone.1.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %multiply.1332.clone.1.clone.1, f32[768,3072]{1,0} %multiply.1332.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %subtract.73.clone.1.clone.1 = f32[768,3072]{1,0} subtract(f32[768,3072]{1,0} %multiply.211.clone.1.clone.1, f32[768,3072]{1,0} %param_8.415), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %multiply.210.clone.1.clone.1 = f32[768,3072]{1,0} multiply(f32[768,3072]{1,0} %subtract.73.clone.1.clone.1, f32[768,3072]{1,0} %broadcast.569.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %add.82.clone.1.clone.1 = f32[768,3072]{1,0} add(f32[768,3072]{1,0} %param_8.415, f32[768,3072]{1,0} %multiply.210.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %sqrt.23.clone.1 = f32[768,3072]{1,0} sqrt(f32[768,3072]{1,0} %add.82.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %add.81.clone.1 = f32[768,3072]{1,0} add(f32[768,3072]{1,0} %sqrt.23.clone.1, f32[768,3072]{1,0} %broadcast.566), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %divide.25.clone.1 = f32[768,3072]{1,0} divide(f32[768,3072]{1,0} %multiply.209.clone.1, f32[768,3072]{1,0} %add.81.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  %subtract.72.clone.1 = f32[768,3072]{1,0} subtract(f32[768,3072]{1,0} %param_7.756, f32[768,3072]{1,0} %divide.25.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_31/update_0/ResourceApplyAdam"}
  ROOT %tuple.94 = (f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) tuple(f32[768,3072]{1,0} %subtract.120, f32[768,3072]{1,0} %add.131.clone.1, f32[768,3072]{1,0} %add.130.clone.1, f32[768,3072]{1,0} %subtract.72.clone.1, f32[768,3072]{1,0} %add.83.clone.1.clone.1, f32[768,3072]{1,0} %add.82.clone.1.clone.1)
}

%fused_computation.196 (param_0.298: f16[16,512,3072]) -> f16[3072,8192] {
  %param_0.298 = f16[16,512,3072]{2,1,0} parameter(0)
  %transpose.139 = f16[3072,16,512]{0,2,1} transpose(f16[16,512,3072]{2,1,0} %param_0.298), dimensions={2,0,1}
  ROOT %bitcast.184 = f16[3072,8192]{0,1} bitcast(f16[3072,16,512]{0,2,1} %transpose.139)
}

%fused_computation.197 (param_0.299: f32[3072], param_1.1708: f32[], param_2.1816: f32[3072], param_3.1204: f32[], param_4.872: f32[3072], param_5.800: f32[3072], param_6.692: f32[], param_7.753: f32[3072], param_8.411: f32[3072], param_9.252: f32[3072], param_10.166: f32[3072]) -> (f32[3072], f32[3072], f32[3072], f32[3072], f32[3072], f32[3072]) {
  %param_0.299 = f32[3072]{0} parameter(0)
  %param_2.1816 = f32[3072]{0} parameter(2)
  %param_4.872 = f32[3072]{0} parameter(4)
  %convert.639.clone.1 = f16[3072]{0} convert(f32[3072]{0} %param_4.872), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Sum"}
  %convert.638.clone.1 = f32[3072]{0} convert(f16[3072]{0} %convert.639.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Cast/Cast"}
  %constant_1350_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.1978.clone.1 = f32[3072]{0} broadcast(f32[] %constant_1350_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_17"}
  %multiply.1277.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %convert.638.clone.1, f32[3072]{0} %broadcast.1978.clone.1), metadata={op_type="Mul" op_name="mul_17"}
  %subtract.125.clone.1 = f32[3072]{0} subtract(f32[3072]{0} %multiply.1277.clone.1, f32[3072]{0} %param_2.1816), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %constant_298_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1204 = f32[] parameter(3)
  %subtract.246.clone.1 = f32[] subtract(f32[] %constant_298_clone_1, f32[] %param_3.1204), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.574.clone.1 = f32[3072]{0} broadcast(f32[] %subtract.246.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %multiply.303.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %subtract.125.clone.1, f32[3072]{0} %broadcast.574.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %add.134.clone.1 = f32[3072]{0} add(f32[3072]{0} %param_2.1816, f32[3072]{0} %multiply.303.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %param_1.1708 = f32[] parameter(1)
  %broadcast.572 = f32[3072]{0} broadcast(f32[] %param_1.1708), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %multiply.300 = f32[3072]{0} multiply(f32[3072]{0} %add.134.clone.1, f32[3072]{0} %broadcast.572), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %param_5.800 = f32[3072]{0} parameter(5)
  %multiply.302.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %multiply.1277.clone.1, f32[3072]{0} %multiply.1277.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %subtract.124.clone.1 = f32[3072]{0} subtract(f32[3072]{0} %multiply.302.clone.1, f32[3072]{0} %param_5.800), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %param_6.692 = f32[] parameter(6)
  %subtract.247.clone.1 = f32[] subtract(f32[] %constant_298_clone_1, f32[] %param_6.692), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.575.clone.1 = f32[3072]{0} broadcast(f32[] %subtract.247.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %multiply.301.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %subtract.124.clone.1, f32[3072]{0} %broadcast.575.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %add.133.clone.1 = f32[3072]{0} add(f32[3072]{0} %param_5.800, f32[3072]{0} %multiply.301.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %sqrt.40 = f32[3072]{0} sqrt(f32[3072]{0} %add.133.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %constant_297 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.573 = f32[3072]{0} broadcast(f32[] %constant_297), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %add.132 = f32[3072]{0} add(f32[3072]{0} %sqrt.40, f32[3072]{0} %broadcast.573), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %divide.42 = f32[3072]{0} divide(f32[3072]{0} %multiply.300, f32[3072]{0} %add.132), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %subtract.123 = f32[3072]{0} subtract(f32[3072]{0} %param_0.299, f32[3072]{0} %divide.42), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %param_7.753 = f32[3072]{0} parameter(7)
  %param_10.166 = f32[3072]{0} parameter(10)
  %param_9.252 = f32[3072]{0} parameter(9)
  %convert.709.clone.1.clone.1 = f16[3072]{0} convert(f32[3072]{0} %param_9.252), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add/Sum"}
  %convert.708.clone.1.clone.1 = f32[3072]{0} convert(f16[3072]{0} %convert.709.clone.1.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add/Cast/Cast"}
  %multiply.1326.clone.1.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %convert.708.clone.1.clone.1, f32[3072]{0} %broadcast.1978.clone.1), metadata={op_type="Mul" op_name="mul_33"}
  %subtract.77.clone.1.clone.1 = f32[3072]{0} subtract(f32[3072]{0} %multiply.1326.clone.1.clone.1, f32[3072]{0} %param_10.166), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %multiply.218.clone.1.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %subtract.77.clone.1.clone.1, f32[3072]{0} %broadcast.574.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %add.86.clone.1.clone.1 = f32[3072]{0} add(f32[3072]{0} %param_10.166, f32[3072]{0} %multiply.218.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %multiply.215.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %add.86.clone.1.clone.1, f32[3072]{0} %broadcast.572), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %param_8.411 = f32[3072]{0} parameter(8)
  %multiply.217.clone.1.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %multiply.1326.clone.1.clone.1, f32[3072]{0} %multiply.1326.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %subtract.76.clone.1.clone.1 = f32[3072]{0} subtract(f32[3072]{0} %multiply.217.clone.1.clone.1, f32[3072]{0} %param_8.411), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %multiply.216.clone.1.clone.1 = f32[3072]{0} multiply(f32[3072]{0} %subtract.76.clone.1.clone.1, f32[3072]{0} %broadcast.575.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %add.85.clone.1.clone.1 = f32[3072]{0} add(f32[3072]{0} %param_8.411, f32[3072]{0} %multiply.216.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %sqrt.24.clone.1 = f32[3072]{0} sqrt(f32[3072]{0} %add.85.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %add.84.clone.1 = f32[3072]{0} add(f32[3072]{0} %sqrt.24.clone.1, f32[3072]{0} %broadcast.573), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %divide.26.clone.1 = f32[3072]{0} divide(f32[3072]{0} %multiply.215.clone.1, f32[3072]{0} %add.84.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  %subtract.75.clone.1 = f32[3072]{0} subtract(f32[3072]{0} %param_7.753, f32[3072]{0} %divide.26.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_32/update_0/ResourceApplyAdam"}
  ROOT %tuple.93 = (f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) tuple(f32[3072]{0} %subtract.123, f32[3072]{0} %add.134.clone.1, f32[3072]{0} %add.133.clone.1, f32[3072]{0} %subtract.75.clone.1, f32[3072]{0} %add.86.clone.1.clone.1, f32[3072]{0} %add.85.clone.1.clone.1)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_intermediate_add_Sum-reduction.1517 (x.1518: f32[], y.1519: f32[]) -> f32[] {
  %x.1518 = f32[] parameter(0)
  %y.1519 = f32[] parameter(1)
  ROOT %add.1520 = f32[] add(f32[] %x.1518, f32[] %y.1519)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_intermediate_add_Sum-reduction.1259 (x.1260: f32[], y.1261: f32[]) -> f32[] {
  %x.1260 = f32[] parameter(0)
  %y.1261 = f32[] parameter(1)
  ROOT %add.1262 = f32[] add(f32[] %x.1260, f32[] %y.1261)
}

%fused_computation.201 (param_0.720: f16[16,512,3072], param_1.1778: f16[16,512,3072]) -> (f32[3072], f32[3072]) {
  %param_0.720 = f16[16,512,3072]{2,1,0} parameter(0)
  %convert.93 = f32[16,512,3072]{2,1,0} convert(f16[16,512,3072]{2,1,0} %param_0.720), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Sum"}
  %bitcast.185 = f32[8192,3072]{1,0} bitcast(f32[16,512,3072]{2,1,0} %convert.93)
  %constant_301 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.71 = f32[3072]{0} reduce(f32[8192,3072]{1,0} %bitcast.185, f32[] %constant_301), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_intermediate_add_Sum-reduction.1517, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Sum"}
  %param_1.1778 = f16[16,512,3072]{2,1,0} parameter(1)
  %convert.68.clone.1 = f32[16,512,3072]{2,1,0} convert(f16[16,512,3072]{2,1,0} %param_1.1778), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add/Sum"}
  %bitcast.165.clone.1 = f32[8192,3072]{1,0} bitcast(f32[16,512,3072]{2,1,0} %convert.68.clone.1)
  %reduce.62.clone.1 = f32[3072]{0} reduce(f32[8192,3072]{1,0} %bitcast.165.clone.1, f32[] %constant_301), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_intermediate_add_Sum-reduction.1259, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add/Sum"}
  ROOT %tuple.159 = (f32[3072]{0}, f32[3072]{0}) tuple(f32[3072]{0} %reduce.71, f32[3072]{0} %reduce.62.clone.1)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_position_embedding_Sum-reduction.1743 (x.1744: f32[], y.1745: f32[]) -> f32[] {
  %x.1744 = f32[] parameter(0)
  %y.1745 = f32[] parameter(1)
  ROOT %add.1746 = f32[] add(f32[] %x.1744, f32[] %y.1745)
}

%fused_computation.202 (param_0.306: f32[512,768], param_1.1709: f32[], param_2.1818: f32[512,768], param_3.1206: f32[], param_4.877: f32[512,768], param_5.807: f32[], param_6.701: f16[16,512,768]) -> (f32[512,768], f32[512,768], f32[512,768]) {
  %param_0.306 = f32[512,768]{1,0} parameter(0)
  %param_2.1818 = f32[512,768]{1,0} parameter(2)
  %param_6.701 = f16[16,512,768]{2,1,0} parameter(6)
  %convert.96.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_6.701), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/position_embedding/Sum"}
  %constant_308_clone_1 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.72.clone.1 = f32[512,768]{1,0} reduce(f32[16,512,768]{2,1,0} %convert.96.clone.1, f32[] %constant_308_clone_1), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_position_embedding_Sum-reduction.1743, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/position_embedding/Sum"}
  %convert.95.clone.1 = f16[512,768]{1,0} convert(f32[512,768]{1,0} %reduce.72.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/position_embedding/Sum"}
  %convert.94.clone.1 = f32[512,768]{1,0} convert(f16[512,768]{1,0} %convert.95.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/position_embedding/Cast/Cast"}
  %constant_306_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.235.clone.1 = f32[512,768]{1,0} broadcast(f32[] %constant_306_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_2"}
  %multiply.310.clone.1 = f32[512,768]{1,0} multiply(f32[512,768]{1,0} %convert.94.clone.1, f32[512,768]{1,0} %broadcast.235.clone.1), metadata={op_type="Mul" op_name="mul_2"}
  %subtract.128.clone.1 = f32[512,768]{1,0} subtract(f32[512,768]{1,0} %multiply.310.clone.1, f32[512,768]{1,0} %param_2.1818), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %constant_304_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1206 = f32[] parameter(3)
  %subtract.248.clone.1 = f32[] subtract(f32[] %constant_304_clone_1, f32[] %param_3.1206), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.234.clone.1 = f32[512,768]{1,0} broadcast(f32[] %subtract.248.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %multiply.308.clone.1 = f32[512,768]{1,0} multiply(f32[512,768]{1,0} %subtract.128.clone.1, f32[512,768]{1,0} %broadcast.234.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %add.137.clone.1 = f32[512,768]{1,0} add(f32[512,768]{1,0} %param_2.1818, f32[512,768]{1,0} %multiply.308.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %param_1.1709 = f32[] parameter(1)
  %broadcast.231 = f32[512,768]{1,0} broadcast(f32[] %param_1.1709), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %multiply.305 = f32[512,768]{1,0} multiply(f32[512,768]{1,0} %add.137.clone.1, f32[512,768]{1,0} %broadcast.231), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %param_4.877 = f32[512,768]{1,0} parameter(4)
  %multiply.307.clone.1 = f32[512,768]{1,0} multiply(f32[512,768]{1,0} %multiply.310.clone.1, f32[512,768]{1,0} %multiply.310.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %subtract.127.clone.1 = f32[512,768]{1,0} subtract(f32[512,768]{1,0} %multiply.307.clone.1, f32[512,768]{1,0} %param_4.877), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %param_5.807 = f32[] parameter(5)
  %subtract.249.clone.1 = f32[] subtract(f32[] %constant_304_clone_1, f32[] %param_5.807), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.232.clone.1 = f32[512,768]{1,0} broadcast(f32[] %subtract.249.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %multiply.306.clone.1 = f32[512,768]{1,0} multiply(f32[512,768]{1,0} %subtract.127.clone.1, f32[512,768]{1,0} %broadcast.232.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %add.136.clone.1 = f32[512,768]{1,0} add(f32[512,768]{1,0} %param_4.877, f32[512,768]{1,0} %multiply.306.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %sqrt.41 = f32[512,768]{1,0} sqrt(f32[512,768]{1,0} %add.136.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %constant_302 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.230 = f32[512,768]{1,0} broadcast(f32[] %constant_302), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %add.135 = f32[512,768]{1,0} add(f32[512,768]{1,0} %sqrt.41, f32[512,768]{1,0} %broadcast.230), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %divide.43 = f32[512,768]{1,0} divide(f32[512,768]{1,0} %multiply.305, f32[512,768]{1,0} %add.135), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %subtract.126 = f32[512,768]{1,0} subtract(f32[512,768]{1,0} %param_0.306, f32[512,768]{1,0} %divide.43), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  ROOT %tuple.85 = (f32[512,768]{1,0}, f32[512,768]{1,0}, f32[512,768]{1,0}) tuple(f32[512,768]{1,0} %subtract.126, f32[512,768]{1,0} %add.137.clone.1, f32[512,768]{1,0} %add.136.clone.1)
}

%fused_computation.206 (param_0.723: f32[16,512], param_1.1242: f32[16,512], param_2.1169: f16[16,512,768], param_3.646: f32[768], param_4.354: f32[16,512], param_5.140: f16[16,512,768], param_6.120: f32[16,512]) -> f16[16,512,768] {
  %param_2.1169 = f16[16,512,768]{2,1,0} parameter(2)
  %convert.98 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_2.1169), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_1/Cast"}
  %param_6.120 = f32[16,512]{1,0} parameter(6)
  %constant_312 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.850 = f32[16,512]{1,0} broadcast(f32[] %constant_312), dimensions={}
  %multiply.593 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_6.120, f32[16,512]{1,0} %broadcast.850), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/variance"}
  %constant_544 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.849 = f32[16,512]{1,0} broadcast(f32[] %constant_544), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.240 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.593, f32[16,512]{1,0} %broadcast.849), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %rsqrt.13 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.240), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/Rsqrt"}
  %broadcast.584 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.13), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %param_3.646 = f32[768]{0} parameter(3)
  %broadcast.582 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_3.646), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %multiply.542 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.584, f32[16,512,768]{2,1,0} %broadcast.582), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %multiply.320 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.98, f32[16,512,768]{2,1,0} %multiply.542), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_1/Mul"}
  %constant_309 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.581 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_309), dimensions={}
  %broadcast.579 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_312), dimensions={}
  %bitcast.188 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.13), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/Rsqrt"}
  %multiply.319 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.188, f32[16,512,1]{1,0,2} %bitcast.188), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/RsqrtGrad"}
  %multiply.318 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.319, f32[16,512,1]{1,0,2} %bitcast.188), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/RsqrtGrad"}
  %param_1.1242 = f32[16,512]{1,0} parameter(1)
  %constant_310 = f32[] constant(-0.5)
  %broadcast.578 = f32[16,512]{1,0} broadcast(f32[] %constant_310), dimensions={}
  %multiply.317 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1242, f32[16,512]{1,0} %broadcast.578), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.187 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.317), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/RsqrtGrad"}
  %multiply.315 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.318, f32[16,512,1]{1,0,2} %bitcast.187), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/RsqrtGrad"}
  %multiply.314 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.579, f32[16,512,1]{1,0,2} %multiply.315), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/truediv"}
  %multiply.313 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.581, f32[16,512,1]{1,0,2} %multiply.314), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/Mul"}
  %bitcast.186 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.313), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/Mul"}
  %broadcast.239 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.186), dimensions={0,1}
  %param_5.140 = f16[16,512,768]{2,1,0} parameter(5)
  %convert.225 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_5.140), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast"}
  %param_4.354 = f32[16,512]{1,0} parameter(4)
  %multiply.591 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.354, f32[16,512]{1,0} %broadcast.850), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mean"}
  %broadcast.844 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.591), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %subtract.261 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.225, f32[16,512,768]{2,1,0} %broadcast.844), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %multiply.312 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.239, f32[16,512,768]{2,1,0} %subtract.261), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mul_1"}
  %add.139 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.320, f32[16,512,768]{2,1,0} %multiply.312), metadata={op_type="AddN" op_name="AddN_19"}
  %param_0.723 = f32[16,512]{1,0} parameter(0)
  %multiply.311 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.850, f32[16,512]{1,0} %param_0.723), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/truediv_1"}
  %broadcast.237 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.311), dimensions={0,1}
  %add.138 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.139, f32[16,512,768]{2,1,0} %broadcast.237), metadata={op_type="AddN" op_name="AddN_19"}
  ROOT %convert.97 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.138), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast/Cast"}
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_mul_2_Sum-reduction.1689 (x.1690: f32[], y.1691: f32[]) -> f32[] {
  %x.1690 = f32[] parameter(0)
  %y.1691 = f32[] parameter(1)
  ROOT %add.1692 = f32[] add(f32[] %x.1690, f32[] %y.1691)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_mul_Sum-reduction.1711 (x.1712: f32[], y.1713: f32[]) -> f32[] {
  %x.1712 = f32[] parameter(0)
  %y.1713 = f32[] parameter(1)
  ROOT %add.1714 = f32[] add(f32[] %x.1712, f32[] %y.1713)
}

%fused_computation.207 (param_0.1138: f32[768], param_1.1564: f32[16,512], param_2.1833: f32[16,512], param_3.1226: f16[16,512,768], param_4.905: f16[8192,768], param_5.842: f16[8192,768], param_6.733: f16[8192,768], param_7.780: f32[16,512], param_8.449: f32[16,512], param_9.301: f16[16,512,768], param_10.213: f32[16,512], param_11.262: f32[16,512,768], param_12.197: f32[768], param_13.62: f32[16,512], param_14.50: f16[16,512,768]) -> (f32[16,512], f32[16,512], f16[16,512,768]) {
  %param_14.50 = f16[16,512,768]{2,1,0} parameter(14)
  %constant_342_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.619.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_342_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.14.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_14.50, f16[16,512,768]{2,1,0} %broadcast.619.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %param_11.262 = f32[16,512,768]{2,1,0} parameter(11)
  %param_13.62 = f32[16,512]{1,0} parameter(13)
  %constant_557 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1950.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_557), dimensions={}
  %multiply.1251.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_13.62, f32[16,512]{1,0} %broadcast.1950.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %constant_556 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1949.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_556), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.595.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1251.clone.1, f32[16,512]{1,0} %broadcast.1949.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.115.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.595.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1948.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.115.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_12.197 = f32[768]{0} parameter(12)
  %broadcast.1947.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_12.197), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1248.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1948.clone.1, f32[16,512,768]{2,1,0} %broadcast.1947.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1247.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %param_11.262, f32[16,512,768]{2,1,0} %multiply.1248.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1312_clone_1 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1945.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1312_clone_1), dimensions={}
  %broadcast.1944.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_557), dimensions={}
  %bitcast.408.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.115.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %multiply.1245.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.408.clone.1, f32[16,512,1]{1,0,2} %bitcast.408.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1244.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1245.clone.1, f32[16,512,1]{1,0,2} %bitcast.408.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %param_10.213 = f32[16,512]{1,0} parameter(10)
  %constant_1310_clone_1 = f32[] constant(-0.5)
  %broadcast.1943.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_1310_clone_1), dimensions={}
  %multiply.1243.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_10.213, f32[16,512]{1,0} %broadcast.1943.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.407.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.1243.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1238.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1244.clone.1, f32[16,512,1]{1,0,2} %bitcast.407.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1237.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1944.clone.1, f32[16,512,1]{1,0,2} %multiply.1238.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/truediv"}
  %multiply.1235.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1945.clone.1, f32[16,512,1]{1,0,2} %multiply.1237.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/Mul"}
  %bitcast.406.clone.1 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.1235.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/Mul"}
  %broadcast.1942.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.406.clone.1), dimensions={0,1}
  %param_9.301 = f16[16,512,768]{2,1,0} parameter(9)
  %convert.610.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_9.301), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_8.449 = f32[16,512]{1,0} parameter(8)
  %multiply.1234.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_8.449, f32[16,512]{1,0} %broadcast.1950.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.1939.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1234.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %subtract.340.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.610.clone.1, f32[16,512,768]{2,1,0} %broadcast.1939.clone.1), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1233.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1942.clone.1, f32[16,512,768]{2,1,0} %subtract.340.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mul_1"}
  %add.594.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1247.clone.1, f32[16,512,768]{2,1,0} %multiply.1233.clone.1), metadata={op_type="AddN" op_name="AddN_16"}
  %param_7.780 = f32[16,512]{1,0} parameter(7)
  %multiply.1232.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1950.clone.1, f32[16,512]{1,0} %param_7.780), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/truediv_1"}
  %broadcast.1937.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1232.clone.1), dimensions={0,1}
  %add.593.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.594.clone.1, f32[16,512,768]{2,1,0} %broadcast.1937.clone.1), metadata={op_type="AddN" op_name="AddN_16"}
  %convert.609.clone.1 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.593.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast/Cast"}
  %param_6.733 = f16[8192,768]{1,0} parameter(6)
  %bitcast.193.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_6.733), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/einsum/Einsum"}
  %add.156.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %convert.609.clone.1, f16[16,512,768]{2,1,0} %bitcast.193.clone.1), metadata={op_type="AddN" op_name="AddN_17"}
  %param_5.842 = f16[8192,768]{1,0} parameter(5)
  %bitcast.192.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_5.842), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/einsum/Einsum"}
  %add.155.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %add.156.clone.1, f16[16,512,768]{2,1,0} %bitcast.192.clone.1), metadata={op_type="AddN" op_name="AddN_17"}
  %param_4.905 = f16[8192,768]{1,0} parameter(4)
  %bitcast.191.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_4.905), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/einsum/Einsum"}
  %add.154.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %add.155.clone.1, f16[16,512,768]{2,1,0} %bitcast.191.clone.1), metadata={op_type="AddN" op_name="AddN_17"}
  %constant_340_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.616.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_340_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %multiply.345.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %add.154.clone.1, f16[16,512,768]{2,1,0} %broadcast.616.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %constant_341_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.617.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_341_clone_1), dimensions={}
  %select.23.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.14.clone.1, f16[16,512,768]{2,1,0} %multiply.345.clone.1, f16[16,512,768]{2,1,0} %broadcast.617.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul_1"}
  %convert.612 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %select.23.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_1/Cast"}
  %negate.40 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %convert.612), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/sub/Neg"}
  %param_1.1564 = f32[16,512]{1,0} parameter(1)
  %multiply.597 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1564, f32[16,512]{1,0} %broadcast.1950.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/variance"}
  %add.244 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.597, f32[16,512]{1,0} %broadcast.1949.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %rsqrt.17 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.244), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/Rsqrt"}
  %broadcast.589 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.17), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %param_0.1138 = f32[768]{0} parameter(0)
  %broadcast.587 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_0.1138), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %multiply.544 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.589, f32[16,512,768]{2,1,0} %broadcast.587), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %multiply.321 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.40, f32[16,512,768]{2,1,0} %multiply.544), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_2/Mul"}
  %constant_315 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.73 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.321, f32[] %constant_315), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_mul_2_Sum-reduction.1689, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_2/Sum"}
  %param_3.1226 = f16[16,512,768]{2,1,0} parameter(3)
  %convert.619.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_3.1226), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast"}
  %multiply.1262.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.612, f32[16,512,768]{2,1,0} %convert.619.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_1/Mul_1"}
  %param_2.1833 = f32[16,512]{1,0} parameter(2)
  %multiply.1261.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1833, f32[16,512]{1,0} %broadcast.1950.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mean"}
  %broadcast.1965.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1261.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %multiply.1260.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.40, f32[16,512,768]{2,1,0} %broadcast.1965.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_2/Mul_1"}
  %add.597.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1262.clone.1, f32[16,512,768]{2,1,0} %multiply.1260.clone.1), metadata={op_type="AddN" op_name="AddN_18"}
  %multiply.322.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.597.clone.1, f32[16,512,768]{2,1,0} %broadcast.587), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul/Mul"}
  %reduce.74.clone.1 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.322.clone.1, f32[] %constant_315), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_mul_Sum-reduction.1711, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul/Sum"}
  ROOT %tuple.126 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.73, f32[16,512]{1,0} %reduce.74.clone.1, f16[16,512,768]{2,1,0} %select.23.clone.1)
}

%fused_computation.209 (param_0.318: f32[768,768], param_1.1710: f32[], param_2.1820: f32[768,768], param_3.1208: f32[], param_4.881: f16[768,768], param_5.815: f32[768,768], param_6.707: f32[], param_7.750: f32[768,768], param_8.407: f32[768,768], param_9.247: f16[768,768], param_10.161: f32[768,768]) -> (f32[768,768], f32[768,768], f32[768,768], f32[768,768], f32[768,768], f32[768,768]) {
  %param_0.318 = f32[768,768]{1,0} parameter(0)
  %param_2.1820 = f32[768,768]{1,0} parameter(2)
  %param_4.881 = f16[768,768]{1,0} parameter(4)
  %convert.631.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_4.881), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/MatMul/Cast/Cast"}
  %constant_1343_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.1974.clone.1 = f32[768,768]{1,0} broadcast(f32[] %constant_1343_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_38"}
  %multiply.1272.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.631.clone.1, f32[768,768]{1,0} %broadcast.1974.clone.1), metadata={op_type="Mul" op_name="mul_38"}
  %subtract.131.clone.1 = f32[768,768]{1,0} subtract(f32[768,768]{1,0} %multiply.1272.clone.1, f32[768,768]{1,0} %param_2.1820), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %constant_317_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1208 = f32[] parameter(3)
  %subtract.250.clone.1 = f32[] subtract(f32[] %constant_317_clone_1, f32[] %param_3.1208), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.592.clone.1 = f32[768,768]{1,0} broadcast(f32[] %subtract.250.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %multiply.326.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %subtract.131.clone.1, f32[768,768]{1,0} %broadcast.592.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %add.142.clone.1 = f32[768,768]{1,0} add(f32[768,768]{1,0} %param_2.1820, f32[768,768]{1,0} %multiply.326.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %param_1.1710 = f32[] parameter(1)
  %broadcast.590 = f32[768,768]{1,0} broadcast(f32[] %param_1.1710), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %multiply.323 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %add.142.clone.1, f32[768,768]{1,0} %broadcast.590), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %param_5.815 = f32[768,768]{1,0} parameter(5)
  %multiply.325.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %multiply.1272.clone.1, f32[768,768]{1,0} %multiply.1272.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %subtract.130.clone.1 = f32[768,768]{1,0} subtract(f32[768,768]{1,0} %multiply.325.clone.1, f32[768,768]{1,0} %param_5.815), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %param_6.707 = f32[] parameter(6)
  %subtract.251.clone.1 = f32[] subtract(f32[] %constant_317_clone_1, f32[] %param_6.707), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.593.clone.1 = f32[768,768]{1,0} broadcast(f32[] %subtract.251.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %multiply.324.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %subtract.130.clone.1, f32[768,768]{1,0} %broadcast.593.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %add.141.clone.1 = f32[768,768]{1,0} add(f32[768,768]{1,0} %param_5.815, f32[768,768]{1,0} %multiply.324.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %sqrt.42 = f32[768,768]{1,0} sqrt(f32[768,768]{1,0} %add.141.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %constant_316 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.591 = f32[768,768]{1,0} broadcast(f32[] %constant_316), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %add.140 = f32[768,768]{1,0} add(f32[768,768]{1,0} %sqrt.42, f32[768,768]{1,0} %broadcast.591), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %divide.44 = f32[768,768]{1,0} divide(f32[768,768]{1,0} %multiply.323, f32[768,768]{1,0} %add.140), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %subtract.129 = f32[768,768]{1,0} subtract(f32[768,768]{1,0} %param_0.318, f32[768,768]{1,0} %divide.44), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %param_7.750 = f32[768,768]{1,0} parameter(7)
  %param_10.161 = f32[768,768]{1,0} parameter(10)
  %param_9.247 = f16[768,768]{1,0} parameter(9)
  %convert.809.clone.1.clone.1 = f32[768,768]{1,0} convert(f16[768,768]{1,0} %param_9.247), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/MatMul/Cast/Cast"}
  %multiply.1393.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %convert.809.clone.1.clone.1, f32[768,768]{1,0} %broadcast.1974.clone.1), metadata={op_type="Mul" op_name="mul_43"}
  %subtract.5.clone.1.clone.1 = f32[768,768]{1,0} subtract(f32[768,768]{1,0} %multiply.1393.clone.1.clone.1, f32[768,768]{1,0} %param_10.161), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %multiply.100.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %subtract.5.clone.1.clone.1, f32[768,768]{1,0} %broadcast.592.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %add.14.clone.1.clone.1 = f32[768,768]{1,0} add(f32[768,768]{1,0} %param_10.161, f32[768,768]{1,0} %multiply.100.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %multiply.97.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %add.14.clone.1.clone.1, f32[768,768]{1,0} %broadcast.590), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %param_8.407 = f32[768,768]{1,0} parameter(8)
  %multiply.99.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %multiply.1393.clone.1.clone.1, f32[768,768]{1,0} %multiply.1393.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %subtract.4.clone.1.clone.1 = f32[768,768]{1,0} subtract(f32[768,768]{1,0} %multiply.99.clone.1.clone.1, f32[768,768]{1,0} %param_8.407), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %multiply.98.clone.1.clone.1 = f32[768,768]{1,0} multiply(f32[768,768]{1,0} %subtract.4.clone.1.clone.1, f32[768,768]{1,0} %broadcast.593.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %add.13.clone.1.clone.1 = f32[768,768]{1,0} add(f32[768,768]{1,0} %param_8.407, f32[768,768]{1,0} %multiply.98.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %sqrt.0.clone.1 = f32[768,768]{1,0} sqrt(f32[768,768]{1,0} %add.13.clone.1.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %add.12.clone.1 = f32[768,768]{1,0} add(f32[768,768]{1,0} %sqrt.0.clone.1, f32[768,768]{1,0} %broadcast.591), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %divide.2.clone.1 = f32[768,768]{1,0} divide(f32[768,768]{1,0} %multiply.97.clone.1, f32[768,768]{1,0} %add.12.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  %subtract.3.clone.1 = f32[768,768]{1,0} subtract(f32[768,768]{1,0} %param_7.750, f32[768,768]{1,0} %divide.2.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_42/update_0/ResourceApplyAdam"}
  ROOT %tuple.92 = (f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) tuple(f32[768,768]{1,0} %subtract.129, f32[768,768]{1,0} %add.142.clone.1, f32[768,768]{1,0} %add.141.clone.1, f32[768,768]{1,0} %subtract.3.clone.1, f32[768,768]{1,0} %add.14.clone.1.clone.1, f32[768,768]{1,0} %add.13.clone.1.clone.1)
}

%fused_computation.217 (param_0.328: f32[768], param_1.1712: f32[], param_2.1824: f32[768], param_3.1212: f32[], param_4.890: f32[768], param_5.829: f32[768], param_6.722: f32[], param_7.775: f32[768], param_8.443: f32[768], param_9.293: f32[768]) -> (f32[768], f32[768], f32[768], f32[768], f32[768]) {
  %param_0.328 = f32[768]{0} parameter(0)
  %param_2.1824 = f32[768]{0} parameter(2)
  %param_4.890 = f32[768]{0} parameter(4)
  %constant_326_clone_1 = f32[] constant(0.0009765625), metadata={op_type="Mul" op_name="mul_1"}
  %broadcast.604.clone.1 = f32[768]{0} broadcast(f32[] %constant_326_clone_1), dimensions={}, metadata={op_type="Mul" op_name="mul_5"}
  %multiply.545.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_4.890, f32[768]{0} %broadcast.604.clone.1), metadata={op_type="Mul" op_name="mul_4"}
  %subtract.137.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.545.clone.1, f32[768]{0} %param_2.1824), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %constant_327_clone_1 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_3.1212 = f32[] parameter(3)
  %subtract.254.clone.1 = f32[] subtract(f32[] %constant_327_clone_1, f32[] %param_3.1212), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.603.clone.1 = f32[768]{0} broadcast(f32[] %subtract.254.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.336.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.137.clone.1, f32[768]{0} %broadcast.603.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %add.148.clone.1 = f32[768]{0} add(f32[768]{0} %param_2.1824, f32[768]{0} %multiply.336.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %param_1.1712 = f32[] parameter(1)
  %broadcast.601 = f32[768]{0} broadcast(f32[] %param_1.1712), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.333 = f32[768]{0} multiply(f32[768]{0} %add.148.clone.1, f32[768]{0} %broadcast.601), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %param_5.829 = f32[768]{0} parameter(5)
  %multiply.335.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.545.clone.1, f32[768]{0} %multiply.545.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %subtract.136.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.335.clone.1, f32[768]{0} %param_5.829), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %param_6.722 = f32[] parameter(6)
  %subtract.255.clone.1 = f32[] subtract(f32[] %constant_327_clone_1, f32[] %param_6.722), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %broadcast.606.clone.1 = f32[768]{0} broadcast(f32[] %subtract.255.clone.1), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.334.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.136.clone.1, f32[768]{0} %broadcast.606.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %add.147.clone.1 = f32[768]{0} add(f32[768]{0} %param_5.829, f32[768]{0} %multiply.334.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %sqrt.44 = f32[768]{0} sqrt(f32[768]{0} %add.147.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %constant_325 = f32[] constant(1e-06), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %broadcast.602 = f32[768]{0} broadcast(f32[] %constant_325), dimensions={}, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %add.146 = f32[768]{0} add(f32[768]{0} %sqrt.44, f32[768]{0} %broadcast.602), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %divide.46 = f32[768]{0} divide(f32[768]{0} %multiply.333, f32[768]{0} %add.146), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %subtract.135 = f32[768]{0} subtract(f32[768]{0} %param_0.328, f32[768]{0} %divide.46), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %param_7.775 = f32[768]{0} parameter(7)
  %param_8.443 = f32[768]{0} parameter(8)
  %multiply.547.clone.1 = f32[768]{0} multiply(f32[768]{0} %param_8.443, f32[768]{0} %broadcast.604.clone.1), metadata={op_type="Mul" op_name="mul_5"}
  %subtract.142.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.547.clone.1, f32[768]{0} %param_7.775), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.344.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.142.clone.1, f32[768]{0} %broadcast.603.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %add.153.clone.1 = f32[768]{0} add(f32[768]{0} %param_7.775, f32[768]{0} %multiply.344.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %param_9.293 = f32[768]{0} parameter(9)
  %multiply.342.clone.1 = f32[768]{0} multiply(f32[768]{0} %multiply.547.clone.1, f32[768]{0} %multiply.547.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %subtract.139.clone.1 = f32[768]{0} subtract(f32[768]{0} %multiply.342.clone.1, f32[768]{0} %param_9.293), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.341.clone.1 = f32[768]{0} multiply(f32[768]{0} %subtract.139.clone.1, f32[768]{0} %broadcast.606.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %add.151.clone.1 = f32[768]{0} add(f32[768]{0} %param_9.293, f32[768]{0} %multiply.341.clone.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  ROOT %tuple.123 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %subtract.135, f32[768]{0} %add.148.clone.1, f32[768]{0} %add.147.clone.1, f32[768]{0} %add.153.clone.1, f32[768]{0} %add.151.clone.1)
}

%fused_computation.225 (param_0.730: f32[], param_1.1116: f32[], param_2.1026: f32[], param_3.510: s64[]) -> f32[] {
  %param_1.1116 = f32[] parameter(1)
  %constant_332 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_2.1026 = f32[] parameter(2)
  %param_3.510 = s64[] parameter(3)
  %constant_65 = s64[] constant(1), metadata={op_type="AddV2" op_name="Adam/add"}
  %add.152 = s64[] add(s64[] %param_3.510, s64[] %constant_65), metadata={op_type="AddV2" op_name="Adam/add"}
  %convert.106 = f32[] convert(s64[] %add.152), metadata={op_type="Cast" op_name="Adam/Cast_1"}
  %power.1 = f32[] power(f32[] %param_2.1026, f32[] %convert.106), metadata={op_type="Pow" op_name="Adam/Pow_1"}
  %subtract.141 = f32[] subtract(f32[] %constant_332, f32[] %power.1), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %sqrt.46 = f32[] sqrt(f32[] %subtract.141), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %multiply.343 = f32[] multiply(f32[] %param_1.1116, f32[] %sqrt.46), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %param_0.730 = f32[] parameter(0)
  %power.0 = f32[] power(f32[] %param_0.730, f32[] %convert.106), metadata={op_type="Pow" op_name="Adam/Pow"}
  %subtract.140 = f32[] subtract(f32[] %constant_332, f32[] %power.0), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  ROOT %divide.48 = f32[] divide(f32[] %multiply.343, f32[] %subtract.140), metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_sub_Sum-reduction.1785 (x.1786: f32[], y.1787: f32[]) -> f32[] {
  %x.1786 = f32[] parameter(0)
  %y.1787 = f32[] parameter(1)
  ROOT %add.1788 = f32[] add(f32[] %x.1786, f32[] %y.1787)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_mul_Sum_1-reduction.1776 (x.1777: f32[], y.1778: f32[]) -> f32[] {
  %x.1777 = f32[] parameter(0)
  %y.1778 = f32[] parameter(1)
  ROOT %add.1779 = f32[] add(f32[] %x.1777, f32[] %y.1778)
}

%fused_computation.227 (param_0.731: f16[16,512,768], param_1.1716: f32[16,512], param_2.1832: f32[16,512], param_3.1221: f16[16,512,768]) -> (f32[768], f32[768]) {
  %param_0.731 = f16[16,512,768]{2,1,0} parameter(0)
  %convert.107 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_0.731), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_1/Cast"}
  %bitcast.190 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %convert.107)
  %constant_339 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.77 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.190, f32[] %constant_339), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_sub_Sum-reduction.1785, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/sub/Sum"}
  %param_3.1221 = f16[16,512,768]{2,1,0} parameter(3)
  %convert.628.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_3.1221), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast"}
  %multiply.1268.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.107, f32[16,512,768]{2,1,0} %convert.628.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_1/Mul_1"}
  %negate.46.clone.1 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %convert.107), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/sub/Neg"}
  %param_2.1832 = f32[16,512]{1,0} parameter(2)
  %constant_563_clone_1 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1971.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_563_clone_1), dimensions={}
  %multiply.1267.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1832, f32[16,512]{1,0} %broadcast.1971.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mean"}
  %broadcast.1969.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1267.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %multiply.1266.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.46.clone.1, f32[16,512,768]{2,1,0} %broadcast.1969.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_2/Mul_1"}
  %add.599.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1268.clone.1, f32[16,512,768]{2,1,0} %multiply.1266.clone.1), metadata={op_type="AddN" op_name="AddN_18"}
  %param_1.1716 = f32[16,512]{1,0} parameter(1)
  %multiply.599.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1716, f32[16,512]{1,0} %broadcast.1971.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/variance"}
  %constant_562_clone_1 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.862.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_562_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.246.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.599.clone.1, f32[16,512]{1,0} %broadcast.862.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %rsqrt.19.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.246.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/Rsqrt"}
  %broadcast.608.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.19.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %multiply.337.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.599.clone.1, f32[16,512,768]{2,1,0} %broadcast.608.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul/Mul_1"}
  %bitcast.189.clone.1 = f32[8192,768]{1,0} bitcast(f32[16,512,768]{2,1,0} %multiply.337.clone.1)
  %reduce.76.clone.1 = f32[768]{0} reduce(f32[8192,768]{1,0} %bitcast.189.clone.1, f32[] %constant_339), dimensions={0}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_batchnorm_mul_Sum_1-reduction.1776, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul/Sum_1"}
  ROOT %tuple.124 = (f32[768]{0}, f32[768]{0}) tuple(f32[768]{0} %reduce.77, f32[768]{0} %reduce.76.clone.1)
}

%fused_computation.229 (param_0.739: f32[768,12,64]) -> f16[768,768] {
  %param_0.739 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.196 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.739), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/einsum/Einsum/Cast"}
  %transpose.140 = f16[12,64,768]{1,0,2} transpose(f16[768,12,64]{2,1,0} %convert.196), dimensions={1,2,0}
  ROOT %bitcast.194 = f16[768,768]{0,1} bitcast(f16[12,64,768]{1,0,2} %transpose.140)
}

%fused_computation.230 (param_0.740: f16[16,12,64,512]) -> f16[8192,768] {
  %param_0.740 = f16[16,12,64,512]{3,2,1,0} parameter(0)
  %transpose.169 = f16[16,512,12,64]{1,3,2,0} transpose(f16[16,12,64,512]{3,2,1,0} %param_0.740), dimensions={0,3,1,2}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum_1"}
  %copy.96 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{1,3,2,0} %transpose.169), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum_1"}
  ROOT %bitcast.195 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.96)
}

%fused_computation.231 (param_0.741: f16[8192,768]) -> f16[16,12,64,512] {
  %param_0.741 = f16[8192,768]{1,0} parameter(0)
  %reshape.322 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.741), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/einsum/Einsum"}
  %transpose.141 = f16[16,12,64,512]{2,3,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %reshape.322), dimensions={0,2,3,1}
  ROOT %copy.97 = f16[16,12,64,512]{3,2,1,0} copy(f16[16,12,64,512]{2,3,1,0} %transpose.141)
}

%fused_computation.232 (param_0.735: f32[768,12,64]) -> f16[768,768] {
  %param_0.735 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.195 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.735), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/einsum/Einsum/Cast"}
  %transpose.142 = f16[12,64,768]{1,0,2} transpose(f16[768,12,64]{2,1,0} %convert.195), dimensions={1,2,0}
  ROOT %bitcast.196 = f16[768,768]{0,1} bitcast(f16[12,64,768]{1,0,2} %transpose.142)
}

%fused_computation.233 (param_0.736: f16[16,12,512,64]) -> f16[8192,768] {
  %param_0.736 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.167 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.736), dimensions={0,2,1,3}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %copy.98 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{3,1,2,0} %transpose.167), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  ROOT %bitcast.197 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.98)
}

%fused_computation.234 (param_0.733: f32[768,12,64]) -> f16[768,768] {
  %param_0.733 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.193 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.733), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/einsum/Einsum/Cast"}
  %transpose.143 = f16[12,64,768]{1,0,2} transpose(f16[768,12,64]{2,1,0} %convert.193), dimensions={1,2,0}
  ROOT %bitcast.198 = f16[768,768]{0,1} bitcast(f16[12,64,768]{1,0,2} %transpose.143)
}

%fused_computation.235 (param_0.734: f16[16,12,512,64]) -> f16[8192,768] {
  %param_0.734 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.166 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.734), dimensions={0,2,1,3}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum/Einsum"}
  %copy.99 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{3,1,2,0} %transpose.166), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum/Einsum"}
  ROOT %bitcast.199 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.99)
}

%fused_computation.236 (param_0.886: f16[8192,768], param_1.1265: f32[12,64]) -> f16[16,12,512,64] {
  %param_1.1265 = f32[12,64]{1,0} parameter(1)
  %convert.237 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1265), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Cast"}
  %broadcast.884 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[12,64]{1,0} %convert.237), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add"}
  %param_0.886 = f16[8192,768]{1,0} parameter(0)
  %reshape.328 = f16[16,512,12,64]{1,3,2,0} reshape(f16[8192,768]{1,0} %param_0.886), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/einsum/Einsum"}
  %add.250 = f16[16,512,12,64]{1,3,2,0} add(f16[16,512,12,64]{1,3,2,0} %broadcast.884, f16[16,512,12,64]{1,3,2,0} %reshape.328), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add"}
  %constant_579 = f16[] constant(0.125), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %broadcast.883 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[] %constant_579), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %multiply.607 = f16[16,512,12,64]{1,3,2,0} multiply(f16[16,512,12,64]{1,3,2,0} %add.250, f16[16,512,12,64]{1,3,2,0} %broadcast.883), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %transpose.144 = f16[16,12,512,64]{2,3,1,0} transpose(f16[16,512,12,64]{1,3,2,0} %multiply.607), dimensions={0,2,1,3}
  ROOT %copy.100 = f16[16,12,512,64]{3,2,1,0} copy(f16[16,12,512,64]{2,3,1,0} %transpose.144)
}

%fused_computation.237 (param_0.1136: f32[16,12,512], param_1.1563: f16[16,12,512,512], param_2.1529: f32[16,12,512], param_3.993: f16[16,12,512,512], param_4.690: f16[16,12,512,512]) -> f16[16,12,512,512] {
  %param_4.690 = f16[16,12,512,512]{3,2,1,0} parameter(4)
  %copy.141 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_4.690), metadata={op_name="XLA_Args"}
  %constant_1331 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1962 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1331), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %compare.112 = pred[16,12,512,512]{2,3,1,0} compare(f16[16,12,512,512]{2,3,1,0} %copy.141, f16[16,12,512,512]{2,3,1,0} %broadcast.1962), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %param_3.993 = f16[16,12,512,512]{3,2,1,0} parameter(3)
  %copy.140 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_3.993), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum"}
  %constant_1330 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1961 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1330), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %multiply.1256 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %copy.140, f16[16,12,512,512]{2,3,1,0} %broadcast.1961), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %constant_1329 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1960 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1329), dimensions={}
  %select.110 = f16[16,12,512,512]{2,3,1,0} select(pred[16,12,512,512]{2,3,1,0} %compare.112, f16[16,12,512,512]{2,3,1,0} %multiply.1256, f16[16,12,512,512]{2,3,1,0} %broadcast.1960), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul_1"}
  %param_0.1136 = f32[16,12,512]{2,1,0} parameter(0)
  %convert.108 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_0.1136), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Sum"}
  %broadcast.241 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.108), dimensions={0,1,2}, metadata={op_type="Sub" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/sub"}
  %subtract.143 = f16[16,12,512,512]{2,3,1,0} subtract(f16[16,12,512,512]{2,3,1,0} %select.110, f16[16,12,512,512]{2,3,1,0} %broadcast.241), metadata={op_type="Sub" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/sub"}
  %param_1.1563 = f16[16,12,512,512]{2,3,1,0} parameter(1)
  %param_2.1529 = f32[16,12,512]{2,1,0} parameter(2)
  %convert.243 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_2.1529), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %broadcast.890 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.243), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %divide.59 = f16[16,12,512,512]{2,3,1,0} divide(f16[16,12,512,512]{2,3,1,0} %param_1.1563, f16[16,12,512,512]{2,3,1,0} %broadcast.890), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %multiply.346 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %subtract.143, f16[16,12,512,512]{2,3,1,0} %divide.59), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/mul_1"}
  ROOT %copy.101 = f16[16,12,512,512]{3,2,1,0} copy(f16[16,12,512,512]{2,3,1,0} %multiply.346), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/mul_1"}
}

%fused_computation.238 (param_0.1134: f16[16,12,512,512], param_1.1561: f32[16,12,512], param_2.1528: f16[16,12,512,512], param_3.991: f16[16,12,512,512]) -> f32[16,12,512,512] {
  %param_3.991 = f16[16,12,512,512]{3,2,1,0} parameter(3)
  %copy.137 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_3.991), metadata={op_name="XLA_Args"}
  %constant_1323 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1956 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1323), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %compare.110 = pred[16,12,512,512]{2,3,1,0} compare(f16[16,12,512,512]{2,3,1,0} %copy.137, f16[16,12,512,512]{2,3,1,0} %broadcast.1956), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %param_2.1528 = f16[16,12,512,512]{3,2,1,0} parameter(2)
  %copy.136 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_2.1528), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum"}
  %constant_1322 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1955 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1322), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %multiply.1254 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %copy.136, f16[16,12,512,512]{2,3,1,0} %broadcast.1955), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %constant_1321 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1954 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1321), dimensions={}
  %select.108 = f16[16,12,512,512]{2,3,1,0} select(pred[16,12,512,512]{2,3,1,0} %compare.110, f16[16,12,512,512]{2,3,1,0} %multiply.1254, f16[16,12,512,512]{2,3,1,0} %broadcast.1954), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul_1"}
  %param_0.1134 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %param_1.1561 = f32[16,12,512]{2,1,0} parameter(1)
  %convert.241 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_1.1561), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %broadcast.888 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.241), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %divide.57 = f16[16,12,512,512]{2,3,1,0} divide(f16[16,12,512,512]{2,3,1,0} %param_0.1134, f16[16,12,512,512]{2,3,1,0} %broadcast.888), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %multiply.347 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %select.108, f16[16,12,512,512]{2,3,1,0} %divide.57), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/mul"}
  %convert.109 = f32[16,12,512,512]{2,3,1,0} convert(f16[16,12,512,512]{2,3,1,0} %multiply.347), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Sum"}
  ROOT %bitcast.200 = f32[16,12,512,512]{3,2,1,0} bitcast(f32[16,12,512,512]{2,3,1,0} %convert.109), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Sum"}
}

%fused_computation.240 (param_0.902: f16[8192,768], param_1.1284: f32[12,64]) -> f16[16,12,64,512] {
  %param_1.1284 = f32[12,64]{1,0} parameter(1)
  %convert.248 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1284), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Cast"}
  %broadcast.898 = f16[16,512,12,64]{3,1,2,0} broadcast(f16[12,64]{1,0} %convert.248), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add"}
  %param_0.902 = f16[8192,768]{1,0} parameter(0)
  %reshape.336 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.902), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/einsum/Einsum"}
  %add.254 = f16[16,512,12,64]{3,1,2,0} add(f16[16,512,12,64]{3,1,2,0} %broadcast.898, f16[16,512,12,64]{3,1,2,0} %reshape.336), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add"}
  %transpose.145 = f16[16,12,64,512]{2,3,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %add.254), dimensions={0,2,3,1}
  ROOT %copy.103 = f16[16,12,64,512]{3,2,1,0} copy(f16[16,12,64,512]{2,3,1,0} %transpose.145)
}

%fused_computation.241 (param_0.742: f32[12,64,768]) -> f16[768,768] {
  %param_0.742 = f32[12,64,768]{2,1,0} parameter(0)
  %convert.197 = f16[12,64,768]{2,1,0} convert(f32[12,64,768]{2,1,0} %param_0.742), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/einsum/Einsum/Cast"}
  %transpose.146 = f16[768,12,64]{0,2,1} transpose(f16[12,64,768]{2,1,0} %convert.197), dimensions={2,0,1}
  ROOT %bitcast.201 = f16[768,768]{0,1} bitcast(f16[768,12,64]{0,2,1} %transpose.146)
}

%fused_computation.242 (param_0.1131: f16[16,512,768], param_1.1558: f32[16,512], param_2.1524: f32[16,512], param_3.984: f16[16,512,768], param_4.675: f32[16,512], param_5.433: f32[16,512,768], param_6.426: f32[768], param_7.371: f32[16,512]) -> f16[16,512,768] {
  %param_0.1131 = f16[16,512,768]{2,1,0} parameter(0)
  %constant_347 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.624 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_347), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.15 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_0.1131, f16[16,512,768]{2,1,0} %broadcast.624), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout/dropout/GreaterEqual"}
  %param_5.433 = f32[16,512,768]{2,1,0} parameter(5)
  %param_7.371 = f32[16,512]{1,0} parameter(7)
  %constant_1294 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1924 = f32[16,512]{1,0} broadcast(f32[] %constant_1294), dimensions={}
  %multiply.1217 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_7.371, f32[16,512]{1,0} %broadcast.1924), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %constant_1299 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1923 = f32[16,512]{1,0} broadcast(f32[] %constant_1299), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.588 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1217, f32[16,512]{1,0} %broadcast.1923), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.113 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.588), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1922 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.113), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_6.426 = f32[768]{0} parameter(6)
  %broadcast.1921 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_6.426), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1215 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1922, f32[16,512,768]{2,1,0} %broadcast.1921), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1214 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %param_5.433, f32[16,512,768]{2,1,0} %multiply.1215), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1298 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1920 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1298), dimensions={}
  %broadcast.1919 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1294), dimensions={}
  %bitcast.402 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.113), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %multiply.1213 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.402, f32[16,512,1]{1,0,2} %bitcast.402), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1211 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1213, f32[16,512,1]{1,0,2} %bitcast.402), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %param_4.675 = f32[16,512]{1,0} parameter(4)
  %constant_1295 = f32[] constant(-0.5)
  %broadcast.1918 = f32[16,512]{1,0} broadcast(f32[] %constant_1295), dimensions={}
  %multiply.1210 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.675, f32[16,512]{1,0} %broadcast.1918), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.401 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.1210), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1208 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1211, f32[16,512,1]{1,0,2} %bitcast.401), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1207 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1919, f32[16,512,1]{1,0,2} %multiply.1208), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/truediv"}
  %multiply.1206 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1920, f32[16,512,1]{1,0,2} %multiply.1207), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/Mul"}
  %bitcast.400 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.1206), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/Mul"}
  %broadcast.1917 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.400), dimensions={0,1}
  %param_3.984 = f16[16,512,768]{2,1,0} parameter(3)
  %convert.605 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_3.984), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_2.1524 = f32[16,512]{1,0} parameter(2)
  %multiply.1205 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1524, f32[16,512]{1,0} %broadcast.1924), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.1915 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1205), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %subtract.338 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.605, f32[16,512,768]{2,1,0} %broadcast.1915), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1204 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1917, f32[16,512,768]{2,1,0} %subtract.338), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mul_1"}
  %add.587 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1214, f32[16,512,768]{2,1,0} %multiply.1204), metadata={op_type="AddN" op_name="AddN_16"}
  %param_1.1558 = f32[16,512]{1,0} parameter(1)
  %multiply.1200 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1924, f32[16,512]{1,0} %param_1.1558), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/truediv_1"}
  %broadcast.1913 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1200), dimensions={0,1}
  %add.586 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.587, f32[16,512,768]{2,1,0} %broadcast.1913), metadata={op_type="AddN" op_name="AddN_16"}
  %convert.604 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.586), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast/Cast"}
  %constant_345 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.622 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_345), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %multiply.349 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %convert.604, f16[16,512,768]{2,1,0} %broadcast.622), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout/dropout/Mul"}
  %constant_346 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.623 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_346), dimensions={}
  ROOT %select.25 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.15, f16[16,512,768]{2,1,0} %multiply.349, f16[16,512,768]{2,1,0} %broadcast.623), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout/dropout/Mul_1"}
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_2_Sum-reduction.1535 (x.1536: f32[], y.1537: f32[]) -> f32[] {
  %x.1536 = f32[] parameter(0)
  %y.1537 = f32[] parameter(1)
  ROOT %add.1538 = f32[] add(f32[] %x.1536, f32[] %y.1537)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_Sum-reduction.1557 (x.1558: f32[], y.1559: f32[]) -> f32[] {
  %x.1558 = f32[] parameter(0)
  %y.1559 = f32[] parameter(1)
  ROOT %add.1560 = f32[] add(f32[] %x.1558, f32[] %y.1559)
}

%fused_computation.244 (param_0.1225: f32[768], param_1.1717: f32[16,512], param_2.1834: f32[16,512], param_3.1231: f16[16,512,768], param_4.915: f16[8192,768], param_5.851: f32[16,512], param_6.742: f32[16,512,768], param_7.785: f32[16,512], param_8.457: f32[768], param_9.310: f32[16,512], param_10.225: f16[16,512,768]) -> (f32[16,512], f32[16,512], f32[16,512,768]) {
  %param_10.225 = f16[16,512,768]{2,1,0} parameter(10)
  %convert.596.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_10.225), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_2/Cast"}
  %param_9.310 = f32[16,512]{1,0} parameter(9)
  %constant_629 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1891.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_629), dimensions={}
  %multiply.1172.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_9.310, f32[16,512]{1,0} %broadcast.1891.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/variance"}
  %constant_628 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1890.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_628), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.576.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1172.clone.1, f32[16,512]{1,0} %broadcast.1890.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/add"}
  %rsqrt.111.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.576.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1889.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.111.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %param_8.457 = f32[768]{0} parameter(8)
  %broadcast.1888.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_8.457), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.1171.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1889.clone.1, f32[16,512,768]{2,1,0} %broadcast.1888.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.1170.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.596.clone.1, f32[16,512,768]{2,1,0} %multiply.1171.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1277_clone_1 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1887.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1277_clone_1), dimensions={}
  %broadcast.1886.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_629), dimensions={}
  %bitcast.396.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.111.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt"}
  %multiply.1169.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.396.clone.1, f32[16,512,1]{1,0,2} %bitcast.396.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1168.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1169.clone.1, f32[16,512,1]{1,0,2} %bitcast.396.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %param_7.785 = f32[16,512]{1,0} parameter(7)
  %constant_1274_clone_1 = f32[] constant(-0.5)
  %broadcast.1885.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_1274_clone_1), dimensions={}
  %multiply.1167.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_7.785, f32[16,512]{1,0} %broadcast.1885.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.395.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.1167.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1166.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1168.clone.1, f32[16,512,1]{1,0,2} %bitcast.395.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1164.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1886.clone.1, f32[16,512,1]{1,0,2} %multiply.1166.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/truediv"}
  %multiply.1161.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1887.clone.1, f32[16,512,1]{1,0,2} %multiply.1164.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/Mul"}
  %bitcast.394.clone.1 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.1161.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/Mul"}
  %broadcast.1884.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.394.clone.1), dimensions={0,1}
  %param_6.742 = f32[16,512,768]{2,1,0} parameter(6)
  %multiply.1160.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1884.clone.1, f32[16,512,768]{2,1,0} %param_6.742), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mul_1"}
  %add.575.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1170.clone.1, f32[16,512,768]{2,1,0} %multiply.1160.clone.1), metadata={op_type="AddN" op_name="AddN_12"}
  %param_5.851 = f32[16,512]{1,0} parameter(5)
  %multiply.1159.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1891.clone.1, f32[16,512]{1,0} %param_5.851), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/truediv_1"}
  %broadcast.1882.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1159.clone.1), dimensions={0,1}
  %add.574.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.575.clone.1, f32[16,512,768]{2,1,0} %broadcast.1882.clone.1), metadata={op_type="AddN" op_name="AddN_12"}
  %param_4.915 = f16[8192,768]{1,0} parameter(4)
  %convert.112.clone.1 = f32[8192,768]{1,0} convert(f16[8192,768]{1,0} %param_4.915), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_1/Cast"}
  %bitcast.205.clone.1 = f32[16,512,768]{2,1,0} bitcast(f32[8192,768]{1,0} %convert.112.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_1/Cast"}
  %add.160.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.574.clone.1, f32[16,512,768]{2,1,0} %bitcast.205.clone.1), metadata={op_type="AddN" op_name="AddN_14"}
  %negate.6 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %add.160.clone.1), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub/Neg"}
  %param_1.1717 = f32[16,512]{1,0} parameter(1)
  %multiply.627 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1717, f32[16,512]{1,0} %broadcast.1891.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %add.262 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.627, f32[16,512]{1,0} %broadcast.1890.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.27 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.262), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.634 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.27), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_0.1225 = f32[768]{0} parameter(0)
  %broadcast.632 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_0.1225), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.550 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.634, f32[16,512,768]{2,1,0} %broadcast.632), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.359 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.6, f32[16,512,768]{2,1,0} %multiply.550), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2/Mul"}
  %constant_353 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.78 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.359, f32[] %constant_353), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_2_Sum-reduction.1535, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2/Sum"}
  %param_3.1231 = f16[16,512,768]{2,1,0} parameter(3)
  %convert.598.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_3.1231), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %multiply.1178.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.160.clone.1, f32[16,512,768]{2,1,0} %convert.598.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1/Mul_1"}
  %param_2.1834 = f32[16,512]{1,0} parameter(2)
  %multiply.1177.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1834, f32[16,512]{1,0} %broadcast.1891.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.1894.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1177.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1176.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.6, f32[16,512,768]{2,1,0} %broadcast.1894.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.579.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1178.clone.1, f32[16,512,768]{2,1,0} %multiply.1176.clone.1), metadata={op_type="AddN" op_name="AddN_15"}
  %multiply.360.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.579.clone.1, f32[16,512,768]{2,1,0} %broadcast.632), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/Mul"}
  %reduce.79.clone.1 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.360.clone.1, f32[] %constant_353), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_batchnorm_mul_Sum-reduction.1557, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul/Sum"}
  ROOT %tuple.129 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.78, f32[16,512]{1,0} %reduce.79.clone.1, f32[16,512,768]{2,1,0} %add.160.clone.1)
}

%fused_computation.248 (param_0.752: f16[16,512,3072], param_1.1139: f16[8192,3072], param_2.1221: f16[16,512,3072], param_3.687: f16[8192,3072], param_4.382: f32[3072]) -> f16[16,512,3072] {
  %param_4.382 = f32[3072]{0} parameter(4)
  %convert.266 = f16[3072]{0} convert(f32[3072]{0} %param_4.382), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Cast"}
  %broadcast.975 = f16[16,512,3072]{2,1,0} broadcast(f16[3072]{0} %convert.266), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add"}
  %param_3.687 = f16[8192,3072]{1,0} parameter(3)
  %bitcast.274 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_3.687), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/einsum/Einsum"}
  %add.272 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.975, f16[16,512,3072]{2,1,0} %bitcast.274), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add"}
  %multiply.552 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.272, f16[16,512,3072]{2,1,0} %add.272)
  %param_2.1221 = f16[16,512,3072]{2,1,0} parameter(2)
  %constant_359 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.640 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_359), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/GreaterEqual"}
  %compare.16 = pred[16,512,3072]{2,1,0} compare(f16[16,512,3072]{2,1,0} %param_2.1221, f16[16,512,3072]{2,1,0} %broadcast.640), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %param_1.1139 = f16[8192,3072]{1,0} parameter(1)
  %bitcast.206 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_1.1139), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum"}
  %select.26 = f16[16,512,3072]{2,1,0} select(pred[16,512,3072]{2,1,0} %compare.16, f16[16,512,3072]{2,1,0} %bitcast.206, f16[16,512,3072]{2,1,0} %broadcast.640), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/Mul"}
  %constant_355 = f16[] constant(0.5), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %broadcast.636 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_355), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %multiply.551 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.272, f16[16,512,3072]{2,1,0} %broadcast.636), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %multiply.371 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %select.26, f16[16,512,3072]{2,1,0} %multiply.551), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_3/Mul_1"}
  %constant_358 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.639 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_358), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/add_1"}
  %param_0.752 = f16[16,512,3072]{2,1,0} parameter(0)
  %multiply.370 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %param_0.752, f16[16,512,3072]{2,1,0} %param_0.752), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/TanhGrad"}
  %subtract.144 = f16[16,512,3072]{2,1,0} subtract(f16[16,512,3072]{2,1,0} %broadcast.639, f16[16,512,3072]{2,1,0} %multiply.370), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/TanhGrad"}
  %multiply.369 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.371, f16[16,512,3072]{2,1,0} %subtract.144), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/TanhGrad"}
  %constant_356 = f16[] constant(0.79785), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %broadcast.637 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_356), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %multiply.368 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.369, f16[16,512,3072]{2,1,0} %broadcast.637), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2/Mul"}
  %multiply.367 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.552, f16[16,512,3072]{2,1,0} %multiply.368), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/Pow/mul"}
  %constant_354 = f16[] constant(0.13416), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/mul_1"}
  %broadcast.635 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_354), dimensions={}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/Pow/mul_1"}
  %multiply.365 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.367, f16[16,512,3072]{2,1,0} %broadcast.635), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/Pow/mul_1"}
  %multiply.364 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %select.26, f16[16,512,3072]{2,1,0} %broadcast.636), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_3/Mul"}
  %add.229 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.639, f16[16,512,3072]{2,1,0} %param_0.752), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/add_1"}
  %multiply.363 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.364, f16[16,512,3072]{2,1,0} %add.229), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul/Mul"}
  %add.162 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %multiply.365, f16[16,512,3072]{2,1,0} %multiply.363), metadata={op_type="AddN" op_name="AddN_13"}
  ROOT %add.161 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %add.162, f16[16,512,3072]{2,1,0} %multiply.368), metadata={op_type="AddN" op_name="AddN_13"}
}

%fused_computation.249 (param_0.1123: f16[16,512,768], param_1.1545: f32[16,512], param_2.1498: f32[16,512,768], param_3.960: f32[16,512], param_4.656: f32[768], param_5.414: f32[16,512], param_6.402: f16[16,512,768]) -> f16[16,512,768] {
  %param_0.1123 = f16[16,512,768]{2,1,0} parameter(0)
  %constant_362 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.643 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_362), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.17 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_0.1123, f16[16,512,768]{2,1,0} %broadcast.643), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/GreaterEqual"}
  %param_6.402 = f16[16,512,768]{2,1,0} parameter(6)
  %convert.594 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_6.402), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_2/Cast"}
  %param_5.414 = f32[16,512]{1,0} parameter(5)
  %constant_1264 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1870 = f32[16,512]{1,0} broadcast(f32[] %constant_1264), dimensions={}
  %multiply.1147 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_5.414, f32[16,512]{1,0} %broadcast.1870), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/variance"}
  %constant_1266 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1869 = f32[16,512]{1,0} broadcast(f32[] %constant_1266), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.569 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1147, f32[16,512]{1,0} %broadcast.1869), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/add"}
  %rsqrt.109 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.569), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1868 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.109), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %param_4.656 = f32[768]{0} parameter(4)
  %broadcast.1867 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_4.656), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.1146 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1868, f32[16,512,768]{2,1,0} %broadcast.1867), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.1145 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.594, f32[16,512,768]{2,1,0} %multiply.1146), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1265 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1866 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1265), dimensions={}
  %broadcast.1865 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1264), dimensions={}
  %bitcast.390 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.109), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt"}
  %multiply.1144 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.390, f32[16,512,1]{1,0,2} %bitcast.390), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1143 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1144, f32[16,512,1]{1,0,2} %bitcast.390), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %param_3.960 = f32[16,512]{1,0} parameter(3)
  %constant_1263 = f32[] constant(-0.5)
  %broadcast.1864 = f32[16,512]{1,0} broadcast(f32[] %constant_1263), dimensions={}
  %multiply.1142 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.960, f32[16,512]{1,0} %broadcast.1864), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.389 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.1142), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1141 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1143, f32[16,512,1]{1,0,2} %bitcast.389), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1140 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1865, f32[16,512,1]{1,0,2} %multiply.1141), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/truediv"}
  %multiply.1139 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1866, f32[16,512,1]{1,0,2} %multiply.1140), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/Mul"}
  %bitcast.388 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.1139), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/Mul"}
  %broadcast.1863 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.388), dimensions={0,1}
  %param_2.1498 = f32[16,512,768]{2,1,0} parameter(2)
  %multiply.1138 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1863, f32[16,512,768]{2,1,0} %param_2.1498), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mul_1"}
  %add.568 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1145, f32[16,512,768]{2,1,0} %multiply.1138), metadata={op_type="AddN" op_name="AddN_12"}
  %param_1.1545 = f32[16,512]{1,0} parameter(1)
  %multiply.1137 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1870, f32[16,512]{1,0} %param_1.1545), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/truediv_1"}
  %broadcast.1861 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1137), dimensions={0,1}
  %add.567 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.568, f32[16,512,768]{2,1,0} %broadcast.1861), metadata={op_type="AddN" op_name="AddN_12"}
  %convert.113 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.567), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_2/Cast"}
  %constant_360 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.641 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_360), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %multiply.372 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %convert.113, f16[16,512,768]{2,1,0} %broadcast.641), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul"}
  %constant_361 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.642 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_361), dimensions={}
  ROOT %select.27 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.17, f16[16,512,768]{2,1,0} %multiply.372, f16[16,512,768]{2,1,0} %broadcast.642), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul_1"}
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_mul_2_Sum-reduction.1427 (x.1428: f32[], y.1429: f32[]) -> f32[] {
  %x.1428 = f32[] parameter(0)
  %y.1429 = f32[] parameter(1)
  ROOT %add.1430 = f32[] add(f32[] %x.1428, f32[] %y.1429)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_mul_Sum-reduction.1449 (x.1450: f32[], y.1451: f32[]) -> f32[] {
  %x.1450 = f32[] parameter(0)
  %y.1451 = f32[] parameter(1)
  ROOT %add.1452 = f32[] add(f32[] %x.1450, f32[] %y.1451)
}

%fused_computation.251 (param_0.1115: f32[768], param_1.1535: f32[16,512], param_2.1843: f32[16,512], param_3.1245: f32[16,512], param_4.931: f32[768], param_5.868: f32[768], param_6.758: f32[16,512], param_7.801: f16[16,512,768], param_8.476: f16[8192,768], param_9.334: f32[768], param_10.248: f16[16,512,768], param_11.289: f16[8192,768], param_12.217: f16[8192,768], param_13.75: f16[8192,768], param_14.57: f32[16,512], param_15.98: f32[16,512], param_16.76: f16[16,512,768], param_17.32: f32[16,512], param_18.31: f32[16,512,768], param_19.81: f32[768], param_20.70: f32[16,512]) -> (f32[16,512], f32[16,512], f16[16,512,768]) {
  %param_18.31 = f32[16,512,768]{2,1,0} parameter(18)
  %param_20.70 = f32[16,512]{1,0} parameter(20)
  %constant_741 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1783.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_741), dimensions={}
  %multiply.1068.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_20.70, f32[16,512]{1,0} %broadcast.1783.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_740 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1782.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_740), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.541.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1068.clone.1, f32[16,512]{1,0} %broadcast.1782.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.103.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.541.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1781.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.103.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_19.81 = f32[768]{0} parameter(19)
  %broadcast.1780.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_19.81), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1067.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1781.clone.1, f32[16,512,768]{2,1,0} %broadcast.1780.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1066.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %param_18.31, f32[16,512,768]{2,1,0} %multiply.1067.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1199_clone_1 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1779.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1199_clone_1), dimensions={}
  %broadcast.1778.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_741), dimensions={}
  %bitcast.380.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.103.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %multiply.1064.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.380.clone.1, f32[16,512,1]{1,0,2} %bitcast.380.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1061.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1064.clone.1, f32[16,512,1]{1,0,2} %bitcast.380.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %param_17.32 = f32[16,512]{1,0} parameter(17)
  %constant_1196_clone_1 = f32[] constant(-0.5)
  %broadcast.1777.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_1196_clone_1), dimensions={}
  %multiply.1060.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_17.32, f32[16,512]{1,0} %broadcast.1777.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.379.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.1060.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1059.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1061.clone.1, f32[16,512,1]{1,0,2} %bitcast.379.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1058.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1778.clone.1, f32[16,512,1]{1,0,2} %multiply.1059.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/truediv"}
  %multiply.1057.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1779.clone.1, f32[16,512,1]{1,0,2} %multiply.1058.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/Mul"}
  %bitcast.378.clone.1 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.1057.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/Mul"}
  %broadcast.1776.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.378.clone.1), dimensions={0,1}
  %param_16.76 = f16[16,512,768]{2,1,0} parameter(16)
  %convert.567.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_16.76), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_15.98 = f32[16,512]{1,0} parameter(15)
  %multiply.1056.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_15.98, f32[16,512]{1,0} %broadcast.1783.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1774.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1056.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %subtract.332.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.567.clone.1, f32[16,512,768]{2,1,0} %broadcast.1774.clone.1), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1055.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1776.clone.1, f32[16,512,768]{2,1,0} %subtract.332.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mul_1"}
  %add.540.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1066.clone.1, f32[16,512,768]{2,1,0} %multiply.1055.clone.1), metadata={op_type="AddN" op_name="AddN_9"}
  %param_14.57 = f32[16,512]{1,0} parameter(14)
  %multiply.1054.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1783.clone.1, f32[16,512]{1,0} %param_14.57), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/truediv_1"}
  %broadcast.1772.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1054.clone.1), dimensions={0,1}
  %add.539.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.540.clone.1, f32[16,512,768]{2,1,0} %broadcast.1772.clone.1), metadata={op_type="AddN" op_name="AddN_9"}
  %convert.566.clone.1 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.539.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast/Cast"}
  %param_13.75 = f16[8192,768]{1,0} parameter(13)
  %bitcast.212.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_13.75), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/einsum/Einsum"}
  %add.168.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %convert.566.clone.1, f16[16,512,768]{2,1,0} %bitcast.212.clone.1), metadata={op_type="AddN" op_name="AddN_10"}
  %param_12.217 = f16[8192,768]{1,0} parameter(12)
  %bitcast.211.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_12.217), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/einsum/Einsum"}
  %add.167.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %add.168.clone.1, f16[16,512,768]{2,1,0} %bitcast.211.clone.1), metadata={op_type="AddN" op_name="AddN_10"}
  %param_11.289 = f16[8192,768]{1,0} parameter(11)
  %bitcast.210.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_11.289), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/einsum/Einsum"}
  %add.166.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %add.167.clone.1, f16[16,512,768]{2,1,0} %bitcast.210.clone.1), metadata={op_type="AddN" op_name="AddN_10"}
  %convert.569 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %add.166.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_2/Cast"}
  %negate.28 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %convert.569), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/sub/Neg"}
  %param_1.1535 = f32[16,512]{1,0} parameter(1)
  %multiply.721 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1535, f32[16,512]{1,0} %broadcast.1783.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/variance"}
  %add.316 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.721, f32[16,512]{1,0} %broadcast.1782.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/add"}
  %rsqrt.47 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.316), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.653 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.47), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %param_0.1115 = f32[768]{0} parameter(0)
  %broadcast.652 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_0.1115), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.554 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.653, f32[16,512,768]{2,1,0} %broadcast.652), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.382 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.28, f32[16,512,768]{2,1,0} %multiply.554), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_2/Mul"}
  %constant_367 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.80 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.382, f32[] %constant_367), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_mul_2_Sum-reduction.1427, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_2/Sum"}
  %param_10.248 = f16[16,512,768]{2,1,0} parameter(10)
  %constant_1236_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1822.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1236_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.106.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_10.248, f16[16,512,768]{2,1,0} %broadcast.1822.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/GreaterEqual"}
  %constant_1235_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1821.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1235_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_1234_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1820.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1234_clone_1), dimensions={}
  %select.104.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.106.clone.1, f16[16,512,768]{2,1,0} %broadcast.1821.clone.1, f16[16,512,768]{2,1,0} %broadcast.1820.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul"}
  %param_9.334 = f32[768]{0} parameter(9)
  %convert.581.clone.1 = f16[768]{0} convert(f32[768]{0} %param_9.334), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Cast"}
  %broadcast.1819.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.581.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %param_8.476 = f16[8192,768]{1,0} parameter(8)
  %bitcast.382.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_8.476), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum"}
  %add.552.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1819.clone.1, f16[16,512,768]{2,1,0} %bitcast.382.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %multiply.1093.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.104.clone.1, f16[16,512,768]{2,1,0} %add.552.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul_1"}
  %convert.580.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.1093.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_2"}
  %param_7.801 = f16[16,512,768]{2,1,0} parameter(7)
  %convert.579.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_7.801), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_6.758 = f32[16,512]{1,0} parameter(6)
  %multiply.1092.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_6.758, f32[16,512]{1,0} %broadcast.1783.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %add.551.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1092.clone.1, f32[16,512]{1,0} %broadcast.1782.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.105.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.551.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1816.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.105.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_5.868 = f32[768]{0} parameter(5)
  %broadcast.1815.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_5.868), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1091.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1816.clone.1, f32[16,512,768]{2,1,0} %broadcast.1815.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1090.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.579.clone.1, f32[16,512,768]{2,1,0} %multiply.1091.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1"}
  %param_4.931 = f32[768]{0} parameter(4)
  %broadcast.1814.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_4.931), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %param_3.1245 = f32[16,512]{1,0} parameter(3)
  %multiply.1089.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.1245, f32[16,512]{1,0} %broadcast.1783.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.1812.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1089.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1088.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.1091.clone.1, f32[16,512,768]{2,1,0} %broadcast.1812.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.334.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1814.clone.1, f32[16,512,768]{2,1,0} %multiply.1088.clone.1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %add.549.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1090.clone.1, f32[16,512,768]{2,1,0} %subtract.334.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1"}
  %add.548.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.580.clone.1, f32[16,512,768]{2,1,0} %add.549.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/add_1"}
  %multiply.1086.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.569, f32[16,512,768]{2,1,0} %add.548.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_1/Mul_1"}
  %param_2.1843 = f32[16,512]{1,0} parameter(2)
  %multiply.1085.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1843, f32[16,512]{1,0} %broadcast.1783.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mean"}
  %broadcast.1810.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1085.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/SquaredDifference"}
  %multiply.1083.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.28, f32[16,512,768]{2,1,0} %broadcast.1810.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.547.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1086.clone.1, f32[16,512,768]{2,1,0} %multiply.1083.clone.1), metadata={op_type="AddN" op_name="AddN_11"}
  %multiply.383.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.547.clone.1, f32[16,512,768]{2,1,0} %broadcast.652), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul/Mul"}
  %reduce.81.clone.1 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.383.clone.1, f32[] %constant_367), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_batchnorm_mul_Sum-reduction.1449, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul/Sum"}
  ROOT %tuple.132 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.80, f32[16,512]{1,0} %reduce.81.clone.1, f16[16,512,768]{2,1,0} %add.166.clone.1)
}

%fused_computation.256 (param_0.764: f32[768,12,64]) -> f16[768,768] {
  %param_0.764 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.201 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.764), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/einsum/Einsum/Cast"}
  %transpose.147 = f16[12,64,768]{1,0,2} transpose(f16[768,12,64]{2,1,0} %convert.201), dimensions={1,2,0}
  ROOT %bitcast.213 = f16[768,768]{0,1} bitcast(f16[12,64,768]{1,0,2} %transpose.147)
}

%fused_computation.257 (param_0.765: f16[16,12,64,512]) -> f16[8192,768] {
  %param_0.765 = f16[16,12,64,512]{3,2,1,0} parameter(0)
  %transpose.173 = f16[16,512,12,64]{1,3,2,0} transpose(f16[16,12,64,512]{3,2,1,0} %param_0.765), dimensions={0,3,1,2}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum_1"}
  %copy.104 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{1,3,2,0} %transpose.173), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum_1"}
  ROOT %bitcast.214 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.104)
}

%fused_computation.258 (param_0.766: f16[8192,768]) -> f16[16,12,64,512] {
  %param_0.766 = f16[8192,768]{1,0} parameter(0)
  %reshape.324 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.766), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/einsum/Einsum"}
  %transpose.148 = f16[16,12,64,512]{2,3,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %reshape.324), dimensions={0,2,3,1}
  ROOT %copy.105 = f16[16,12,64,512]{3,2,1,0} copy(f16[16,12,64,512]{2,3,1,0} %transpose.148)
}

%fused_computation.259 (param_0.760: f32[768,12,64]) -> f16[768,768] {
  %param_0.760 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.199 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.760), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/einsum/Einsum/Cast"}
  %transpose.149 = f16[12,64,768]{1,0,2} transpose(f16[768,12,64]{2,1,0} %convert.199), dimensions={1,2,0}
  ROOT %bitcast.215 = f16[768,768]{0,1} bitcast(f16[12,64,768]{1,0,2} %transpose.149)
}

%fused_computation.260 (param_0.761: f16[16,12,512,64]) -> f16[8192,768] {
  %param_0.761 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.171 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.761), dimensions={0,2,1,3}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/Mul"}
  %copy.106 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{3,1,2,0} %transpose.171), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/Mul"}
  ROOT %bitcast.216 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.106)
}

%fused_computation.261 (param_0.758: f32[768,12,64]) -> f16[768,768] {
  %param_0.758 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.198 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.758), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/einsum/Einsum/Cast"}
  %transpose.150 = f16[12,64,768]{1,0,2} transpose(f16[768,12,64]{2,1,0} %convert.198), dimensions={1,2,0}
  ROOT %bitcast.217 = f16[768,768]{0,1} bitcast(f16[12,64,768]{1,0,2} %transpose.150)
}

%fused_computation.262 (param_0.759: f16[16,12,512,64]) -> f16[8192,768] {
  %param_0.759 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.170 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.759), dimensions={0,2,1,3}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum/Einsum"}
  %copy.107 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{3,1,2,0} %transpose.170), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum/Einsum"}
  ROOT %bitcast.218 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.107)
}

%fused_computation.263 (param_0.952: f16[8192,768], param_1.1340: f32[12,64]) -> f16[16,12,512,64] {
  %constant_747 = f16[] constant(0.125), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %broadcast.1133 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[] %constant_747), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %param_1.1340 = f32[12,64]{1,0} parameter(1)
  %convert.315 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1340), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Cast"}
  %broadcast.1132 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[12,64]{1,0} %convert.315), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add"}
  %param_0.952 = f16[8192,768]{1,0} parameter(0)
  %reshape.340 = f16[16,512,12,64]{1,3,2,0} reshape(f16[8192,768]{1,0} %param_0.952), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/einsum/Einsum"}
  %add.320 = f16[16,512,12,64]{1,3,2,0} add(f16[16,512,12,64]{1,3,2,0} %broadcast.1132, f16[16,512,12,64]{1,3,2,0} %reshape.340), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add"}
  %multiply.725 = f16[16,512,12,64]{1,3,2,0} multiply(f16[16,512,12,64]{1,3,2,0} %broadcast.1133, f16[16,512,12,64]{1,3,2,0} %add.320), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/Mul"}
  %transpose.151 = f16[16,12,512,64]{2,3,1,0} transpose(f16[16,512,12,64]{1,3,2,0} %multiply.725), dimensions={0,2,1,3}
  ROOT %copy.108 = f16[16,12,512,64]{3,2,1,0} copy(f16[16,12,512,64]{2,3,1,0} %transpose.151)
}

%fused_computation.264 (param_0.1113: f32[16,12,512], param_1.1534: f16[16,12,512,512], param_2.1477: f32[16,12,512], param_3.937: f16[16,12,512,512], param_4.632: f16[16,12,512,512]) -> f16[16,12,512,512] {
  %param_4.632 = f16[16,12,512,512]{3,2,1,0} parameter(4)
  %copy.133 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_4.632), metadata={op_name="XLA_Args"}
  %constant_1217 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1795 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1217), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %compare.104 = pred[16,12,512,512]{2,3,1,0} compare(f16[16,12,512,512]{2,3,1,0} %copy.133, f16[16,12,512,512]{2,3,1,0} %broadcast.1795), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/GreaterEqual"}
  %param_3.937 = f16[16,12,512,512]{3,2,1,0} parameter(3)
  %copy.132 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_3.937), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum"}
  %constant_1216 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1794 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1216), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %multiply.1072 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %copy.132, f16[16,12,512,512]{2,3,1,0} %broadcast.1794), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul"}
  %constant_1215 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1793 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1215), dimensions={}
  %select.102 = f16[16,12,512,512]{2,3,1,0} select(pred[16,12,512,512]{2,3,1,0} %compare.104, f16[16,12,512,512]{2,3,1,0} %multiply.1072, f16[16,12,512,512]{2,3,1,0} %broadcast.1793), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul_1"}
  %param_0.1113 = f32[16,12,512]{2,1,0} parameter(0)
  %convert.117 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_0.1113), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Sum"}
  %broadcast.248 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.117), dimensions={0,1,2}, metadata={op_type="Sub" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %subtract.145 = f16[16,12,512,512]{2,3,1,0} subtract(f16[16,12,512,512]{2,3,1,0} %select.102, f16[16,12,512,512]{2,3,1,0} %broadcast.248), metadata={op_type="Sub" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %param_1.1534 = f16[16,12,512,512]{2,3,1,0} parameter(1)
  %param_2.1477 = f32[16,12,512]{2,1,0} parameter(2)
  %convert.334 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_2.1477), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %broadcast.1140 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.334), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %divide.65 = f16[16,12,512,512]{2,3,1,0} divide(f16[16,12,512,512]{2,3,1,0} %param_1.1534, f16[16,12,512,512]{2,3,1,0} %broadcast.1140), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %multiply.386 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %subtract.145, f16[16,12,512,512]{2,3,1,0} %divide.65), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul_1"}
  ROOT %copy.109 = f16[16,12,512,512]{3,2,1,0} copy(f16[16,12,512,512]{2,3,1,0} %multiply.386), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul_1"}
}

%fused_computation.265 (param_0.1111: f16[16,12,512,512], param_1.1532: f32[16,12,512], param_2.1476: f16[16,12,512,512], param_3.935: f16[16,12,512,512]) -> f32[16,12,512,512] {
  %param_3.935 = f16[16,12,512,512]{3,2,1,0} parameter(3)
  %copy.129 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_3.935), metadata={op_name="XLA_Args"}
  %constant_1209 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1789 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1209), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %compare.102 = pred[16,12,512,512]{2,3,1,0} compare(f16[16,12,512,512]{2,3,1,0} %copy.129, f16[16,12,512,512]{2,3,1,0} %broadcast.1789), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/GreaterEqual"}
  %param_2.1476 = f16[16,12,512,512]{3,2,1,0} parameter(2)
  %copy.128 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_2.1476), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum"}
  %constant_1208 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1788 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1208), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %multiply.1070 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %copy.128, f16[16,12,512,512]{2,3,1,0} %broadcast.1788), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul"}
  %constant_1206 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1787 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_1206), dimensions={}
  %select.100 = f16[16,12,512,512]{2,3,1,0} select(pred[16,12,512,512]{2,3,1,0} %compare.102, f16[16,12,512,512]{2,3,1,0} %multiply.1070, f16[16,12,512,512]{2,3,1,0} %broadcast.1787), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul_1"}
  %param_0.1111 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %param_1.1532 = f32[16,12,512]{2,1,0} parameter(1)
  %convert.332 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_1.1532), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %broadcast.1138 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.332), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %divide.63 = f16[16,12,512,512]{2,3,1,0} divide(f16[16,12,512,512]{2,3,1,0} %param_0.1111, f16[16,12,512,512]{2,3,1,0} %broadcast.1138), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %multiply.387 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %select.100, f16[16,12,512,512]{2,3,1,0} %divide.63), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul"}
  %convert.118 = f32[16,12,512,512]{2,3,1,0} convert(f16[16,12,512,512]{2,3,1,0} %multiply.387), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Sum"}
  ROOT %bitcast.219 = f32[16,12,512,512]{3,2,1,0} bitcast(f32[16,12,512,512]{2,3,1,0} %convert.118), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Sum"}
}

%fused_computation.267 (param_0.968: f16[8192,768], param_1.1359: f32[12,64]) -> f16[16,12,64,512] {
  %param_1.1359 = f32[12,64]{1,0} parameter(1)
  %convert.338 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1359), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add/Cast"}
  %broadcast.1148 = f16[16,512,12,64]{3,1,2,0} broadcast(f16[12,64]{1,0} %convert.338), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add"}
  %param_0.968 = f16[8192,768]{1,0} parameter(0)
  %reshape.344 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.968), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/einsum/Einsum"}
  %add.324 = f16[16,512,12,64]{3,1,2,0} add(f16[16,512,12,64]{3,1,2,0} %broadcast.1148, f16[16,512,12,64]{3,1,2,0} %reshape.344), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add"}
  %transpose.152 = f16[16,12,64,512]{2,3,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %add.324), dimensions={0,2,3,1}
  ROOT %copy.111 = f16[16,12,64,512]{3,2,1,0} copy(f16[16,12,64,512]{2,3,1,0} %transpose.152)
}

%fused_computation.268 (param_0.767: f32[12,64,768]) -> f16[768,768] {
  %param_0.767 = f32[12,64,768]{2,1,0} parameter(0)
  %convert.202 = f16[12,64,768]{2,1,0} convert(f32[12,64,768]{2,1,0} %param_0.767), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/einsum/Einsum/Cast"}
  %transpose.153 = f16[768,12,64]{0,2,1} transpose(f16[12,64,768]{2,1,0} %convert.202), dimensions={2,0,1}
  ROOT %bitcast.220 = f16[768,768]{0,1} bitcast(f16[768,12,64]{0,2,1} %transpose.153)
}

%fused_computation.269 (param_0.1108: f16[16,512,768], param_1.1529: f32[16,512], param_2.1472: f32[16,512], param_3.926: f16[16,512,768], param_4.613: f32[16,512], param_5.377: f32[16,512,768], param_6.367: f32[768], param_7.311: f32[16,512]) -> f16[16,512,768] {
  %param_0.1108 = f16[16,512,768]{2,1,0} parameter(0)
  %constant_373 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.660 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_373), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.18 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_0.1108, f16[16,512,768]{2,1,0} %broadcast.660), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout/dropout/GreaterEqual"}
  %param_5.377 = f32[16,512,768]{2,1,0} parameter(5)
  %param_7.311 = f32[16,512]{1,0} parameter(7)
  %constant_1181 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1757 = f32[16,512]{1,0} broadcast(f32[] %constant_1181), dimensions={}
  %multiply.1040 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_7.311, f32[16,512]{1,0} %broadcast.1757), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_1185 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1756 = f32[16,512]{1,0} broadcast(f32[] %constant_1185), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.535 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1040, f32[16,512]{1,0} %broadcast.1756), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.101 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.535), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1755 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.101), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_6.367 = f32[768]{0} parameter(6)
  %broadcast.1754 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_6.367), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1039 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1755, f32[16,512,768]{2,1,0} %broadcast.1754), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.1038 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %param_5.377, f32[16,512,768]{2,1,0} %multiply.1039), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1184 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1753 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1184), dimensions={}
  %broadcast.1752 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1181), dimensions={}
  %bitcast.374 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.101), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %multiply.1037 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.374, f32[16,512,1]{1,0,2} %bitcast.374), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1036 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1037, f32[16,512,1]{1,0,2} %bitcast.374), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %param_4.613 = f32[16,512]{1,0} parameter(4)
  %constant_1182 = f32[] constant(-0.5)
  %broadcast.1751 = f32[16,512]{1,0} broadcast(f32[] %constant_1182), dimensions={}
  %multiply.1035 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.613, f32[16,512]{1,0} %broadcast.1751), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.373 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.1035), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1033 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1036, f32[16,512,1]{1,0,2} %bitcast.373), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.1032 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1752, f32[16,512,1]{1,0,2} %multiply.1033), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/truediv"}
  %multiply.1031 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1753, f32[16,512,1]{1,0,2} %multiply.1032), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/Mul"}
  %bitcast.372 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.1031), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/Mul"}
  %broadcast.1750 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.372), dimensions={0,1}
  %param_3.926 = f16[16,512,768]{2,1,0} parameter(3)
  %convert.563 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_3.926), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_2.1472 = f32[16,512]{1,0} parameter(2)
  %multiply.1030 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1472, f32[16,512]{1,0} %broadcast.1757), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1748 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1030), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %subtract.330 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.563, f32[16,512,768]{2,1,0} %broadcast.1748), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1029 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1750, f32[16,512,768]{2,1,0} %subtract.330), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mul_1"}
  %add.534 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1038, f32[16,512,768]{2,1,0} %multiply.1029), metadata={op_type="AddN" op_name="AddN_9"}
  %param_1.1529 = f32[16,512]{1,0} parameter(1)
  %multiply.1028 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1757, f32[16,512]{1,0} %param_1.1529), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/truediv_1"}
  %broadcast.1746 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1028), dimensions={0,1}
  %add.533 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.534, f32[16,512,768]{2,1,0} %broadcast.1746), metadata={op_type="AddN" op_name="AddN_9"}
  %convert.562 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.533), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast/Cast"}
  %constant_371 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.657 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_371), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %multiply.391 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %convert.562, f16[16,512,768]{2,1,0} %broadcast.657), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout/dropout/Mul"}
  %constant_372 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.658 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_372), dimensions={}
  ROOT %select.29 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.18, f16[16,512,768]{2,1,0} %multiply.391, f16[16,512,768]{2,1,0} %broadcast.658), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout/dropout/Mul_1"}
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_2_Sum-reduction.1277 (x.1278: f32[], y.1279: f32[]) -> f32[] {
  %x.1278 = f32[] parameter(0)
  %y.1279 = f32[] parameter(1)
  ROOT %add.1280 = f32[] add(f32[] %x.1278, f32[] %y.1279)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_Sum-reduction.1299 (x.1300: f32[], y.1301: f32[]) -> f32[] {
  %x.1300 = f32[] parameter(0)
  %y.1301 = f32[] parameter(1)
  ROOT %add.1302 = f32[] add(f32[] %x.1300, f32[] %y.1301)
}

%fused_computation.271 (param_0.1226: f32[768], param_1.1722: f32[16,512], param_2.1844: f32[16,512], param_3.1250: f16[16,512,768], param_4.941: f16[8192,768], param_5.877: f32[16,512], param_6.767: f32[16,512,768], param_7.806: f32[16,512], param_8.484: f32[768], param_9.343: f32[16,512], param_10.261: f16[16,768], param_11.305: f16[8192,768]) -> (f32[16,512], f32[16,512], f32[16,512,768]) {
  %param_11.305 = f16[8192,768]{1,0} parameter(11)
  %convert.554.clone.1 = f32[8192,768]{1,0} convert(f16[8192,768]{1,0} %param_11.305), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %bitcast.368.clone.1 = f32[16,512,768]{2,1,0} bitcast(f32[8192,768]{1,0} %convert.554.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %param_10.261 = f16[16,768]{1,0} parameter(10)
  %convert.552.clone.1 = f32[16,768]{1,0} convert(f16[16,768]{1,0} %param_10.261), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_3/Cast"}
  %bitcast.367.clone.1 = f32[16,1,768]{2,1,0} bitcast(f32[16,768]{1,0} %convert.552.clone.1), metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %constant_379 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %pad.37.clone.1 = f32[16,512,768]{2,1,0} pad(f32[16,1,768]{2,1,0} %bitcast.367.clone.1, f32[] %constant_379), padding=0_0x0_511x0_0, metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %add.523.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %bitcast.368.clone.1, f32[16,512,768]{2,1,0} %pad.37.clone.1), metadata={op_type="AddN" op_name="AddN_3"}
  %param_9.343 = f32[16,512]{1,0} parameter(9)
  %constant_798 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1720.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_798), dimensions={}
  %multiply.1003.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_9.343, f32[16,512]{1,0} %broadcast.1720.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  %constant_795 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1718.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_795), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.521.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.1003.clone.1, f32[16,512]{1,0} %broadcast.1718.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add"}
  %rsqrt.99.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.521.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1717.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.99.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %param_8.484 = f32[768]{0} parameter(8)
  %broadcast.1716.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_8.484), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.1002.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1717.clone.1, f32[16,512,768]{2,1,0} %broadcast.1716.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.1001.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.523.clone.1, f32[16,512,768]{2,1,0} %multiply.1002.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1162_clone_1 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1715.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1162_clone_1), dimensions={}
  %broadcast.1714.clone.1 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_798), dimensions={}
  %bitcast.366.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.99.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %multiply.1000.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.366.clone.1, f32[16,512,1]{1,0,2} %bitcast.366.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.999.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.1000.clone.1, f32[16,512,1]{1,0,2} %bitcast.366.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %param_7.806 = f32[16,512]{1,0} parameter(7)
  %constant_1160_clone_1 = f32[] constant(-0.5)
  %broadcast.1713.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_1160_clone_1), dimensions={}
  %multiply.998.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_7.806, f32[16,512]{1,0} %broadcast.1713.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.365.clone.1 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.998.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.997.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.999.clone.1, f32[16,512,1]{1,0,2} %bitcast.365.clone.1), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.996.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1714.clone.1, f32[16,512,1]{1,0,2} %multiply.997.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/truediv"}
  %multiply.995.clone.1 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1715.clone.1, f32[16,512,1]{1,0,2} %multiply.996.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/Mul"}
  %bitcast.364.clone.1 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.995.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/Mul"}
  %broadcast.1712.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.364.clone.1), dimensions={0,1}
  %param_6.767 = f32[16,512,768]{2,1,0} parameter(6)
  %multiply.994.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1712.clone.1, f32[16,512,768]{2,1,0} %param_6.767), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mul_1"}
  %add.520.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1001.clone.1, f32[16,512,768]{2,1,0} %multiply.994.clone.1), metadata={op_type="AddN" op_name="AddN_5"}
  %param_5.877 = f32[16,512]{1,0} parameter(5)
  %multiply.993.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1720.clone.1, f32[16,512]{1,0} %param_5.877), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/truediv_1"}
  %broadcast.1710.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.993.clone.1), dimensions={0,1}
  %add.519.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.520.clone.1, f32[16,512,768]{2,1,0} %broadcast.1710.clone.1), metadata={op_type="AddN" op_name="AddN_5"}
  %param_4.941 = f16[8192,768]{1,0} parameter(4)
  %convert.121.clone.1 = f32[8192,768]{1,0} convert(f16[8192,768]{1,0} %param_4.941), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_1/Cast"}
  %bitcast.224.clone.1 = f32[16,512,768]{2,1,0} bitcast(f32[8192,768]{1,0} %convert.121.clone.1), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_1/Cast"}
  %add.172.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.519.clone.1, f32[16,512,768]{2,1,0} %bitcast.224.clone.1), metadata={op_type="AddN" op_name="AddN_7"}
  %negate.8 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %add.172.clone.1), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub/Neg"}
  %param_1.1722 = f32[16,512]{1,0} parameter(1)
  %multiply.746 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1722, f32[16,512]{1,0} %broadcast.1720.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %add.332 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.746, f32[16,512]{1,0} %broadcast.1718.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.55 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.332), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.672 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.55), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_0.1226 = f32[768]{0} parameter(0)
  %broadcast.671 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_0.1226), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.556 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.672, f32[16,512,768]{2,1,0} %broadcast.671), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.403 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.8, f32[16,512,768]{2,1,0} %multiply.556), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2/Mul"}
  %reduce.82 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.403, f32[] %constant_379), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_2_Sum-reduction.1277, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2/Sum"}
  %param_3.1250 = f16[16,512,768]{2,1,0} parameter(3)
  %convert.557.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_3.1250), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %multiply.1009.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.172.clone.1, f32[16,512,768]{2,1,0} %convert.557.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1/Mul_1"}
  %param_2.1844 = f32[16,512]{1,0} parameter(2)
  %multiply.1008.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1844, f32[16,512]{1,0} %broadcast.1720.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1723.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.1008.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.1007.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.8, f32[16,512,768]{2,1,0} %broadcast.1723.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.526.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.1009.clone.1, f32[16,512,768]{2,1,0} %multiply.1007.clone.1), metadata={op_type="AddN" op_name="AddN_8"}
  %multiply.404.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.526.clone.1, f32[16,512,768]{2,1,0} %broadcast.671), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/Mul"}
  %reduce.83.clone.1 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.404.clone.1, f32[] %constant_379), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_batchnorm_mul_Sum-reduction.1299, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul/Sum"}
  ROOT %tuple.135 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.82, f32[16,512]{1,0} %reduce.83.clone.1, f32[16,512,768]{2,1,0} %add.172.clone.1)
}

%fused_computation.275 (param_0.777: f16[16,512,3072], param_1.1161: f16[8192,3072], param_2.1297: f16[16,512,3072], param_3.749: f16[8192,3072], param_4.439: f32[3072]) -> f16[16,512,3072] {
  %constant_380 = f16[] constant(0.13416), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/mul_1"}
  %broadcast.674 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_380), dimensions={}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/Pow/mul_1"}
  %param_4.439 = f32[3072]{0} parameter(4)
  %convert.350 = f16[3072]{0} convert(f32[3072]{0} %param_4.439), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add/Cast"}
  %broadcast.1227 = f16[16,512,3072]{2,1,0} broadcast(f16[3072]{0} %convert.350), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add"}
  %param_3.749 = f16[8192,3072]{1,0} parameter(3)
  %bitcast.288 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_3.749), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/einsum/Einsum"}
  %add.342 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.1227, f16[16,512,3072]{2,1,0} %bitcast.288), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add"}
  %multiply.558 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.342, f16[16,512,3072]{2,1,0} %add.342)
  %param_2.1297 = f16[16,512,3072]{2,1,0} parameter(2)
  %constant_385 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.679 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_385), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/GreaterEqual"}
  %compare.19 = pred[16,512,3072]{2,1,0} compare(f16[16,512,3072]{2,1,0} %param_2.1297, f16[16,512,3072]{2,1,0} %broadcast.679), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/GreaterEqual"}
  %param_1.1161 = f16[8192,3072]{1,0} parameter(1)
  %bitcast.225 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_1.1161), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum"}
  %select.30 = f16[16,512,3072]{2,1,0} select(pred[16,512,3072]{2,1,0} %compare.19, f16[16,512,3072]{2,1,0} %bitcast.225, f16[16,512,3072]{2,1,0} %broadcast.679), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/Mul"}
  %constant_382 = f16[] constant(0.5), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %broadcast.675 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_382), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %multiply.557 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.342, f16[16,512,3072]{2,1,0} %broadcast.675), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul"}
  %multiply.415 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %select.30, f16[16,512,3072]{2,1,0} %multiply.557), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul_3/Mul_1"}
  %constant_384 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.678 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_384), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/add_1"}
  %param_0.777 = f16[16,512,3072]{2,1,0} parameter(0)
  %multiply.414 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %param_0.777, f16[16,512,3072]{2,1,0} %param_0.777), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/TanhGrad"}
  %subtract.146 = f16[16,512,3072]{2,1,0} subtract(f16[16,512,3072]{2,1,0} %broadcast.678, f16[16,512,3072]{2,1,0} %multiply.414), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/TanhGrad"}
  %multiply.413 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.415, f16[16,512,3072]{2,1,0} %subtract.146), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/TanhGrad"}
  %constant_383 = f16[] constant(0.79785), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %broadcast.676 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_383), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %multiply.412 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.413, f16[16,512,3072]{2,1,0} %broadcast.676), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul_2/Mul"}
  %multiply.411 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.558, f16[16,512,3072]{2,1,0} %multiply.412), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/Pow/mul"}
  %multiply.410 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %broadcast.674, f16[16,512,3072]{2,1,0} %multiply.411), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/Pow/mul_1"}
  %multiply.409 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %select.30, f16[16,512,3072]{2,1,0} %broadcast.675), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul_3/Mul"}
  %add.230 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.678, f16[16,512,3072]{2,1,0} %param_0.777), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/add_1"}
  %multiply.407 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.409, f16[16,512,3072]{2,1,0} %add.230), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul/Mul"}
  %add.174 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %multiply.410, f16[16,512,3072]{2,1,0} %multiply.407), metadata={op_type="AddN" op_name="AddN_6"}
  ROOT %add.173 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %add.174, f16[16,512,3072]{2,1,0} %multiply.412), metadata={op_type="AddN" op_name="AddN_6"}
}

%fused_computation.276 (param_0.1100: f16[16,512,768], param_1.1516: f32[16,512], param_2.1446: f32[16,512,768], param_3.902: f32[16,512], param_4.594: f32[768], param_5.358: f32[16,512], param_6.341: f16[16,768], param_7.282: f16[8192,768]) -> f16[16,512,768] {
  %param_0.1100 = f16[16,512,768]{2,1,0} parameter(0)
  %constant_388 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.683 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_388), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.20 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_0.1100, f16[16,512,768]{2,1,0} %broadcast.683), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/GreaterEqual"}
  %param_7.282 = f16[8192,768]{1,0} parameter(7)
  %convert.549 = f32[8192,768]{1,0} convert(f16[8192,768]{1,0} %param_7.282), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %bitcast.358 = f32[16,512,768]{2,1,0} bitcast(f32[8192,768]{1,0} %convert.549), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %param_6.341 = f16[16,768]{1,0} parameter(6)
  %convert.548 = f32[16,768]{1,0} convert(f16[16,768]{1,0} %param_6.341), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_3/Cast"}
  %bitcast.357 = f32[16,1,768]{2,1,0} bitcast(f32[16,768]{1,0} %convert.548), metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %constant_1149 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %pad.35 = f32[16,512,768]{2,1,0} pad(f32[16,1,768]{2,1,0} %bitcast.357, f32[] %constant_1149), padding=0_0x0_511x0_0, metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %add.514 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %bitcast.358, f32[16,512,768]{2,1,0} %pad.35), metadata={op_type="AddN" op_name="AddN_3"}
  %param_5.358 = f32[16,512]{1,0} parameter(5)
  %constant_1145 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1694 = f32[16,512]{1,0} broadcast(f32[] %constant_1145), dimensions={}
  %multiply.980 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_5.358, f32[16,512]{1,0} %broadcast.1694), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  %constant_1147 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1693 = f32[16,512]{1,0} broadcast(f32[] %constant_1147), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.512 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.980, f32[16,512]{1,0} %broadcast.1693), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add"}
  %rsqrt.97 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.512), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1692 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.97), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %param_4.594 = f32[768]{0} parameter(4)
  %broadcast.1691 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_4.594), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.979 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1692, f32[16,512,768]{2,1,0} %broadcast.1691), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.976 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.514, f32[16,512,768]{2,1,0} %multiply.979), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_1/Mul"}
  %constant_1146 = f32[] constant(2), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/Mul"}
  %broadcast.1690 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1146), dimensions={}
  %broadcast.1689 = f32[16,512,1]{1,0,2} broadcast(f32[] %constant_1145), dimensions={}
  %bitcast.356 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %rsqrt.97), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %multiply.975 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %bitcast.356, f32[16,512,1]{1,0,2} %bitcast.356), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.974 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.975, f32[16,512,1]{1,0,2} %bitcast.356), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %param_3.902 = f32[16,512]{1,0} parameter(3)
  %constant_1144 = f32[] constant(-0.5)
  %broadcast.1688 = f32[16,512]{1,0} broadcast(f32[] %constant_1144), dimensions={}
  %multiply.973 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.902, f32[16,512]{1,0} %broadcast.1688), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %bitcast.355 = f32[16,512,1]{1,0,2} bitcast(f32[16,512]{1,0} %multiply.973), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.972 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %multiply.974, f32[16,512,1]{1,0,2} %bitcast.355), metadata={op_type="RsqrtGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/RsqrtGrad"}
  %multiply.971 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1689, f32[16,512,1]{1,0,2} %multiply.972), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/truediv"}
  %multiply.970 = f32[16,512,1]{1,0,2} multiply(f32[16,512,1]{1,0,2} %broadcast.1690, f32[16,512,1]{1,0,2} %multiply.971), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/Mul"}
  %bitcast.354 = f32[16,512]{1,0} bitcast(f32[16,512,1]{1,0,2} %multiply.970), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/Mul"}
  %broadcast.1687 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %bitcast.354), dimensions={0,1}
  %param_2.1446 = f32[16,512,768]{2,1,0} parameter(2)
  %multiply.969 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1687, f32[16,512,768]{2,1,0} %param_2.1446), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mul_1"}
  %add.511 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.976, f32[16,512,768]{2,1,0} %multiply.969), metadata={op_type="AddN" op_name="AddN_5"}
  %param_1.1516 = f32[16,512]{1,0} parameter(1)
  %multiply.968 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %broadcast.1694, f32[16,512]{1,0} %param_1.1516), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/truediv_1"}
  %broadcast.1685 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.968), dimensions={0,1}
  %add.510 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %add.511, f32[16,512,768]{2,1,0} %broadcast.1685), metadata={op_type="AddN" op_name="AddN_5"}
  %convert.122 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.510), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_2/Cast"}
  %constant_386 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.681 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_386), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %multiply.416 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %convert.122, f16[16,512,768]{2,1,0} %broadcast.681), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_387 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.682 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_387), dimensions={}
  ROOT %select.31 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.20, f16[16,512,768]{2,1,0} %multiply.416, f16[16,512,768]{2,1,0} %broadcast.682), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_mul_2_Sum-reduction.1169 (x.1170: f32[], y.1171: f32[]) -> f32[] {
  %x.1170 = f32[] parameter(0)
  %y.1171 = f32[] parameter(1)
  ROOT %add.1172 = f32[] add(f32[] %x.1170, f32[] %y.1171)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_mul_Sum-reduction.1191 (x.1192: f32[], y.1193: f32[]) -> f32[] {
  %x.1192 = f32[] parameter(0)
  %y.1193 = f32[] parameter(1)
  ROOT %add.1194 = f32[] add(f32[] %x.1192, f32[] %y.1193)
}

%fused_computation.278 (param_0.1091: f32[768], param_1.1500: f32[16,512], param_2.1425: f16[16,768], param_3.878: f16[8192,768], param_4.954: f32[16,512], param_5.892: f32[16,512], param_6.783: f32[768], param_7.821: f32[768], param_8.499: f32[16,512], param_9.361: f16[16,512,768], param_10.284: f16[8192,768], param_11.327: f32[768], param_12.241: f16[16,512,768]) -> (f32[16,512], f32[16,512]) {
  %param_3.878 = f16[8192,768]{1,0} parameter(3)
  %convert.514 = f32[8192,768]{1,0} convert(f16[8192,768]{1,0} %param_3.878), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %bitcast.332 = f32[16,512,768]{2,1,0} bitcast(f32[8192,768]{1,0} %convert.514), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/Cast/Cast"}
  %param_2.1425 = f16[16,768]{1,0} parameter(2)
  %convert.513 = f32[16,768]{1,0} convert(f16[16,768]{1,0} %param_2.1425), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast_3/Cast"}
  %bitcast.331 = f32[16,1,768]{2,1,0} bitcast(f32[16,768]{1,0} %convert.513), metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %constant_393 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %pad.27 = f32[16,512,768]{2,1,0} pad(f32[16,1,768]{2,1,0} %bitcast.331, f32[] %constant_393), padding=0_0x0_511x0_0, metadata={op_type="StridedSliceGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice/StridedSliceGrad"}
  %add.475 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %bitcast.332, f32[16,512,768]{2,1,0} %pad.27), metadata={op_type="AddN" op_name="AddN_3"}
  %negate.10 = f32[16,512,768]{2,1,0} negate(f32[16,512,768]{2,1,0} %add.475), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/sub/Neg"}
  %param_1.1500 = f32[16,512]{1,0} parameter(1)
  %constant_910 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1365 = f32[16,512]{1,0} broadcast(f32[] %constant_910), dimensions={}
  %multiply.828 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1500, f32[16,512]{1,0} %broadcast.1365), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  %constant_909 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1364 = f32[16,512]{1,0} broadcast(f32[] %constant_909), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.391 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.828, f32[16,512]{1,0} %broadcast.1364), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add"}
  %rsqrt.75 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.391), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.695 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.75), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %param_0.1091 = f32[768]{0} parameter(0)
  %broadcast.694 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_0.1091), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.560 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.695, f32[16,512,768]{2,1,0} %broadcast.694), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.426 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.10, f32[16,512,768]{2,1,0} %multiply.560), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_2/Mul"}
  %reduce.84 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.426, f32[] %constant_393), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_mul_2_Sum-reduction.1169, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_2/Sum"}
  %param_12.241 = f16[16,512,768]{2,1,0} parameter(12)
  %constant_1113_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1647.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1113_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.98.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_12.241, f16[16,512,768]{2,1,0} %broadcast.1647.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/GreaterEqual"}
  %constant_1112_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1646.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1112_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_1111_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1645.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_1111_clone_1), dimensions={}
  %select.96.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.98.clone.1, f16[16,512,768]{2,1,0} %broadcast.1646.clone.1, f16[16,512,768]{2,1,0} %broadcast.1645.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %param_11.327 = f32[768]{0} parameter(11)
  %convert.529.clone.1 = f16[768]{0} convert(f32[768]{0} %param_11.327), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Cast"}
  %broadcast.1644.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.529.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %param_10.284 = f16[8192,768]{1,0} parameter(10)
  %bitcast.340.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_10.284), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum"}
  %add.489.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1644.clone.1, f16[16,512,768]{2,1,0} %bitcast.340.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %multiply.937.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.96.clone.1, f16[16,512,768]{2,1,0} %add.489.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
  %convert.527.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.937.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_2"}
  %param_9.361 = f16[16,512,768]{2,1,0} parameter(9)
  %convert.525.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_9.361), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_8.499 = f32[16,512]{1,0} parameter(8)
  %multiply.934.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_8.499, f32[16,512]{1,0} %broadcast.1365), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %add.488.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.934.clone.1, f32[16,512]{1,0} %broadcast.1364), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.93.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.488.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1640.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.93.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_7.821 = f32[768]{0} parameter(7)
  %broadcast.1639.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_7.821), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.933.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1640.clone.1, f32[16,512,768]{2,1,0} %broadcast.1639.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.932.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.525.clone.1, f32[16,512,768]{2,1,0} %multiply.933.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1"}
  %param_6.783 = f32[768]{0} parameter(6)
  %broadcast.1638.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_6.783), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %param_5.892 = f32[16,512]{1,0} parameter(5)
  %multiply.931.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_5.892, f32[16,512]{1,0} %broadcast.1365), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1636.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.931.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.930.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.933.clone.1, f32[16,512,768]{2,1,0} %broadcast.1636.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.326.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1638.clone.1, f32[16,512,768]{2,1,0} %multiply.930.clone.1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %add.487.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.932.clone.1, f32[16,512,768]{2,1,0} %subtract.326.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1"}
  %add.486.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.527.clone.1, f32[16,512,768]{2,1,0} %add.487.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/add_1"}
  %multiply.929.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.475, f32[16,512,768]{2,1,0} %add.486.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_1/Mul_1"}
  %param_4.954 = f32[16,512]{1,0} parameter(4)
  %multiply.927.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.954, f32[16,512]{1,0} %broadcast.1365), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mean"}
  %broadcast.1634.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.927.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/SquaredDifference"}
  %multiply.926.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %negate.10, f32[16,512,768]{2,1,0} %broadcast.1634.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_2/Mul_1"}
  %add.485.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.929.clone.1, f32[16,512,768]{2,1,0} %multiply.926.clone.1), metadata={op_type="AddN" op_name="AddN_4"}
  %multiply.427.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.485.clone.1, f32[16,512,768]{2,1,0} %broadcast.694), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul/Mul"}
  %reduce.85.clone.1 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.427.clone.1, f32[] %constant_393), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_batchnorm_mul_Sum-reduction.1191, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul/Sum"}
  ROOT %tuple.137 = (f32[16,512]{1,0}, f32[16,512]{1,0}) tuple(f32[16,512]{1,0} %reduce.84, f32[16,512]{1,0} %reduce.85.clone.1)
}

%fused_computation.282 (param_0.451: f16[16,768], param_1.705: f16[16,768]) -> f16[16,768] {
  %param_0.451 = f16[16,768]{1,0} parameter(0)
  %constant_425 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.255 = f16[16,768]{1,0} broadcast(f16[] %constant_425), dimensions={}, metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/TanhGrad"}
  %param_1.705 = f16[16,768]{1,0} parameter(1)
  %multiply.431 = f16[16,768]{1,0} multiply(f16[16,768]{1,0} %param_1.705, f16[16,768]{1,0} %param_1.705), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/TanhGrad"}
  %subtract.147 = f16[16,768]{1,0} subtract(f16[16,768]{1,0} %broadcast.255, f16[16,768]{1,0} %multiply.431), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/TanhGrad"}
  ROOT %multiply.430 = f16[16,768]{1,0} multiply(f16[16,768]{1,0} %param_0.451, f16[16,768]{1,0} %subtract.147), metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/TanhGrad"}
}

%fused_computation.283 (param_0.860: f32[16,2], param_1.1231: f32[16], param_2.1161: s32[16,1]) -> f16[16,2] {
  %constant_66 = f32[] constant(64), metadata={op_type="Const" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/ExpandDims"}
  %broadcast.257 = f32[16,2]{1,0} broadcast(f32[] %constant_66), dimensions={}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/mul"}
  %param_0.860 = f32[16,2]{1,0} parameter(0)
  %param_1.1231 = f32[16]{0} parameter(1)
  %broadcast.256 = f32[16,2]{1,0} broadcast(f32[16]{0} %param_1.1231), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %divide.49 = f32[16,2]{1,0} divide(f32[16,2]{1,0} %param_0.860, f32[16,2]{1,0} %broadcast.256), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %param_2.1161 = s32[16,1]{1,0} parameter(2)
  %convert.221 = f32[16,1]{1,0} convert(s32[16,1]{1,0} %param_2.1161), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_5"}
  %convert.220 = s64[16,1]{1,0} convert(f32[16,1]{1,0} %convert.221), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_6"}
  %bitcast.272 = s64[16]{0} bitcast(s64[16,1]{1,0} %convert.220), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_6"}
  %broadcast.823 = s64[16,2]{1,0} broadcast(s64[16]{0} %bitcast.272), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %iota.8 = s64[16,2]{1,0} iota(), iota_dimension=1, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.40 = pred[16,2]{1,0} compare(s64[16,2]{1,0} %broadcast.823, s64[16,2]{1,0} %iota.8), direction=EQ, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_523 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.822 = f32[16,2]{1,0} broadcast(f32[] %constant_523), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_522 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %broadcast.821 = f32[16,2]{1,0} broadcast(f32[] %constant_522), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %select.54 = f32[16,2]{1,0} select(pred[16,2]{1,0} %compare.40, f32[16,2]{1,0} %broadcast.822, f32[16,2]{1,0} %broadcast.821), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_521 = s64[] constant(0), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.820 = s64[16]{0} broadcast(s64[] %constant_521), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.39 = pred[16]{0} compare(s64[16]{0} %broadcast.820, s64[16]{0} %bitcast.272), direction=LE, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_520 = s64[] constant(2), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.819 = s64[16]{0} broadcast(s64[] %constant_520), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.38 = pred[16]{0} compare(s64[16]{0} %bitcast.272, s64[16]{0} %broadcast.819), direction=LT, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %and.5 = pred[16]{0} and(pred[16]{0} %compare.39, pred[16]{0} %compare.38), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.818 = f32[16]{0} broadcast(f32[] %constant_522), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_519 = f32[] constant(nan), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.817 = f32[16]{0} broadcast(f32[] %constant_519), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %select.53 = f32[16]{0} select(pred[16]{0} %and.5, f32[16]{0} %broadcast.818, f32[16]{0} %broadcast.817), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.815 = f32[16,2]{1,0} broadcast(f32[16]{0} %select.53), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %add.238 = f32[16,2]{1,0} add(f32[16,2]{1,0} %select.54, f32[16,2]{1,0} %broadcast.815), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.148 = f32[16,2]{1,0} subtract(f32[16,2]{1,0} %divide.49, f32[16,2]{1,0} %add.238), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %multiply.432 = f32[16,2]{1,0} multiply(f32[16,2]{1,0} %broadcast.257, f32[16,2]{1,0} %subtract.148), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/mul"}
  ROOT %convert.125 = f16[16,2]{1,0} convert(f32[16,2]{1,0} %multiply.432), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/Cast_4/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast"}
}

%max_float_.819 (x.820: f32[], y.821: f32[]) -> f32[] {
  %x.820 = f32[] parameter(0)
  %y.821 = f32[] parameter(1)
  ROOT %maximum.822 = f32[] maximum(f32[] %x.820, f32[] %y.821)
}

%fused_computation.286 (param_0.1020: f32[2], param_1.1420: f16[16,8]) -> f32[16] {
  %param_1.1420 = f16[16,8]{1,0} parameter(1)
  %slice.15 = f16[16,2]{1,0} slice(f16[16,8]{1,0} %param_1.1420), slice={[0:16], [0:2]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}
  %param_0.1020 = f32[2]{0} parameter(0)
  %convert.400 = f16[2]{0} convert(f32[2]{0} %param_0.1020), metadata={op_type="Cast" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/Cast"}
  %broadcast.1445 = f16[16,2]{1,0} broadcast(f16[2]{0} %convert.400), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %add.421 = f16[16,2]{1,0} add(f16[16,2]{1,0} %slice.15, f16[16,2]{1,0} %broadcast.1445), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %convert.129 = f32[16,2]{1,0} convert(f16[16,2]{1,0} %add.421), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_4"}
  %constant_426 = f32[] constant(-inf), metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  ROOT %reduce.86 = f32[16]{0} reduce(f32[16,2]{1,0} %convert.129, f32[] %constant_426), dimensions={1}, to_apply=%max_float_.819, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
}

%fused_computation.288 (param_0.807: f32[768,2]) -> f16[768,8] {
  %param_0.807 = f32[768,2]{1,0} parameter(0)
  %convert.131 = f16[768,2]{1,0} convert(f32[768,2]{1,0} %param_0.807), metadata={op_type="Cast" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul/Cast"}
  %constant_427 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  ROOT %pad.17 = f16[768,8]{1,0} pad(f16[768,2]{1,0} %convert.131, f16[] %constant_427), padding=0_0x0_6, metadata={op_type="MatMul" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}
}

%fused_computation.289 (param_0.466: f32[768]) -> f16[16,768] {
  %param_0.466 = f32[768]{0} parameter(0)
  %convert.132 = f16[768]{0} convert(f32[768]{0} %param_0.466), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd/Cast"}
  ROOT %broadcast.269 = f16[16,768]{1,0} broadcast(f16[768]{0} %convert.132), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd"}
}

%fused_computation.290 (param_0.1017: f32[16,512], param_1.1415: f32[768], param_2.1340: f32[768], param_3.800: f32[16,512], param_4.490: f32[16,512], param_5.283: f32[768], param_6.271: f32[768], param_7.224: f32[16,512], param_8.177: f16[16,512,768], param_9.137: f16[8192,768], param_10.81: f32[768], param_11.58: f16[16,512,768]) -> f16[16,768] {
  %param_11.58 = f16[16,512,768]{2,1,0} parameter(11)
  %constant_955 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1442 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_955), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.68 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_11.58, f16[16,512,768]{2,1,0} %broadcast.1442), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/GreaterEqual"}
  %constant_954 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1440 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_954), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_953 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1439 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_953), dimensions={}
  %select.74 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.68, f16[16,512,768]{2,1,0} %broadcast.1440, f16[16,512,768]{2,1,0} %broadcast.1439), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %param_10.81 = f32[768]{0} parameter(10)
  %convert.398 = f16[768]{0} convert(f32[768]{0} %param_10.81), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Cast"}
  %broadcast.1437 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.398), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %param_9.137 = f16[8192,768]{1,0} parameter(9)
  %bitcast.304 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_9.137), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum"}
  %add.419 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1437, f16[16,512,768]{2,1,0} %bitcast.304), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %multiply.876 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.74, f16[16,512,768]{2,1,0} %add.419), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
  %convert.397 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.876), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_2"}
  %param_8.177 = f16[16,512,768]{2,1,0} parameter(8)
  %convert.395 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_8.177), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_7.224 = f32[16,512]{1,0} parameter(7)
  %constant_947 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1435 = f32[16,512]{1,0} broadcast(f32[] %constant_947), dimensions={}
  %multiply.875 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_7.224, f32[16,512]{1,0} %broadcast.1435), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_948 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1433 = f32[16,512]{1,0} broadcast(f32[] %constant_948), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.418 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.875, f32[16,512]{1,0} %broadcast.1433), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.83 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.418), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1432 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.83), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_6.271 = f32[768]{0} parameter(6)
  %broadcast.1431 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_6.271), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.874 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1432, f32[16,512,768]{2,1,0} %broadcast.1431), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.873 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.395, f32[16,512,768]{2,1,0} %multiply.874), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1"}
  %param_5.283 = f32[768]{0} parameter(5)
  %broadcast.1430 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_5.283), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %param_4.490 = f32[16,512]{1,0} parameter(4)
  %multiply.871 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.490, f32[16,512]{1,0} %broadcast.1435), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1428 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.871), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.870 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.874, f32[16,512,768]{2,1,0} %broadcast.1428), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.307 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1430, f32[16,512,768]{2,1,0} %multiply.870), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %add.417 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.873, f32[16,512,768]{2,1,0} %subtract.307), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1"}
  %add.416 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.397, f32[16,512,768]{2,1,0} %add.417), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/add_1"}
  %param_3.800 = f32[16,512]{1,0} parameter(3)
  %multiply.869 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.800, f32[16,512]{1,0} %broadcast.1435), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  %add.415 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.869, f32[16,512]{1,0} %broadcast.1433), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add"}
  %rsqrt.82 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.415), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1425 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.82), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %param_2.1340 = f32[768]{0} parameter(2)
  %broadcast.1424 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1340), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.867 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1425, f32[16,512,768]{2,1,0} %broadcast.1424), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.866 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.416, f32[16,512,768]{2,1,0} %multiply.867), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_1"}
  %param_1.1415 = f32[768]{0} parameter(1)
  %broadcast.1423 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_1.1415), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/sub"}
  %param_0.1017 = f32[16,512]{1,0} parameter(0)
  %multiply.865 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.1017, f32[16,512]{1,0} %broadcast.1435), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mean"}
  %broadcast.1421 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.865), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/SquaredDifference"}
  %multiply.864 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.867, f32[16,512,768]{2,1,0} %broadcast.1421), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_2"}
  %subtract.306 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1423, f32[16,512,768]{2,1,0} %multiply.864), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/sub"}
  %add.414 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.866, f32[16,512,768]{2,1,0} %subtract.306), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add_1"}
  %slice.12 = f32[16,1,768]{2,1,0} slice(f32[16,512,768]{2,1,0} %add.414), slice={[0:16], [0:1], [0:768]}, metadata={op_type="StridedSlice" op_name="model/bert_pretrainer/bert_encoder_1/tf.__operators__.getitem/strided_slice"}
  %convert.133 = f16[16,1,768]{2,1,0} convert(f32[16,1,768]{2,1,0} %slice.12), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast_3"}
  ROOT %bitcast.232 = f16[16,768]{1,0} bitcast(f16[16,1,768]{2,1,0} %convert.133), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast_3"}
}

%scatter-combiner.1154 (p0.1155: f16[], p1.1156: f16[]) -> f16[] {
  %p0.1155 = f16[] parameter(0)
  %p1.1156 = f16[] parameter(1)
  ROOT %add.1157 = f16[] add(f16[] %p0.1155, f16[] %p1.1156)
}

%fused_computation.291 (param_0.1034: f16[1216,768], param_1.1439: s32[16,76], param_2.1359: s32[16]) -> f16[8192,768] {
  %constant_395 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.270 = f16[8192,768]{1,0} broadcast(f16[] %constant_395), dimensions={}, metadata={op_type="UnsortedSegmentSum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/UnsortedSegmentSum"}
  %param_1.1439 = s32[16,76]{1,0} parameter(1)
  %param_2.1359 = s32[16]{0} parameter(2)
  %broadcast.1463 = s32[16,76]{1,0} broadcast(s32[16]{0} %param_2.1359), dimensions={0}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/add"}
  %add.434 = s32[16,76]{1,0} add(s32[16,76]{1,0} %param_1.1439, s32[16,76]{1,0} %broadcast.1463), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/add"}
  %bitcast.308 = s32[1216]{0} bitcast(s32[16,76]{1,0} %add.434), metadata={op_type="Reshape" op_name="model/bert_pretrainer/cls/predictions/Reshape_1"}
  %param_0.1034 = f16[1216,768]{1,0} parameter(0)
  ROOT %scatter.1 = f16[8192,768]{1,0} scatter(f16[8192,768]{1,0} %broadcast.270, s32[1216]{0} %bitcast.308, f16[1216,768]{1,0} %param_0.1034), update_window_dims={1}, inserted_window_dims={0}, scatter_dims_to_operand_dims={0}, index_vector_dim=1, to_apply=%scatter-combiner.1154, metadata={op_type="UnsortedSegmentSum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/UnsortedSegmentSum"}
}

%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_mul_2_Sum-reduction.1069 (x.1070: f32[], y.1071: f32[]) -> f32[] {
  %x.1070 = f32[] parameter(0)
  %y.1071 = f32[] parameter(1)
  ROOT %add.1072 = f32[] add(f32[] %x.1070, f32[] %y.1071)
}

%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_mul_Sum-reduction.1091 (x.1092: f32[], y.1093: f32[]) -> f32[] {
  %x.1092 = f32[] parameter(0)
  %y.1093 = f32[] parameter(1)
  ROOT %add.1094 = f32[] add(f32[] %x.1092, f32[] %y.1093)
}

%fused_computation.293 (param_0.1080: f32[768], param_1.1488: f32[1216], param_2.1411: f16[1216,768], param_3.1272: f32[1216], param_4.972: f16[1216,768]) -> (f32[1216], f32[1216]) {
  %param_2.1411 = f16[1216,768]{1,0} parameter(2)
  %convert.487 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %param_2.1411), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast_1/Cast"}
  %negate.12 = f32[1216,768]{1,0} negate(f32[1216,768]{1,0} %convert.487), metadata={op_type="Neg" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/sub/Neg"}
  %constant_1030 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1540 = f32[1216]{0} broadcast(f32[] %constant_1030), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/add"}
  %param_1.1488 = f32[1216]{0} parameter(1)
  %constant_1029 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1539 = f32[1216]{0} broadcast(f32[] %constant_1029), dimensions={}
  %multiply.894 = f32[1216]{0} multiply(f32[1216]{0} %param_1.1488, f32[1216]{0} %broadcast.1539), metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/variance"}
  %add.449 = f32[1216]{0} add(f32[1216]{0} %broadcast.1540, f32[1216]{0} %multiply.894), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/add"}
  %rsqrt.91 = f32[1216]{0} rsqrt(f32[1216]{0} %add.449), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/Rsqrt"}
  %broadcast.705 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %rsqrt.91), dimensions={0}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %param_0.1080 = f32[768]{0} parameter(0)
  %broadcast.704 = f32[1216,768]{1,0} broadcast(f32[768]{0} %param_0.1080), dimensions={1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %multiply.564 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %broadcast.705, f32[1216,768]{1,0} %broadcast.704), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %multiply.452 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %negate.12, f32[1216,768]{1,0} %multiply.564), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_2/Mul"}
  %constant_404 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.87 = f32[1216]{0} reduce(f32[1216,768]{1,0} %multiply.452, f32[] %constant_404), dimensions={1}, to_apply=%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_mul_2_Sum-reduction.1069, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_2/Sum"}
  %param_4.972 = f16[1216,768]{1,0} parameter(4)
  %convert.495.clone.1 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %param_4.972), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast"}
  %multiply.908.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %convert.487, f32[1216,768]{1,0} %convert.495.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_1/Mul_1"}
  %param_3.1272 = f32[1216]{0} parameter(3)
  %multiply.907.clone.1 = f32[1216]{0} multiply(f32[1216]{0} %param_3.1272, f32[1216]{0} %broadcast.1539), metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/mean"}
  %broadcast.1614.clone.1 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %multiply.907.clone.1), dimensions={0}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/SquaredDifference"}
  %multiply.906.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %negate.12, f32[1216,768]{1,0} %broadcast.1614.clone.1), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_2/Mul_1"}
  %add.466.clone.1 = f32[1216,768]{1,0} add(f32[1216,768]{1,0} %multiply.908.clone.1, f32[1216,768]{1,0} %multiply.906.clone.1), metadata={op_type="AddN" op_name="AddN"}
  %multiply.453.clone.1 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %add.466.clone.1, f32[1216,768]{1,0} %broadcast.704), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul/Mul"}
  %reduce.88.clone.1 = f32[1216]{0} reduce(f32[1216,768]{1,0} %multiply.453.clone.1, f32[] %constant_404), dimensions={1}, to_apply=%gradient_tape_model_bert_pretrainer_cls_predictions_transform_LayerNorm_batchnorm_mul_Sum-reduction.1091, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul/Sum"}
  ROOT %tuple.141 = (f32[1216]{0}, f32[1216]{0}) tuple(f32[1216]{0} %reduce.87, f32[1216]{0} %reduce.88.clone.1)
}

%max_float_.1014 (x.1015: f32[], y.1016: f32[]) -> f32[] {
  %x.1015 = f32[] parameter(0)
  %y.1016 = f32[] parameter(1)
  ROOT %maximum.1017 = f32[] maximum(f32[] %x.1015, f32[] %y.1016)
}

%fused_computation.300 (param_0.1053: f32[30522], param_1.1458: f16[1216,30528]) -> f32[1216] {
  %param_1.1458 = f16[1216,30528]{1,0} parameter(1)
  %slice.25 = f16[1216,30522]{1,0} slice(f16[1216,30528]{1,0} %param_1.1458), slice={[0:1216], [0:30522]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}
  %param_0.1053 = f32[30522]{0} parameter(0)
  %convert.427 = f16[30522]{0} convert(f32[30522]{0} %param_0.1053), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/BiasAdd/Cast"}
  %broadcast.1543 = f16[1216,30522]{1,0} broadcast(f16[30522]{0} %convert.427), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %add.451 = f16[1216,30522]{1,0} add(f16[1216,30522]{1,0} %slice.25, f16[1216,30522]{1,0} %broadcast.1543), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %convert.143 = f32[1216,30522]{1,0} convert(f16[1216,30522]{1,0} %add.451), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast_1"}
  %constant_408 = f32[] constant(-inf), metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  ROOT %reduce.89 = f32[1216]{0} reduce(f32[1216,30522]{1,0} %convert.143, f32[] %constant_408), dimensions={1}, to_apply=%max_float_.1014, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
}

%fused_computation.302 (param_0.1041: f32[768], param_1.1443: f16[1216,768], param_2.1369: f32[768], param_3.820: f32[1216], param_4.518: f32[1216]) -> f16[1216,768] {
  %param_1.1443 = f16[1216,768]{1,0} parameter(1)
  %convert.146 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %param_1.1443), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast"}
  %constant_1019 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1532 = f32[1216]{0} broadcast(f32[] %constant_1019), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/add"}
  %param_4.518 = f32[1216]{0} parameter(4)
  %constant_995 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1531 = f32[1216]{0} broadcast(f32[] %constant_995), dimensions={}
  %multiply.890 = f32[1216]{0} multiply(f32[1216]{0} %param_4.518, f32[1216]{0} %broadcast.1531), metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/variance"}
  %add.444 = f32[1216]{0} add(f32[1216]{0} %broadcast.1532, f32[1216]{0} %multiply.890), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/add"}
  %rsqrt.87 = f32[1216]{0} rsqrt(f32[1216]{0} %add.444), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/Rsqrt"}
  %broadcast.707 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %rsqrt.87), dimensions={0}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %param_2.1369 = f32[768]{0} parameter(2)
  %broadcast.706 = f32[1216,768]{1,0} broadcast(f32[768]{0} %param_2.1369), dimensions={1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %multiply.567 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %broadcast.707, f32[1216,768]{1,0} %broadcast.706), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul"}
  %multiply.459 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %convert.146, f32[1216,768]{1,0} %multiply.567), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_1"}
  %param_0.1041 = f32[768]{0} parameter(0)
  %broadcast.296 = f32[1216,768]{1,0} broadcast(f32[768]{0} %param_0.1041), dimensions={1}, metadata={op_type="Sub" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/sub"}
  %param_3.820 = f32[1216]{0} parameter(3)
  %multiply.880 = f32[1216]{0} multiply(f32[1216]{0} %param_3.820, f32[1216]{0} %broadcast.1531), metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/mean"}
  %broadcast.1511 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %multiply.880), dimensions={0}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/SquaredDifference"}
  %multiply.458 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %multiply.567, f32[1216,768]{1,0} %broadcast.1511), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_2"}
  %subtract.153 = f32[1216,768]{1,0} subtract(f32[1216,768]{1,0} %broadcast.296, f32[1216,768]{1,0} %multiply.458), metadata={op_type="Sub" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/sub"}
  %add.189 = f32[1216,768]{1,0} add(f32[1216,768]{1,0} %multiply.459, f32[1216,768]{1,0} %subtract.153), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/add_1"}
  ROOT %convert.145 = f16[1216,768]{1,0} convert(f32[1216,768]{1,0} %add.189), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast_1"}
}

%model_bert_pretrainer_cls_predictions_transform_LayerNorm_moments_variance-reduction.959 (x.960: f32[], y.961: f32[]) -> f32[] {
  %x.960 = f32[] parameter(0)
  %y.961 = f32[] parameter(1)
  ROOT %add.962 = f32[] add(f32[] %x.960, f32[] %y.961)
}

%fused_computation.304 (param_0.1045: f32[1216], param_1.1449: f16[1216,768]) -> f32[1216] {
  %param_1.1449 = f16[1216,768]{1,0} parameter(1)
  %convert.422 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %param_1.1449), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast"}
  %param_0.1045 = f32[1216]{0} parameter(0)
  %constant_1004 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1520 = f32[1216]{0} broadcast(f32[] %constant_1004), dimensions={}
  %multiply.884 = f32[1216]{0} multiply(f32[1216]{0} %param_0.1045, f32[1216]{0} %broadcast.1520), metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/mean"}
  %broadcast.1519 = f32[1216,768]{1,0} broadcast(f32[1216]{0} %multiply.884), dimensions={0}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/SquaredDifference"}
  %subtract.314 = f32[1216,768]{1,0} subtract(f32[1216,768]{1,0} %convert.422, f32[1216,768]{1,0} %broadcast.1519), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/SquaredDifference"}
  %multiply.461 = f32[1216,768]{1,0} multiply(f32[1216,768]{1,0} %subtract.314, f32[1216,768]{1,0} %subtract.314), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/SquaredDifference"}
  %constant_412 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  ROOT %reduce.90 = f32[1216]{0} reduce(f32[1216,768]{1,0} %multiply.461, f32[] %constant_412), dimensions={1}, to_apply=%model_bert_pretrainer_cls_predictions_transform_LayerNorm_moments_variance-reduction.959, metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/variance"}
}

%model_bert_pretrainer_cls_predictions_transform_LayerNorm_moments_mean-reduction.941 (x.942: f32[], y.943: f32[]) -> f32[] {
  %x.942 = f32[] parameter(0)
  %y.943 = f32[] parameter(1)
  ROOT %add.944 = f32[] add(f32[] %x.942, f32[] %y.943)
}

%fused_computation.307 (param_0.1234: f16[1216,768]) -> (f32[1216], f16[1216,768], f16[1216,768]) {
  %constant_417_clone_1 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.711.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_417_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/add_1"}
  %param_0.1234 = f16[1216,768]{1,0} parameter(0)
  %constant_422_clone_1 = f16[] constant(0.044708), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_1"}
  %broadcast.299.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_422_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_1"}
  %multiply.571.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %param_0.1234, f16[1216,768]{1,0} %param_0.1234), metadata={op_type="Square" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow/Pow"}
  %multiply.466.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %param_0.1234, f16[1216,768]{1,0} %multiply.571.clone.1), metadata={op_type="Pow" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Pow"}
  %multiply.465.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %broadcast.299.clone.1, f16[1216,768]{1,0} %multiply.466.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_1"}
  %add.191.clone.1 = f16[1216,768]{1,0} add(f16[1216,768]{1,0} %param_0.1234, f16[1216,768]{1,0} %multiply.465.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/add"}
  %constant_423_clone_1 = f16[] constant(0.79785), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %broadcast.713.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_423_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_2"}
  %multiply.463.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %add.191.clone.1, f16[1216,768]{1,0} %broadcast.713.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_2"}
  %tanh.0.clone.1 = f16[1216,768]{1,0} tanh(f16[1216,768]{1,0} %multiply.463.clone.1), metadata={op_type="Tanh" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/Tanh"}
  %add.232.clone.1 = f16[1216,768]{1,0} add(f16[1216,768]{1,0} %broadcast.711.clone.1, f16[1216,768]{1,0} %tanh.0.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/add_1"}
  %constant_416_clone_1 = f16[] constant(0.5), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %broadcast.710.clone.1 = f16[1216,768]{1,0} broadcast(f16[] %constant_416_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul"}
  %multiply.570.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %param_0.1234, f16[1216,768]{1,0} %broadcast.710.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul"}
  %multiply.568.clone.1 = f16[1216,768]{1,0} multiply(f16[1216,768]{1,0} %add.232.clone.1, f16[1216,768]{1,0} %multiply.570.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/cls/predictions/transform/dense/Gelu/mul_3"}
  %convert.148 = f32[1216,768]{1,0} convert(f16[1216,768]{1,0} %multiply.568.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast"}
  %constant_415 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.91 = f32[1216]{0} reduce(f32[1216,768]{1,0} %convert.148, f32[] %constant_415), dimensions={1}, to_apply=%model_bert_pretrainer_cls_predictions_transform_LayerNorm_moments_mean-reduction.941, metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/mean"}
  ROOT %tuple.147 = (f32[1216]{0}, f16[1216,768]{1,0}, f16[1216,768]{1,0}) tuple(f32[1216]{0} %reduce.91, f16[1216,768]{1,0} %multiply.568.clone.1, f16[1216,768]{1,0} %tanh.0.clone.1)
}

%fused_computation.311 (param_0.516: f32[768]) -> f16[1216,768] {
  %param_0.516 = f32[768]{0} parameter(0)
  %convert.151 = f16[768]{0} convert(f32[768]{0} %param_0.516), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd/Cast"}
  ROOT %broadcast.300 = f16[1216,768]{1,0} broadcast(f16[768]{0} %convert.151), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd"}
}

%fused_computation.312 (param_0.1032: f32[16,512], param_1.1436: f32[768], param_2.1357: f32[768], param_3.806: f32[16,512], param_4.495: f32[16,512], param_5.284: f32[768], param_6.272: f32[768], param_7.225: f32[16,512], param_8.178: f16[16,512,768], param_9.138: f16[8192,768], param_10.82: f32[768], param_11.59: f16[16,512,768], param_12.45: s32[16,76], param_13.22: s32[16]) -> f16[1216,768] {
  %param_11.59 = f16[16,512,768]{2,1,0} parameter(11)
  %constant_934 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1402 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_934), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.66 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_11.59, f16[16,512,768]{2,1,0} %broadcast.1402), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/GreaterEqual"}
  %constant_932 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1401 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_932), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_931 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1400 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_931), dimensions={}
  %select.72 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.66, f16[16,512,768]{2,1,0} %broadcast.1401, f16[16,512,768]{2,1,0} %broadcast.1400), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %param_10.82 = f32[768]{0} parameter(10)
  %convert.391 = f16[768]{0} convert(f32[768]{0} %param_10.82), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Cast"}
  %broadcast.1399 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.391), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %param_9.138 = f16[8192,768]{1,0} parameter(9)
  %bitcast.302 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_9.138), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum"}
  %add.406 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1399, f16[16,512,768]{2,1,0} %bitcast.302), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %multiply.851 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.72, f16[16,512,768]{2,1,0} %add.406), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
  %convert.390 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.851), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_2"}
  %param_8.178 = f16[16,512,768]{2,1,0} parameter(8)
  %convert.389 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_8.178), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_7.225 = f32[16,512]{1,0} parameter(7)
  %constant_923 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1398 = f32[16,512]{1,0} broadcast(f32[] %constant_923), dimensions={}
  %multiply.850 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_7.225, f32[16,512]{1,0} %broadcast.1398), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_924 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1397 = f32[16,512]{1,0} broadcast(f32[] %constant_924), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.404 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.850, f32[16,512]{1,0} %broadcast.1397), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.79 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.404), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1396 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.79), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_6.272 = f32[768]{0} parameter(6)
  %broadcast.1395 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_6.272), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.849 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1396, f32[16,512,768]{2,1,0} %broadcast.1395), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.848 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.389, f32[16,512,768]{2,1,0} %multiply.849), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1"}
  %param_5.284 = f32[768]{0} parameter(5)
  %broadcast.1394 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_5.284), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %param_4.495 = f32[16,512]{1,0} parameter(4)
  %multiply.847 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.495, f32[16,512]{1,0} %broadcast.1398), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1392 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.847), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.846 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.849, f32[16,512,768]{2,1,0} %broadcast.1392), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.303 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1394, f32[16,512,768]{2,1,0} %multiply.846), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %add.403 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.848, f32[16,512,768]{2,1,0} %subtract.303), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1"}
  %add.402 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.390, f32[16,512,768]{2,1,0} %add.403), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/add_1"}
  %param_3.806 = f32[16,512]{1,0} parameter(3)
  %multiply.845 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.806, f32[16,512]{1,0} %broadcast.1398), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  %add.400 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.845, f32[16,512]{1,0} %broadcast.1397), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add"}
  %rsqrt.78 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.400), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1389 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.78), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %param_2.1357 = f32[768]{0} parameter(2)
  %broadcast.1388 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1357), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.844 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1389, f32[16,512,768]{2,1,0} %broadcast.1388), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul"}
  %multiply.843 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.402, f32[16,512,768]{2,1,0} %multiply.844), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_1"}
  %param_1.1436 = f32[768]{0} parameter(1)
  %broadcast.1387 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_1.1436), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/sub"}
  %param_0.1032 = f32[16,512]{1,0} parameter(0)
  %multiply.842 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.1032, f32[16,512]{1,0} %broadcast.1398), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mean"}
  %broadcast.1384 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.842), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/SquaredDifference"}
  %multiply.841 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.844, f32[16,512,768]{2,1,0} %broadcast.1384), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_2"}
  %subtract.302 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1387, f32[16,512,768]{2,1,0} %multiply.841), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/sub"}
  %add.399 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.843, f32[16,512,768]{2,1,0} %subtract.302), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/add_1"}
  %convert.152 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.399), metadata={op_type="Cast" op_name="model/bert_pretrainer/Cast"}
  %bitcast.239 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %convert.152), metadata={op_type="Reshape" op_name="model/bert_pretrainer/cls/predictions/Reshape_2"}
  %param_12.45 = s32[16,76]{1,0} parameter(12)
  %param_13.22 = s32[16]{0} parameter(13)
  %broadcast.1460 = s32[16,76]{1,0} broadcast(s32[16]{0} %param_13.22), dimensions={0}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/add"}
  %add.432 = s32[16,76]{1,0} add(s32[16,76]{1,0} %param_12.45, s32[16,76]{1,0} %broadcast.1460), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/add"}
  %bitcast.306 = s32[1216]{0} bitcast(s32[16,76]{1,0} %add.432), metadata={op_type="Reshape" op_name="model/bert_pretrainer/cls/predictions/Reshape_1"}
  ROOT %gather.0 = f16[1216,768]{1,0} gather(f16[8192,768]{1,0} %bitcast.239, s32[1216]{0} %bitcast.306), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,768}, metadata={op_type="GatherV2" op_name="model/bert_pretrainer/cls/predictions/GatherV2"}
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_moments_variance-reduction.723 (x.724: f32[], y.725: f32[]) -> f32[] {
  %x.724 = f32[] parameter(0)
  %y.725 = f32[] parameter(1)
  ROOT %add.726 = f32[] add(f32[] %x.724, f32[] %y.725)
}

%fused_computation.315 (param_0.1238: f32[16,512], param_1.1748: f32[16,512], param_2.1878: f32[768], param_3.1289: f32[768], param_4.984: f32[16,512], param_5.923: f16[16,512,768], param_6.810: f16[8192,768], param_7.842: f32[768], param_8.518: f16[16,512,768]) -> (f32[16,512], f32[16,512,768]) {
  %param_8.518 = f16[16,512,768]{2,1,0} parameter(8)
  %constant_848_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1279.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_848_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.60.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_8.518, f16[16,512,768]{2,1,0} %broadcast.1279.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/GreaterEqual"}
  %constant_847_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1278.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_847_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_846_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1277.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_846_clone_1), dimensions={}
  %select.66.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.60.clone.1, f16[16,512,768]{2,1,0} %broadcast.1278.clone.1, f16[16,512,768]{2,1,0} %broadcast.1277.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %param_7.842 = f32[768]{0} parameter(7)
  %convert.371.clone.1 = f16[768]{0} convert(f32[768]{0} %param_7.842), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Cast"}
  %broadcast.1276.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.371.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %param_6.810 = f16[8192,768]{1,0} parameter(6)
  %bitcast.296.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_6.810), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum"}
  %add.365.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1276.clone.1, f16[16,512,768]{2,1,0} %bitcast.296.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %multiply.790.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.66.clone.1, f16[16,512,768]{2,1,0} %add.365.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
  %convert.370.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.790.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_2"}
  %param_5.923 = f16[16,512,768]{2,1,0} parameter(5)
  %convert.368.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_5.923), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_4.984 = f32[16,512]{1,0} parameter(4)
  %constant_880_clone_1 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1275.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_880_clone_1), dimensions={}
  %multiply.789.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.984, f32[16,512]{1,0} %broadcast.1275.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_844_clone_1 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1274.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_844_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.364.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.789.clone.1, f32[16,512]{1,0} %broadcast.1274.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.63.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.364.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1273.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.63.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_3.1289 = f32[768]{0} parameter(3)
  %broadcast.1272.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_3.1289), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.788.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1273.clone.1, f32[16,512,768]{2,1,0} %broadcast.1272.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.787.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.368.clone.1, f32[16,512,768]{2,1,0} %multiply.788.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1"}
  %param_2.1878 = f32[768]{0} parameter(2)
  %broadcast.1271.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1878), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %param_1.1748 = f32[16,512]{1,0} parameter(1)
  %multiply.786.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1748, f32[16,512]{1,0} %broadcast.1275.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1269.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.786.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.785.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.788.clone.1, f32[16,512,768]{2,1,0} %broadcast.1269.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.295.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1271.clone.1, f32[16,512,768]{2,1,0} %multiply.785.clone.1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %add.363.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.787.clone.1, f32[16,512,768]{2,1,0} %subtract.295.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1"}
  %add.362.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.370.clone.1, f32[16,512,768]{2,1,0} %add.363.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/add_1"}
  %param_0.1238 = f32[16,512]{1,0} parameter(0)
  %multiply.816.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.1238, f32[16,512]{1,0} %broadcast.1275.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mean"}
  %broadcast.1338.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.816.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/SquaredDifference"}
  %subtract.293.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %add.362.clone.1, f32[16,512,768]{2,1,0} %broadcast.1338.clone.1), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/SquaredDifference"}
  %multiply.470 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %subtract.293.clone.1, f32[16,512,768]{2,1,0} %subtract.293.clone.1), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/SquaredDifference"}
  %constant_430 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.93 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.470, f32[] %constant_430), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_moments_variance-reduction.723, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  ROOT %tuple.149 = (f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.93, f32[16,512,768]{2,1,0} %subtract.293.clone.1)
}

%fused_computation.318 (param_0.991: f16[16,512,3072], param_1.1384: f16[16,512,3072], param_2.1299: f16[8192,3072], param_3.753: f32[3072]) -> f16[8192,3072] {
  %param_1.1384 = f16[16,512,3072]{2,1,0} parameter(1)
  %constant_437 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.726 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_437), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/GreaterEqual"}
  %compare.23 = pred[16,512,3072]{2,1,0} compare(f16[16,512,3072]{2,1,0} %param_1.1384, f16[16,512,3072]{2,1,0} %broadcast.726), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/GreaterEqual"}
  %constant_436 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.725 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_436), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/add_1"}
  %param_0.991 = f16[16,512,3072]{2,1,0} parameter(0)
  %add.233 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.725, f16[16,512,3072]{2,1,0} %param_0.991), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/add_1"}
  %param_3.753 = f32[3072]{0} parameter(3)
  %convert.353 = f16[3072]{0} convert(f32[3072]{0} %param_3.753), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add/Cast"}
  %broadcast.1229 = f16[16,512,3072]{2,1,0} broadcast(f16[3072]{0} %convert.353), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add"}
  %param_2.1299 = f16[8192,3072]{1,0} parameter(2)
  %bitcast.290 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_2.1299), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/einsum/Einsum"}
  %add.344 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.1229, f16[16,512,3072]{2,1,0} %bitcast.290), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add"}
  %constant_435 = f16[] constant(0.5), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %broadcast.724 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_435), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %multiply.573 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.344, f16[16,512,3072]{2,1,0} %broadcast.724), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul"}
  %multiply.473 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.233, f16[16,512,3072]{2,1,0} %multiply.573), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul_3"}
  %select.38 = f16[16,512,3072]{2,1,0} select(pred[16,512,3072]{2,1,0} %compare.23, f16[16,512,3072]{2,1,0} %multiply.473, f16[16,512,3072]{2,1,0} %broadcast.726), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/Mul_1"}
  ROOT %bitcast.241 = f16[8192,3072]{1,0} bitcast(f16[16,512,3072]{2,1,0} %select.38)
}

%fused_computation.319 (param_0.994: f16[8192,3072], param_1.1389: f32[3072]) -> f16[16,512,3072] {
  %param_1.1389 = f32[3072]{0} parameter(1)
  %convert.355 = f16[3072]{0} convert(f32[3072]{0} %param_1.1389), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add/Cast"}
  %broadcast.1231 = f16[16,512,3072]{2,1,0} broadcast(f16[3072]{0} %convert.355), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add"}
  %param_0.994 = f16[8192,3072]{1,0} parameter(0)
  %bitcast.292 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_0.994), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/einsum/Einsum"}
  %add.348 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.1231, f16[16,512,3072]{2,1,0} %bitcast.292), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/add"}
  %multiply.574 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.348, f16[16,512,3072]{2,1,0} %add.348)
  %multiply.476 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.348, f16[16,512,3072]{2,1,0} %multiply.574), metadata={op_type="Pow" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/Pow"}
  %constant_438 = f16[] constant(0.044708), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_1"}
  %broadcast.727 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_438), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_1"}
  %multiply.475 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.476, f16[16,512,3072]{2,1,0} %broadcast.727), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul_1"}
  %add.196 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %multiply.475, f16[16,512,3072]{2,1,0} %add.348), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/add"}
  %constant_439 = f16[] constant(0.79785), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %broadcast.728 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_439), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %multiply.474 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.196, f16[16,512,3072]{2,1,0} %broadcast.728), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/mul_2"}
  ROOT %tanh.1 = f16[16,512,3072]{2,1,0} tanh(f16[16,512,3072]{2,1,0} %multiply.474), metadata={op_type="Tanh" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/Tanh"}
}

%fused_computation.321 (param_0.986: f32[16,512], param_1.1379: f32[768], param_2.1294: f32[768], param_3.743: f32[16,512], param_4.429: f16[16,512,768]) -> f16[8192,768] {
  %param_4.429 = f16[16,512,768]{2,1,0} parameter(4)
  %convert.344 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_4.429), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_3.743 = f32[16,512]{1,0} parameter(3)
  %constant_803 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1207 = f32[16,512]{1,0} broadcast(f32[] %constant_803), dimensions={}
  %multiply.756 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.743, f32[16,512]{1,0} %broadcast.1207), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_805 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1205 = f32[16,512]{1,0} broadcast(f32[] %constant_805), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.336 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.756, f32[16,512]{1,0} %broadcast.1205), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.57 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.336), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1203 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.57), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_2.1294 = f32[768]{0} parameter(2)
  %broadcast.1202 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1294), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.755 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1203, f32[16,512,768]{2,1,0} %broadcast.1202), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.754 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.344, f32[16,512,768]{2,1,0} %multiply.755), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1"}
  %param_1.1379 = f32[768]{0} parameter(1)
  %broadcast.1201 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_1.1379), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %param_0.986 = f32[16,512]{1,0} parameter(0)
  %multiply.753 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.986, f32[16,512]{1,0} %broadcast.1207), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1198 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.753), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.752 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.755, f32[16,512,768]{2,1,0} %broadcast.1198), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.288 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1201, f32[16,512,768]{2,1,0} %multiply.752), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %add.335 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.754, f32[16,512,768]{2,1,0} %subtract.288), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1"}
  %convert.156 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.335), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_1"}
  ROOT %bitcast.243 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %convert.156)
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_moments_variance-reduction.644 (x.645: f32[], y.646: f32[]) -> f32[] {
  %x.645 = f32[] parameter(0)
  %y.646 = f32[] parameter(1)
  ROOT %add.647 = f32[] add(f32[] %x.645, f32[] %y.646)
}

%fused_computation.324 (param_0.977: f32[16,512], param_1.1368: f16[16,512,768]) -> f32[16,512] {
  %param_1.1368 = f16[16,512,768]{2,1,0} parameter(1)
  %convert.340 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_1.1368), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_0.977 = f32[16,512]{1,0} parameter(0)
  %constant_771 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1165 = f32[16,512]{1,0} broadcast(f32[] %constant_771), dimensions={}
  %multiply.733 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.977, f32[16,512]{1,0} %broadcast.1165), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1164 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.733), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %subtract.284 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.340, f32[16,512,768]{2,1,0} %broadcast.1164), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.480 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %subtract.284, f32[16,512,768]{2,1,0} %subtract.284), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %constant_442 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  ROOT %reduce.94 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.480, f32[] %constant_442), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_moments_variance-reduction.644, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_moments_mean-reduction.626 (x.627: f32[], y.628: f32[]) -> f32[] {
  %x.627 = f32[] parameter(0)
  %y.628 = f32[] parameter(1)
  ROOT %add.629 = f32[] add(f32[] %x.627, f32[] %y.628)
}

%fused_computation.327 (param_0.1239: f16[16,512,768], param_1.1751: f16[8192,768], param_2.1882: f32[768], param_3.1295: f16[16,512,768]) -> (f32[16,512], f16[16,512,768]) {
  %param_0.1239 = f16[16,512,768]{2,1,0} parameter(0)
  %param_3.1295 = f16[16,512,768]{2,1,0} parameter(3)
  %constant_447_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.739.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_447_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.24.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_3.1295, f16[16,512,768]{2,1,0} %broadcast.739.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout/dropout/GreaterEqual"}
  %constant_445_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.736.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_445_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_446_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.737.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_446_clone_1), dimensions={}
  %select.39.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.24.clone.1, f16[16,512,768]{2,1,0} %broadcast.736.clone.1, f16[16,512,768]{2,1,0} %broadcast.737.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout/dropout/Mul"}
  %param_2.1882 = f32[768]{0} parameter(2)
  %convert.160.clone.1 = f16[768]{0} convert(f32[768]{0} %param_2.1882), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add/Cast"}
  %broadcast.309.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.160.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add"}
  %param_1.1751 = f16[8192,768]{1,0} parameter(1)
  %bitcast.244.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_1.1751), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/einsum/Einsum"}
  %add.202.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.309.clone.1, f16[16,512,768]{2,1,0} %bitcast.244.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add"}
  %multiply.482.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.39.clone.1, f16[16,512,768]{2,1,0} %add.202.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout/dropout/Mul_1"}
  %add.201.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %param_0.1239, f16[16,512,768]{2,1,0} %multiply.482.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/add"}
  %convert.159 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %add.201.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %constant_444 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.95 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %convert.159, f32[] %constant_444), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_layer_norm_moments_mean-reduction.626, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  ROOT %tuple.151 = (f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.95, f16[16,512,768]{2,1,0} %add.201.clone.1)
}

%fused_computation.329 (param_0.555: f16[16,12,512,64]) -> f16[8192,768] {
  %param_0.555 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.154 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.555), dimensions={0,2,1,3}, metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum"}
  %copy.112 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{3,1,2,0} %transpose.154), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum"}
  ROOT %bitcast.245 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.112)
}

%fused_computation.331 (param_0.961: f16[16,12,512,512], param_1.1349: f32[16,12,512], param_2.1271: f16[16,12,512,512]) -> f16[16,12,512,512] {
  %param_2.1271 = f16[16,12,512,512]{3,2,1,0} parameter(2)
  %copy.125 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_2.1271), metadata={op_name="XLA_Args"}
  %constant_756 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1144 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_756), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %compare.56 = pred[16,12,512,512]{2,3,1,0} compare(f16[16,12,512,512]{2,3,1,0} %copy.125, f16[16,12,512,512]{2,3,1,0} %broadcast.1144), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/GreaterEqual"}
  %constant_449 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.742 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_449), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %constant_450 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.741 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_450), dimensions={}
  %select.40 = f16[16,12,512,512]{2,3,1,0} select(pred[16,12,512,512]{2,3,1,0} %compare.56, f16[16,12,512,512]{2,3,1,0} %broadcast.742, f16[16,12,512,512]{2,3,1,0} %broadcast.741), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul"}
  %param_0.961 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %param_1.1349 = f32[16,12,512]{2,1,0} parameter(1)
  %convert.329 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_1.1349), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %broadcast.1136 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.329), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %divide.61 = f16[16,12,512,512]{2,3,1,0} divide(f16[16,12,512,512]{2,3,1,0} %param_0.961, f16[16,12,512,512]{2,3,1,0} %broadcast.1136), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %multiply.483 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %select.40, f16[16,12,512,512]{2,3,1,0} %divide.61), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul_1"}
  ROOT %copy.113 = f16[16,12,512,512]{3,2,1,0} copy(f16[16,12,512,512]{2,3,1,0} %multiply.483), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul_1"}
}

%fused_computation.333 (param_0.563: f16[16,12,512,512]) -> f32[16,12,512,512] {
  %param_0.563 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %convert.163 = f32[16,12,512,512]{2,3,1,0} convert(f16[16,12,512,512]{2,3,1,0} %param_0.563), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  ROOT %bitcast.246 = f32[16,12,512,512]{3,2,1,0} bitcast(f32[16,12,512,512]{2,3,1,0} %convert.163), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
}

%fused_computation.334 (param_0.565: f16[16,12,512,512], param_1.826: f16[16,12,512]) -> f16[16,12,512,512] {
  %param_0.565 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %param_1.826 = f16[16,12,512]{2,1,0} parameter(1)
  %broadcast.313 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %param_1.826), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %subtract.158 = f16[16,12,512,512]{2,3,1,0} subtract(f16[16,12,512,512]{2,3,1,0} %param_0.565, f16[16,12,512,512]{2,3,1,0} %broadcast.313), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  ROOT %exponential.0 = f16[16,12,512,512]{2,3,1,0} exponential(f16[16,12,512,512]{2,3,1,0} %subtract.158), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
}

%fused_computation.335 (param_0.877: f16[16,12,512,512], param_1.1251: s32[16,512]) -> f16[16,12,512,512] {
  %param_0.877 = f16[16,12,512,512]{3,2,1,0} parameter(0)
  %transpose.155 = f16[16,12,512,512]{2,3,1,0} transpose(f16[16,12,512,512]{3,2,1,0} %param_0.877), dimensions={0,1,3,2}, metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum/Einsum"}
  %constant_573 = f16[] constant(-65504), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul"}
  %broadcast.876 = f16[16,512]{1,0} broadcast(f16[] %constant_573), dimensions={}
  %constant_572 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.875 = f16[16,512]{1,0} broadcast(f16[] %constant_572), dimensions={}
  %param_1.1251 = s32[16,512]{1,0} parameter(1)
  %convert.233 = f16[16,512]{1,0} convert(s32[16,512]{1,0} %param_1.1251), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/self_attention_mask/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int32_Cast"}
  %subtract.265 = f16[16,512]{1,0} subtract(f16[16,512]{1,0} %broadcast.875, f16[16,512]{1,0} %convert.233), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %multiply.603 = f16[16,512]{1,0} multiply(f16[16,512]{1,0} %broadcast.876, f16[16,512]{1,0} %subtract.265), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul"}
  %broadcast.874 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,512]{1,0} %multiply.603), dimensions={0,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/add"}
  ROOT %add.204 = f16[16,12,512,512]{2,3,1,0} add(f16[16,12,512,512]{2,3,1,0} %transpose.155, f16[16,12,512,512]{2,3,1,0} %broadcast.874), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/add"}
}

%fused_computation.337 (param_0.571: f16[8192,768], param_1.835: f32[12,64]) -> f16[16,12,512,64] {
  %param_1.835 = f32[12,64]{1,0} parameter(1)
  %convert.165 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.835), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add/Cast"}
  %broadcast.316 = f16[16,512,12,64]{3,1,2,0} broadcast(f16[12,64]{1,0} %convert.165), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add"}
  %param_0.571 = f16[8192,768]{1,0} parameter(0)
  %reshape.317 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.571), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/einsum/Einsum"}
  %add.206 = f16[16,512,12,64]{3,1,2,0} add(f16[16,512,12,64]{3,1,2,0} %broadcast.316, f16[16,512,12,64]{3,1,2,0} %reshape.317), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add"}
  ROOT %transpose.156 = f16[16,12,512,64]{3,2,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %add.206), dimensions={0,2,1,3}
}

%fused_computation.339 (param_0.940: f32[768], param_1.1326: f32[768], param_2.1243: f32[16,512], param_3.715: f32[768], param_4.412: f32[768], param_5.202: f32[16,512], param_6.188: f16[16,512,768], param_7.151: f16[8192,768], param_8.121: f32[768], param_9.82: f16[16,512,768], param_10.39: f32[16,512], param_11.29: f32[16,512]) -> f16[16,512,768] {
  %param_9.82 = f16[16,512,768]{2,1,0} parameter(9)
  %constant_694 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1061 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_694), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.50 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_9.82, f16[16,512,768]{2,1,0} %broadcast.1061), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/GreaterEqual"}
  %constant_693 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1060 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_693), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_692 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1059 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_692), dimensions={}
  %select.60 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.50, f16[16,512,768]{2,1,0} %broadcast.1060, f16[16,512,768]{2,1,0} %broadcast.1059), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul"}
  %param_8.121 = f32[768]{0} parameter(8)
  %convert.304 = f16[768]{0} convert(f32[768]{0} %param_8.121), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Cast"}
  %broadcast.1058 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.304), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %param_7.151 = f16[8192,768]{1,0} parameter(7)
  %bitcast.284 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_7.151), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum"}
  %add.300 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1058, f16[16,512,768]{2,1,0} %bitcast.284), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %multiply.690 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.60, f16[16,512,768]{2,1,0} %add.300), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul_1"}
  %convert.303 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.690), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_2"}
  %param_6.188 = f16[16,512,768]{2,1,0} parameter(6)
  %convert.296 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_6.188), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_5.202 = f32[16,512]{1,0} parameter(5)
  %constant_688 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1057 = f32[16,512]{1,0} broadcast(f32[] %constant_688), dimensions={}
  %multiply.689 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_5.202, f32[16,512]{1,0} %broadcast.1057), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %constant_689 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1056 = f32[16,512]{1,0} broadcast(f32[] %constant_689), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.299 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.689, f32[16,512]{1,0} %broadcast.1056), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.37 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.299), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1055 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.37), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_4.412 = f32[768]{0} parameter(4)
  %broadcast.1054 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_4.412), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.688 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1055, f32[16,512,768]{2,1,0} %broadcast.1054), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.687 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.296, f32[16,512,768]{2,1,0} %multiply.688), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1"}
  %param_3.715 = f32[768]{0} parameter(3)
  %broadcast.1053 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_3.715), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %param_2.1243 = f32[16,512]{1,0} parameter(2)
  %multiply.686 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_2.1243, f32[16,512]{1,0} %broadcast.1057), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.1051 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.686), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.684 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.688, f32[16,512,768]{2,1,0} %broadcast.1051), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.280 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1053, f32[16,512,768]{2,1,0} %multiply.684), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %add.298 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.687, f32[16,512,768]{2,1,0} %subtract.280), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1"}
  %add.297 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.303, f32[16,512,768]{2,1,0} %add.298), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/add_1"}
  %param_11.29 = f32[16,512]{1,0} parameter(11)
  %multiply.716 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_11.29, f32[16,512]{1,0} %broadcast.1057), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/variance"}
  %add.312 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.716, f32[16,512]{1,0} %broadcast.1056), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/add"}
  %rsqrt.43 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.312), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/Rsqrt"}
  %broadcast.748 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.43), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %param_1.1326 = f32[768]{0} parameter(1)
  %broadcast.747 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_1.1326), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.576 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.748, f32[16,512,768]{2,1,0} %broadcast.747), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul"}
  %multiply.488 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %add.297, f32[16,512,768]{2,1,0} %multiply.576), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_1"}
  %param_0.940 = f32[768]{0} parameter(0)
  %broadcast.317 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_0.940), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/sub"}
  %param_10.39 = f32[16,512]{1,0} parameter(10)
  %multiply.710 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_10.39, f32[16,512]{1,0} %broadcast.1057), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mean"}
  %broadcast.1095 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.710), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/SquaredDifference"}
  %multiply.485 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.576, f32[16,512,768]{2,1,0} %broadcast.1095), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_2"}
  %subtract.159 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.317, f32[16,512,768]{2,1,0} %multiply.485), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/sub"}
  %add.207 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.488, f32[16,512,768]{2,1,0} %subtract.159), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/add_1"}
  ROOT %convert.166 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.207), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast_2"}
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_moments_variance-reduction.547 (x.548: f32[], y.549: f32[]) -> f32[] {
  %x.548 = f32[] parameter(0)
  %y.549 = f32[] parameter(1)
  ROOT %add.550 = f32[] add(f32[] %x.548, f32[] %y.549)
}

%fused_computation.341 (param_0.1241: f32[16,512], param_1.1756: f32[16,512], param_2.1889: f32[768], param_3.1301: f32[768], param_4.995: f32[16,512], param_5.934: f16[16,512,768], param_6.822: f16[8192,768], param_7.850: f32[768], param_8.524: f16[16,512,768]) -> (f32[16,512], f32[16,512,768]) {
  %param_8.524 = f16[16,512,768]{2,1,0} parameter(8)
  %constant_677_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1037.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_677_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.48.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_8.524, f16[16,512,768]{2,1,0} %broadcast.1037.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/GreaterEqual"}
  %constant_675_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1036.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_675_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_674_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1035.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_674_clone_1), dimensions={}
  %select.58.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.48.clone.1, f16[16,512,768]{2,1,0} %broadcast.1036.clone.1, f16[16,512,768]{2,1,0} %broadcast.1035.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul"}
  %param_7.850 = f32[768]{0} parameter(7)
  %convert.291.clone.1 = f16[768]{0} convert(f32[768]{0} %param_7.850), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Cast"}
  %broadcast.1034.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.291.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %param_6.822 = f16[8192,768]{1,0} parameter(6)
  %bitcast.282.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_6.822), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum"}
  %add.292.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1034.clone.1, f16[16,512,768]{2,1,0} %bitcast.282.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %multiply.676.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.58.clone.1, f16[16,512,768]{2,1,0} %add.292.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul_1"}
  %convert.290.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.676.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_2"}
  %param_5.934 = f16[16,512,768]{2,1,0} parameter(5)
  %convert.289.clone.1 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_5.934), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_4.995 = f32[16,512]{1,0} parameter(4)
  %constant_712_clone_1 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1033.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_712_clone_1), dimensions={}
  %multiply.674.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.995, f32[16,512]{1,0} %broadcast.1033.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %constant_672_clone_1 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1032.clone.1 = f32[16,512]{1,0} broadcast(f32[] %constant_672_clone_1), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.291.clone.1 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.674.clone.1, f32[16,512]{1,0} %broadcast.1032.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.35.clone.1 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.291.clone.1), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1030.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.35.clone.1), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_3.1301 = f32[768]{0} parameter(3)
  %broadcast.1029.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_3.1301), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.673.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1030.clone.1, f32[16,512,768]{2,1,0} %broadcast.1029.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.672.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.289.clone.1, f32[16,512,768]{2,1,0} %multiply.673.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1"}
  %param_2.1889 = f32[768]{0} parameter(2)
  %broadcast.1028.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1889), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %param_1.1756 = f32[16,512]{1,0} parameter(1)
  %multiply.671.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_1.1756, f32[16,512]{1,0} %broadcast.1033.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.1026.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.671.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.670.clone.1 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.673.clone.1, f32[16,512,768]{2,1,0} %broadcast.1026.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.278.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1028.clone.1, f32[16,512,768]{2,1,0} %multiply.670.clone.1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %add.290.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.672.clone.1, f32[16,512,768]{2,1,0} %subtract.278.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1"}
  %add.289.clone.1 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.290.clone.1, f32[16,512,768]{2,1,0} %add.290.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/add_1"}
  %param_0.1241 = f32[16,512]{1,0} parameter(0)
  %multiply.708.clone.1 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.1241, f32[16,512]{1,0} %broadcast.1033.clone.1), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mean"}
  %broadcast.1091.clone.1 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.708.clone.1), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/SquaredDifference"}
  %subtract.276.clone.1 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %add.289.clone.1, f32[16,512,768]{2,1,0} %broadcast.1091.clone.1), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/SquaredDifference"}
  %multiply.491 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %subtract.276.clone.1, f32[16,512,768]{2,1,0} %subtract.276.clone.1), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/SquaredDifference"}
  %constant_456 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.96 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.491, f32[] %constant_456), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_moments_variance-reduction.547, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/variance"}
  ROOT %tuple.152 = (f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.96, f32[16,512,768]{2,1,0} %subtract.276.clone.1)
}

%fused_computation.344 (param_0.925: f16[16,512,3072], param_1.1309: f16[16,512,3072], param_2.1223: f16[8192,3072], param_3.691: f32[3072]) -> f16[8192,3072] {
  %param_1.1309 = f16[16,512,3072]{2,1,0} parameter(1)
  %constant_463 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.758 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_463), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_1/dropout/GreaterEqual"}
  %compare.26 = pred[16,512,3072]{2,1,0} compare(f16[16,512,3072]{2,1,0} %param_1.1309, f16[16,512,3072]{2,1,0} %broadcast.758), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %constant_462 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.757 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_462), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/add_1"}
  %param_0.925 = f16[16,512,3072]{2,1,0} parameter(0)
  %add.234 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.757, f16[16,512,3072]{2,1,0} %param_0.925), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/add_1"}
  %param_3.691 = f32[3072]{0} parameter(3)
  %convert.268 = f16[3072]{0} convert(f32[3072]{0} %param_3.691), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Cast"}
  %broadcast.978 = f16[16,512,3072]{2,1,0} broadcast(f16[3072]{0} %convert.268), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add"}
  %param_2.1223 = f16[8192,3072]{1,0} parameter(2)
  %bitcast.276 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_2.1223), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/einsum/Einsum"}
  %add.274 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.978, f16[16,512,3072]{2,1,0} %bitcast.276), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add"}
  %constant_461 = f16[] constant(0.5), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %broadcast.755 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_461), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %multiply.577 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.274, f16[16,512,3072]{2,1,0} %broadcast.755), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul"}
  %multiply.494 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.234, f16[16,512,3072]{2,1,0} %multiply.577), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_3"}
  %select.42 = f16[16,512,3072]{2,1,0} select(pred[16,512,3072]{2,1,0} %compare.26, f16[16,512,3072]{2,1,0} %multiply.494, f16[16,512,3072]{2,1,0} %broadcast.758), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/Mul_1"}
  ROOT %bitcast.248 = f16[8192,3072]{1,0} bitcast(f16[16,512,3072]{2,1,0} %select.42)
}

%fused_computation.345 (param_0.928: f16[8192,3072], param_1.1314: f32[3072]) -> f16[16,512,3072] {
  %param_1.1314 = f32[3072]{0} parameter(1)
  %convert.271 = f16[3072]{0} convert(f32[3072]{0} %param_1.1314), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Cast"}
  %broadcast.981 = f16[16,512,3072]{2,1,0} broadcast(f16[3072]{0} %convert.271), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add"}
  %param_0.928 = f16[8192,3072]{1,0} parameter(0)
  %bitcast.278 = f16[16,512,3072]{2,1,0} bitcast(f16[8192,3072]{1,0} %param_0.928), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/einsum/Einsum"}
  %add.276 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %broadcast.981, f16[16,512,3072]{2,1,0} %bitcast.278), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add"}
  %multiply.578 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.276, f16[16,512,3072]{2,1,0} %add.276)
  %multiply.497 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.276, f16[16,512,3072]{2,1,0} %multiply.578), metadata={op_type="Pow" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/Pow"}
  %constant_464 = f16[] constant(0.044708), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_1"}
  %broadcast.759 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_464), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_1"}
  %multiply.496 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %multiply.497, f16[16,512,3072]{2,1,0} %broadcast.759), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_1"}
  %add.211 = f16[16,512,3072]{2,1,0} add(f16[16,512,3072]{2,1,0} %multiply.496, f16[16,512,3072]{2,1,0} %add.276), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/add"}
  %constant_465 = f16[] constant(0.79785), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %broadcast.760 = f16[16,512,3072]{2,1,0} broadcast(f16[] %constant_465), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  %multiply.495 = f16[16,512,3072]{2,1,0} multiply(f16[16,512,3072]{2,1,0} %add.211, f16[16,512,3072]{2,1,0} %broadcast.760), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/mul_2"}
  ROOT %tanh.2 = f16[16,512,3072]{2,1,0} tanh(f16[16,512,3072]{2,1,0} %multiply.495), metadata={op_type="Tanh" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/Tanh"}
}

%fused_computation.347 (param_0.920: f32[16,512], param_1.1304: f32[768], param_2.1218: f32[768], param_3.681: f32[16,512], param_4.372: f16[16,512,768]) -> f16[8192,768] {
  %param_4.372 = f16[16,512,768]{2,1,0} parameter(4)
  %convert.255 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_4.372), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_3.681 = f32[16,512]{1,0} parameter(3)
  %constant_635 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.956 = f32[16,512]{1,0} broadcast(f32[] %constant_635), dimensions={}
  %multiply.637 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.681, f32[16,512]{1,0} %broadcast.956), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %constant_636 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.955 = f32[16,512]{1,0} broadcast(f32[] %constant_636), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.266 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.637, f32[16,512]{1,0} %broadcast.955), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.29 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.266), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.954 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.29), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_2.1218 = f32[768]{0} parameter(2)
  %broadcast.952 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1218), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.636 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.954, f32[16,512,768]{2,1,0} %broadcast.952), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.635 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.255, f32[16,512,768]{2,1,0} %multiply.636), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1"}
  %param_1.1304 = f32[768]{0} parameter(1)
  %broadcast.951 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_1.1304), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %param_0.920 = f32[16,512]{1,0} parameter(0)
  %multiply.634 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.920, f32[16,512]{1,0} %broadcast.956), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.949 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.634), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.633 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.636, f32[16,512,768]{2,1,0} %broadcast.949), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.271 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.951, f32[16,512,768]{2,1,0} %multiply.633), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %add.265 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.635, f32[16,512,768]{2,1,0} %subtract.271), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1"}
  %convert.170 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.265), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_1"}
  ROOT %bitcast.250 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %convert.170)
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_moments_variance-reduction.468 (x.469: f32[], y.470: f32[]) -> f32[] {
  %x.469 = f32[] parameter(0)
  %y.470 = f32[] parameter(1)
  ROOT %add.471 = f32[] add(f32[] %x.469, f32[] %y.470)
}

%fused_computation.350 (param_0.911: f32[16,512], param_1.1293: f16[16,512,768]) -> f32[16,512] {
  %param_1.1293 = f16[16,512,768]{2,1,0} parameter(1)
  %convert.251 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_1.1293), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_0.911 = f32[16,512]{1,0} parameter(0)
  %constant_605 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.914 = f32[16,512]{1,0} broadcast(f32[] %constant_605), dimensions={}
  %multiply.616 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.911, f32[16,512]{1,0} %broadcast.914), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.913 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.616), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %subtract.267 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.251, f32[16,512,768]{2,1,0} %broadcast.913), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.502 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %subtract.267, f32[16,512,768]{2,1,0} %subtract.267), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %constant_469 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  ROOT %reduce.97 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.502, f32[] %constant_469), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_moments_variance-reduction.468, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_moments_mean-reduction.450 (x.451: f32[], y.452: f32[]) -> f32[] {
  %x.451 = f32[] parameter(0)
  %y.452 = f32[] parameter(1)
  ROOT %add.453 = f32[] add(f32[] %x.451, f32[] %y.452)
}

%fused_computation.353 (param_0.1242: f16[16,512,768], param_1.1759: f16[8192,768], param_2.1893: f32[768], param_3.1307: f16[16,512,768]) -> (f32[16,512], f16[16,512,768]) {
  %param_0.1242 = f16[16,512,768]{2,1,0} parameter(0)
  %param_3.1307 = f16[16,512,768]{2,1,0} parameter(3)
  %constant_475_clone_1 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.769.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_475_clone_1), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.27.clone.1 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_3.1307, f16[16,512,768]{2,1,0} %broadcast.769.clone.1), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout/dropout/GreaterEqual"}
  %constant_472_clone_1 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.767.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_472_clone_1), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_474_clone_1 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.768.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_474_clone_1), dimensions={}
  %select.43.clone.1 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.27.clone.1, f16[16,512,768]{2,1,0} %broadcast.767.clone.1, f16[16,512,768]{2,1,0} %broadcast.768.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout/dropout/Mul"}
  %param_2.1893 = f32[768]{0} parameter(2)
  %convert.174.clone.1 = f16[768]{0} convert(f32[768]{0} %param_2.1893), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/add/Cast"}
  %broadcast.323.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.174.clone.1), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/add"}
  %param_1.1759 = f16[8192,768]{1,0} parameter(1)
  %bitcast.251.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_1.1759), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/einsum/Einsum"}
  %add.216.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.323.clone.1, f16[16,512,768]{2,1,0} %bitcast.251.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/add"}
  %multiply.504.clone.1 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.43.clone.1, f16[16,512,768]{2,1,0} %add.216.clone.1), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout/dropout/Mul_1"}
  %add.215.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %param_0.1242, f16[16,512,768]{2,1,0} %multiply.504.clone.1), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/add"}
  %convert.173 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %add.215.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %constant_471 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.98 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %convert.173, f32[] %constant_471), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_layer_norm_moments_mean-reduction.450, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  ROOT %tuple.154 = (f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.98, f16[16,512,768]{2,1,0} %add.215.clone.1)
}

%fused_computation.355 (param_0.611: f16[16,12,512,64]) -> f16[8192,768] {
  %param_0.611 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.157 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.611), dimensions={0,2,1,3}, metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum"}
  %copy.115 = f16[16,512,12,64]{3,2,1,0} copy(f16[16,512,12,64]{3,1,2,0} %transpose.157), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum"}
  ROOT %bitcast.252 = f16[8192,768]{1,0} bitcast(f16[16,512,12,64]{3,2,1,0} %copy.115)
}

%fused_computation.357 (param_0.895: f16[16,12,512,512], param_1.1274: f32[16,12,512], param_2.1195: f16[16,12,512,512]) -> f16[16,12,512,512] {
  %param_2.1195 = f16[16,12,512,512]{3,2,1,0} parameter(2)
  %copy.121 = f16[16,12,512,512]{2,3,1,0} copy(f16[16,12,512,512]{3,2,1,0} %param_2.1195), metadata={op_name="XLA_Args"}
  %constant_589 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.894 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_589), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %compare.44 = pred[16,12,512,512]{2,3,1,0} compare(f16[16,12,512,512]{2,3,1,0} %copy.121, f16[16,12,512,512]{2,3,1,0} %broadcast.894), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/GreaterEqual"}
  %constant_476 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.771 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_476), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %constant_477 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.770 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[] %constant_477), dimensions={}
  %select.44 = f16[16,12,512,512]{2,3,1,0} select(pred[16,12,512,512]{2,3,1,0} %compare.44, f16[16,12,512,512]{2,3,1,0} %broadcast.771, f16[16,12,512,512]{2,3,1,0} %broadcast.770), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul"}
  %param_0.895 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %param_1.1274 = f32[16,12,512]{2,1,0} parameter(1)
  %convert.239 = f16[16,12,512]{2,1,0} convert(f32[16,12,512]{2,1,0} %param_1.1274), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %broadcast.886 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %convert.239), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %divide.55 = f16[16,12,512,512]{2,3,1,0} divide(f16[16,12,512,512]{2,3,1,0} %param_0.895, f16[16,12,512,512]{2,3,1,0} %broadcast.886), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %multiply.506 = f16[16,12,512,512]{2,3,1,0} multiply(f16[16,12,512,512]{2,3,1,0} %select.44, f16[16,12,512,512]{2,3,1,0} %divide.55), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul_1"}
  ROOT %copy.116 = f16[16,12,512,512]{3,2,1,0} copy(f16[16,12,512,512]{2,3,1,0} %multiply.506), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul_1"}
}

%fused_computation.359 (param_0.619: f16[16,12,512,512]) -> f32[16,12,512,512] {
  %param_0.619 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %convert.177 = f32[16,12,512,512]{2,3,1,0} convert(f16[16,12,512,512]{2,3,1,0} %param_0.619), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  ROOT %bitcast.253 = f32[16,12,512,512]{3,2,1,0} bitcast(f32[16,12,512,512]{2,3,1,0} %convert.177), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
}

%fused_computation.360 (param_0.621: f16[16,12,512,512], param_1.886: f16[16,12,512]) -> f16[16,12,512,512] {
  %param_0.621 = f16[16,12,512,512]{2,3,1,0} parameter(0)
  %param_1.886 = f16[16,12,512]{2,1,0} parameter(1)
  %broadcast.326 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,12,512]{2,1,0} %param_1.886), dimensions={0,1,2}, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %subtract.162 = f16[16,12,512,512]{2,3,1,0} subtract(f16[16,12,512,512]{2,3,1,0} %param_0.621, f16[16,12,512,512]{2,3,1,0} %broadcast.326), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  ROOT %exponential.1 = f16[16,12,512,512]{2,3,1,0} exponential(f16[16,12,512,512]{2,3,1,0} %subtract.162), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
}

%fused_computation.361 (param_0.875: f16[16,12,512,512], param_1.1248: s32[16,512]) -> f16[16,12,512,512] {
  %param_0.875 = f16[16,12,512,512]{3,2,1,0} parameter(0)
  %transpose.158 = f16[16,12,512,512]{2,3,1,0} transpose(f16[16,12,512,512]{3,2,1,0} %param_0.875), dimensions={0,1,3,2}, metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum/Einsum"}
  %constant_568 = f16[] constant(-65504), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul"}
  %broadcast.869 = f16[16,512]{1,0} broadcast(f16[] %constant_568), dimensions={}
  %constant_567 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.868 = f16[16,512]{1,0} broadcast(f16[] %constant_567), dimensions={}
  %param_1.1248 = s32[16,512]{1,0} parameter(1)
  %convert.228 = f16[16,512]{1,0} convert(s32[16,512]{1,0} %param_1.1248), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/self_attention_mask/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int32_Cast"}
  %subtract.263 = f16[16,512]{1,0} subtract(f16[16,512]{1,0} %broadcast.868, f16[16,512]{1,0} %convert.228), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %multiply.601 = f16[16,512]{1,0} multiply(f16[16,512]{1,0} %broadcast.869, f16[16,512]{1,0} %subtract.263), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul"}
  %broadcast.867 = f16[16,12,512,512]{2,3,1,0} broadcast(f16[16,512]{1,0} %multiply.601), dimensions={0,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/add"}
  ROOT %add.219 = f16[16,12,512,512]{2,3,1,0} add(f16[16,12,512,512]{2,3,1,0} %transpose.158, f16[16,12,512,512]{2,3,1,0} %broadcast.867), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/add"}
}

%fused_computation.364 (param_0.631: f16[8192,768], param_1.899: f32[12,64]) -> f16[16,12,512,64] {
  %param_1.899 = f32[12,64]{1,0} parameter(1)
  %convert.180 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.899), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Cast"}
  %broadcast.331 = f16[16,512,12,64]{3,1,2,0} broadcast(f16[12,64]{1,0} %convert.180), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add"}
  %param_0.631 = f16[8192,768]{1,0} parameter(0)
  %reshape.320 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.631), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/einsum/Einsum"}
  %add.221 = f16[16,512,12,64]{3,1,2,0} add(f16[16,512,12,64]{3,1,2,0} %broadcast.331, f16[16,512,12,64]{3,1,2,0} %reshape.320), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add"}
  ROOT %transpose.159 = f16[16,12,512,64]{3,2,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %add.221), dimensions={0,2,1,3}
}

%fused_computation.366 (param_0.864: f32[768], param_1.1234: f16[16,512,768], param_2.1164: f32[768], param_3.647: f16[16,512,768], param_4.355: f32[16,512], param_5.143: f32[16,512]) -> f16[16,512,768] {
  %param_1.1234 = f16[16,512,768]{2,1,0} parameter(1)
  %convert.182 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_1.1234), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast"}
  %param_5.143 = f32[16,512]{1,0} parameter(5)
  %constant_530 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.855 = f32[16,512]{1,0} broadcast(f32[] %constant_530), dimensions={}
  %multiply.595 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_5.143, f32[16,512]{1,0} %broadcast.855), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/variance"}
  %constant_550 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.854 = f32[16,512]{1,0} broadcast(f32[] %constant_550), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.242 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.595, f32[16,512]{1,0} %broadcast.854), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %rsqrt.15 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.242), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/Rsqrt"}
  %broadcast.777 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.15), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %param_2.1164 = f32[768]{0} parameter(2)
  %broadcast.775 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1164), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %multiply.580 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.777, f32[16,512,768]{2,1,0} %broadcast.775), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul"}
  %multiply.512 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.182, f32[16,512,768]{2,1,0} %multiply.580), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_1"}
  %param_0.864 = f32[768]{0} parameter(0)
  %broadcast.332 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_0.864), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/sub"}
  %param_4.355 = f32[16,512]{1,0} parameter(4)
  %multiply.585 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_4.355, f32[16,512]{1,0} %broadcast.855), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mean"}
  %broadcast.831 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.585), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %multiply.511 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.580, f32[16,512,768]{2,1,0} %broadcast.831), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_2"}
  %subtract.164 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.332, f32[16,512,768]{2,1,0} %multiply.511), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/sub"}
  %add.223 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.512, f32[16,512,768]{2,1,0} %subtract.164), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add_1"}
  %convert.181 = f16[16,512,768]{2,1,0} convert(f32[16,512,768]{2,1,0} %add.223), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast_1"}
  %param_3.647 = f16[16,512,768]{2,1,0} parameter(3)
  %constant_484 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.780 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_484), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.28 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_3.647, f16[16,512,768]{2,1,0} %broadcast.780), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %constant_482 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.778 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_482), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_483 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.779 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_483), dimensions={}
  %select.45 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.28, f16[16,512,768]{2,1,0} %broadcast.778, f16[16,512,768]{2,1,0} %broadcast.779), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  ROOT %multiply.510 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %convert.181, f16[16,512,768]{2,1,0} %select.45), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul_1"}
}

%model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_moments_variance-reduction.370 (x.371: f32[], y.372: f32[]) -> f32[] {
  %x.371 = f32[] parameter(0)
  %y.372 = f32[] parameter(1)
  ROOT %add.373 = f32[] add(f32[] %x.371, f32[] %y.372)
}

%fused_computation.368 (param_0.868: f32[16,512], param_1.1240: f16[16,512,768]) -> f32[16,512] {
  %param_1.1240 = f16[16,512,768]{2,1,0} parameter(1)
  %convert.223 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_1.1240), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast"}
  %param_0.868 = f32[16,512]{1,0} parameter(0)
  %constant_537 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.841 = f32[16,512]{1,0} broadcast(f32[] %constant_537), dimensions={}
  %multiply.589 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.868, f32[16,512]{1,0} %broadcast.841), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mean"}
  %broadcast.840 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.589), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %subtract.259 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %convert.223, f32[16,512,768]{2,1,0} %broadcast.840), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %multiply.514 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %subtract.259, f32[16,512,768]{2,1,0} %subtract.259), metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/SquaredDifference"}
  %constant_487 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  ROOT %reduce.99 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %multiply.514, f32[] %constant_487), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_moments_variance-reduction.370, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/variance"}
}

%model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_moments_mean-reduction.352 (x.353: f32[], y.354: f32[]) -> f32[] {
  %x.353 = f32[] parameter(0)
  %y.354 = f32[] parameter(1)
  ROOT %add.355 = f32[] add(f32[] %x.353, f32[] %y.354)
}

%fused_computation.371 (param_0.1244: s32[16,512], param_1.1764: f32[30522,768], param_2.1898: f16[8192,768], param_3.1311: f32[512,768]) -> (f32[16,512], f16[16,512,768]) {
  %param_3.1311 = f32[512,768]{1,0} parameter(3)
  %convert.186.clone.1 = f16[512,768]{1,0} convert(f32[512,768]{1,0} %param_3.1311), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/position_embedding/Cast"}
  %broadcast.334.clone.1 = f16[16,512,768]{2,1,0} broadcast(f16[512,768]{1,0} %convert.186.clone.1), dimensions={1,2}, metadata={op_type="BroadcastTo" op_name="model/bert_pretrainer/bert_encoder_1/position_embedding/BroadcastTo"}
  %param_2.1898 = f16[8192,768]{1,0} parameter(2)
  %bitcast.255.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_2.1898), metadata={op_type="Reshape" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/Reshape_1"}
  %add.226.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.334.clone.1, f16[16,512,768]{2,1,0} %bitcast.255.clone.1), metadata={op_type="AddN" op_name="model/bert_pretrainer/bert_encoder_1/add/ArithmeticOptimizer/AddOpsRewrite_add_1"}
  %param_1.1764 = f32[30522,768]{1,0} parameter(1)
  %convert.212.clone.1 = f16[30522,768]{1,0} convert(f32[30522,768]{1,0} %param_1.1764), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/word_embeddings/GatherV2/Cast"}
  %param_0.1244 = s32[16,512]{1,0} parameter(0)
  %bitcast.268.clone.1 = s32[8192]{0} bitcast(s32[16,512]{1,0} %param_0.1244), metadata={op_type="Reshape" op_name="model/bert_pretrainer/bert_encoder_1/word_embeddings/Reshape"}
  %gather.1.clone.1 = f16[8192,768]{1,0} gather(f16[30522,768]{1,0} %convert.212.clone.1, s32[8192]{0} %bitcast.268.clone.1), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,768}, metadata={op_type="GatherV2" op_name="model/bert_pretrainer/bert_encoder_1/word_embeddings/GatherV2"}
  %bitcast.254.clone.1 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %gather.1.clone.1), metadata={op_type="Reshape" op_name="model/bert_pretrainer/bert_encoder_1/word_embeddings/Reshape_1"}
  %add.225.clone.1 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %add.226.clone.1, f16[16,512,768]{2,1,0} %bitcast.254.clone.1), metadata={op_type="AddN" op_name="model/bert_pretrainer/bert_encoder_1/add/ArithmeticOptimizer/AddOpsRewrite_add_1"}
  %convert.185 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %add.225.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast"}
  %constant_489 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.100 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %convert.185, f32[] %constant_489), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_embeddings_layer_norm_moments_mean-reduction.352, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mean"}
  ROOT %tuple.155 = (f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) tuple(f32[16,512]{1,0} %reduce.100, f16[16,512,768]{2,1,0} %add.225.clone.1)
}

%fused_computation.373 (param_0.853: f32[2,768]) -> f16[8,768] {
  %param_0.853 = f32[2,768]{1,0} parameter(0)
  %convert.187 = f16[2,768]{1,0} convert(f32[2,768]{1,0} %param_0.853), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul/Cast"}
  %constant_490 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  ROOT %pad.18 = f16[8,768]{1,0} pad(f16[2,768]{1,0} %convert.187, f16[] %constant_490), padding=0_6x0_0, metadata={op_type="MatMul" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul"}
}

%fused_computation.374 (param_0.854: s32[16,512]) -> f16[8192,8] {
  %param_0.854 = s32[16,512]{1,0} parameter(0)
  %bitcast.256 = s32[8192]{0} bitcast(s32[16,512]{1,0} %param_0.854), metadata={op_type="Reshape" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/Reshape"}
  %broadcast.339 = s32[8192,2]{1,0} broadcast(s32[8192]{0} %bitcast.256), dimensions={0}, metadata={op_type="OneHot" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/one_hot"}
  %iota.4 = s32[8192,2]{1,0} iota(), iota_dimension=1, metadata={op_type="OneHot" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/one_hot"}
  %compare.12 = pred[8192,2]{1,0} compare(s32[8192,2]{1,0} %broadcast.339, s32[8192,2]{1,0} %iota.4), direction=EQ, metadata={op_type="OneHot" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/one_hot"}
  %constant_491 = f16[] constant(1), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/sub"}
  %broadcast.336 = f16[8192,2]{1,0} broadcast(f16[] %constant_491), dimensions={}, metadata={op_type="OneHot" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/one_hot"}
  %constant_492 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.335 = f16[8192,2]{1,0} broadcast(f16[] %constant_492), dimensions={}, metadata={op_type="OneHot" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/one_hot"}
  %select.46 = f16[8192,2]{1,0} select(pred[8192,2]{1,0} %compare.12, f16[8192,2]{1,0} %broadcast.336, f16[8192,2]{1,0} %broadcast.335), metadata={op_type="OneHot" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/one_hot"}
  ROOT %pad.19 = f16[8192,8]{1,0} pad(f16[8192,2]{1,0} %select.46, f16[] %constant_492), padding=0_0x0_6, metadata={op_type="MatMul" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul"}
}

%fused_computation.377 (param_0.738: f16[8192,768]) -> f16[16,12,512,64] {
  %param_0.738 = f16[8192,768]{1,0} parameter(0)
  %reshape.321 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.738), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/einsum/Einsum"}
  ROOT %transpose.168 = f16[16,12,512,64]{3,2,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %reshape.321), dimensions={0,2,1,3}
}

%fused_computation.378 (param_0.763: f16[8192,768]) -> f16[16,12,512,64] {
  %param_0.763 = f16[8192,768]{1,0} parameter(0)
  %reshape.323 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.763), metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/einsum/Einsum"}
  ROOT %transpose.172 = f16[16,12,512,64]{3,2,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %reshape.323), dimensions={0,2,1,3}
}

%fused_computation.379 (param_0.795: f32[30522,768]) -> f16[30528,768] {
  %param_0.795 = f32[30522,768]{1,0} parameter(0)
  %convert.203 = f16[30522,768]{1,0} convert(f32[30522,768]{1,0} %param_0.795), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/word_embeddings/GatherV2/Cast"}
  %constant_409 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  ROOT %pad.20 = f16[30528,768]{1,0} pad(f16[30522,768]{1,0} %convert.203, f16[] %constant_409), padding=0_6x0_0, metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}
}

%fused_computation.381 (param_0.819: f32[12,64,768]) -> f16[768,768] {
  %param_0.819 = f32[12,64,768]{2,1,0} parameter(0)
  %convert.204 = f16[12,64,768]{2,1,0} convert(f32[12,64,768]{2,1,0} %param_0.819), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/einsum/Einsum/Cast"}
  ROOT %bitcast.260 = f16[768,768]{1,0} bitcast(f16[12,64,768]{2,1,0} %convert.204)
}

%fused_computation.382 (param_0.821: f32[768,12,64]) -> f16[768,768] {
  %param_0.821 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.205 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.821), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/einsum/Einsum/Cast"}
  ROOT %bitcast.261 = f16[768,768]{1,0} bitcast(f16[768,12,64]{2,1,0} %convert.205)
}

%fused_computation.383 (param_0.825: f32[768,12,64]) -> f16[768,768] {
  %param_0.825 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.206 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.825), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/einsum/Einsum/Cast"}
  ROOT %bitcast.262 = f16[768,768]{1,0} bitcast(f16[768,12,64]{2,1,0} %convert.206)
}

%fused_computation.384 (param_0.827: f32[768,12,64]) -> f16[768,768] {
  %param_0.827 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.207 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.827), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/einsum/Einsum/Cast"}
  ROOT %bitcast.263 = f16[768,768]{1,0} bitcast(f16[768,12,64]{2,1,0} %convert.207)
}

%fused_computation.385 (param_0.839: f32[12,64,768]) -> f16[768,768] {
  %param_0.839 = f32[12,64,768]{2,1,0} parameter(0)
  %convert.208 = f16[12,64,768]{2,1,0} convert(f32[12,64,768]{2,1,0} %param_0.839), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/attention_output/einsum/Einsum/Cast"}
  ROOT %bitcast.264 = f16[768,768]{1,0} bitcast(f16[12,64,768]{2,1,0} %convert.208)
}

%fused_computation.386 (param_0.841: f32[768,12,64]) -> f16[768,768] {
  %param_0.841 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.209 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.841), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/einsum/Einsum/Cast"}
  ROOT %bitcast.265 = f16[768,768]{1,0} bitcast(f16[768,12,64]{2,1,0} %convert.209)
}

%fused_computation.387 (param_0.845: f32[768,12,64]) -> f16[768,768] {
  %param_0.845 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.210 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.845), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/einsum/Einsum/Cast"}
  ROOT %bitcast.266 = f16[768,768]{1,0} bitcast(f16[768,12,64]{2,1,0} %convert.210)
}

%fused_computation.388 (param_0.847: f32[768,12,64]) -> f16[768,768] {
  %param_0.847 = f32[768,12,64]{2,1,0} parameter(0)
  %convert.211 = f16[768,12,64]{2,1,0} convert(f32[768,12,64]{2,1,0} %param_0.847), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/einsum/Einsum/Cast"}
  ROOT %bitcast.267 = f16[768,768]{1,0} bitcast(f16[768,12,64]{2,1,0} %convert.211)
}

%fused_computation.389 (param_0.882: f16[8192,768], param_1.1258: f32[12,64]) -> f16[16,12,64,512] {
  %param_1.1258 = f32[12,64]{1,0} parameter(1)
  %convert.235 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1258), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Cast"}
  %broadcast.880 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[12,64]{1,0} %convert.235), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add"}
  %param_0.882 = f16[8192,768]{1,0} parameter(0)
  %reshape.326 = f16[16,512,12,64]{1,3,2,0} reshape(f16[8192,768]{1,0} %param_0.882), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/einsum/Einsum"}
  %add.248 = f16[16,512,12,64]{1,3,2,0} add(f16[16,512,12,64]{1,3,2,0} %broadcast.880, f16[16,512,12,64]{1,3,2,0} %reshape.326), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add"}
  %constant_576 = f16[] constant(0.125), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %broadcast.879 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[] %constant_576), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %multiply.605 = f16[16,512,12,64]{1,3,2,0} multiply(f16[16,512,12,64]{1,3,2,0} %add.248, f16[16,512,12,64]{1,3,2,0} %broadcast.879), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  ROOT %transpose.174 = f16[16,12,64,512]{3,2,1,0} transpose(f16[16,512,12,64]{1,3,2,0} %multiply.605), dimensions={0,2,3,1}
}

%fused_computation.390 (param_0.899: f16[8192,768], param_1.1279: f32[12,64]) -> f16[16,12,512,64] {
  %param_1.1279 = f32[12,64]{1,0} parameter(1)
  %convert.246 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1279), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Cast"}
  %broadcast.896 = f16[16,512,12,64]{3,1,2,0} broadcast(f16[12,64]{1,0} %convert.246), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add"}
  %param_0.899 = f16[8192,768]{1,0} parameter(0)
  %reshape.332 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.899), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/einsum/Einsum"}
  %add.252 = f16[16,512,12,64]{3,1,2,0} add(f16[16,512,12,64]{3,1,2,0} %broadcast.896, f16[16,512,12,64]{3,1,2,0} %reshape.332), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add"}
  ROOT %transpose.175 = f16[16,12,512,64]{3,2,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %add.252), dimensions={0,2,1,3}
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_moments_mean-reduction.529 (x.530: f32[], y.531: f32[]) -> f32[] {
  %x.530 = f32[] parameter(0)
  %y.531 = f32[] parameter(1)
  ROOT %add.532 = f32[] add(f32[] %x.530, f32[] %y.531)
}

%fused_computation.391 (param_0.1255: f32[16,512], param_1.1769: f32[768], param_2.1902: f32[768], param_3.1314: f32[16,512], param_4.1002: f16[16,512,768], param_5.938: f16[8192,768], param_6.824: f32[768], param_7.852: f16[16,512,768]) -> f32[16,512] {
  %param_7.852 = f16[16,512,768]{2,1,0} parameter(7)
  %constant_663 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1013 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_663), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.46 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_7.852, f16[16,512,768]{2,1,0} %broadcast.1013), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/GreaterEqual"}
  %constant_662 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1012 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_662), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_661 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1010 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_661), dimensions={}
  %select.56 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.46, f16[16,512,768]{2,1,0} %broadcast.1012, f16[16,512,768]{2,1,0} %broadcast.1010), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul"}
  %param_6.824 = f32[768]{0} parameter(6)
  %convert.284 = f16[768]{0} convert(f32[768]{0} %param_6.824), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Cast"}
  %broadcast.1009 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.284), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %param_5.938 = f16[8192,768]{1,0} parameter(5)
  %bitcast.280 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_5.938), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum"}
  %add.284 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1009, f16[16,512,768]{2,1,0} %bitcast.280), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add"}
  %multiply.660 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.56, f16[16,512,768]{2,1,0} %add.284), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul_1"}
  %convert.283 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.660), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast_2"}
  %param_4.1002 = f16[16,512,768]{2,1,0} parameter(4)
  %convert.281 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_4.1002), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/Cast"}
  %param_3.1314 = f32[16,512]{1,0} parameter(3)
  %constant_658 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1008 = f32[16,512]{1,0} broadcast(f32[] %constant_658), dimensions={}
  %multiply.659 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.1314, f32[16,512]{1,0} %broadcast.1008), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %constant_659 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1006 = f32[16,512]{1,0} broadcast(f32[] %constant_659), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.283 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.659, f32[16,512]{1,0} %broadcast.1006), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.33 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.283), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1005 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.33), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %param_2.1902 = f32[768]{0} parameter(2)
  %broadcast.1003 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1902), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.658 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1005, f32[16,512,768]{2,1,0} %broadcast.1003), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul"}
  %multiply.657 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.281, f32[16,512,768]{2,1,0} %multiply.658), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_1"}
  %param_1.1769 = f32[768]{0} parameter(1)
  %broadcast.1001 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_1.1769), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %param_0.1255 = f32[16,512]{1,0} parameter(0)
  %multiply.656 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.1255, f32[16,512]{1,0} %broadcast.1008), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %broadcast.998 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.656), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.655 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.658, f32[16,512,768]{2,1,0} %broadcast.998), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.275 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1001, f32[16,512,768]{2,1,0} %multiply.655), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/sub"}
  %add.282 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.657, f32[16,512,768]{2,1,0} %subtract.275), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/add_1"}
  %add.281 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.283, f32[16,512,768]{2,1,0} %add.282), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/add_1"}
  %constant_1549 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  ROOT %reduce.101 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %add.281, f32[] %constant_1549), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_0_output_layer_norm_moments_mean-reduction.529, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mean"}
}

%fused_computation.393 (param_0.949: f16[8192,768], param_1.1335: f32[12,64]) -> f16[16,12,64,512] {
  %constant_744 = f16[] constant(0.125), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %broadcast.1128 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[] %constant_744), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %param_1.1335 = f32[12,64]{1,0} parameter(1)
  %convert.313 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1335), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Cast"}
  %broadcast.1126 = f16[16,512,12,64]{1,3,2,0} broadcast(f16[12,64]{1,0} %convert.313), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add"}
  %param_0.949 = f16[8192,768]{1,0} parameter(0)
  %reshape.338 = f16[16,512,12,64]{1,3,2,0} reshape(f16[8192,768]{1,0} %param_0.949), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/einsum/Einsum"}
  %add.318 = f16[16,512,12,64]{1,3,2,0} add(f16[16,512,12,64]{1,3,2,0} %broadcast.1126, f16[16,512,12,64]{1,3,2,0} %reshape.338), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add"}
  %multiply.723 = f16[16,512,12,64]{1,3,2,0} multiply(f16[16,512,12,64]{1,3,2,0} %broadcast.1128, f16[16,512,12,64]{1,3,2,0} %add.318), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/Mul"}
  ROOT %transpose.176 = f16[16,12,64,512]{3,2,1,0} transpose(f16[16,512,12,64]{1,3,2,0} %multiply.723), dimensions={0,2,3,1}
}

%fused_computation.394 (param_0.965: f16[8192,768], param_1.1354: f32[12,64]) -> f16[16,12,512,64] {
  %param_1.1354 = f32[12,64]{1,0} parameter(1)
  %convert.336 = f16[12,64]{1,0} convert(f32[12,64]{1,0} %param_1.1354), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add/Cast"}
  %broadcast.1146 = f16[16,512,12,64]{3,1,2,0} broadcast(f16[12,64]{1,0} %convert.336), dimensions={2,3}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add"}
  %param_0.965 = f16[8192,768]{1,0} parameter(0)
  %reshape.342 = f16[16,512,12,64]{3,1,2,0} reshape(f16[8192,768]{1,0} %param_0.965), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/einsum/Einsum"}
  %add.322 = f16[16,512,12,64]{3,1,2,0} add(f16[16,512,12,64]{3,1,2,0} %broadcast.1146, f16[16,512,12,64]{3,1,2,0} %reshape.342), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add"}
  ROOT %transpose.177 = f16[16,12,512,64]{3,2,1,0} transpose(f16[16,512,12,64]{3,1,2,0} %add.322), dimensions={0,2,1,3}
}

%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_moments_mean-reduction.705 (x.706: f32[], y.707: f32[]) -> f32[] {
  %x.706 = f32[] parameter(0)
  %y.707 = f32[] parameter(1)
  ROOT %add.708 = f32[] add(f32[] %x.706, f32[] %y.707)
}

%fused_computation.395 (param_0.1254: f32[16,512], param_1.1768: f32[768], param_2.1901: f32[768], param_3.1313: f32[16,512], param_4.1001: f16[16,512,768], param_5.937: f16[8192,768], param_6.823: f32[768], param_7.851: f16[16,512,768]) -> f32[16,512] {
  %param_7.851 = f16[16,512,768]{2,1,0} parameter(7)
  %constant_834 = f16[] constant(0.099976), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %broadcast.1257 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_834), dimensions={}, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/GreaterEqual"}
  %compare.58 = pred[16,512,768]{2,1,0} compare(f16[16,512,768]{2,1,0} %param_7.851, f16[16,512,768]{2,1,0} %broadcast.1257), direction=GE, metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/GreaterEqual"}
  %constant_833 = f16[] constant(1.1113), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul"}
  %broadcast.1256 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_833), dimensions={}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %constant_832 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %broadcast.1255 = f16[16,512,768]{2,1,0} broadcast(f16[] %constant_832), dimensions={}
  %select.64 = f16[16,512,768]{2,1,0} select(pred[16,512,768]{2,1,0} %compare.58, f16[16,512,768]{2,1,0} %broadcast.1256, f16[16,512,768]{2,1,0} %broadcast.1255), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul"}
  %param_6.823 = f32[768]{0} parameter(6)
  %convert.363 = f16[768]{0} convert(f32[768]{0} %param_6.823), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add/Cast"}
  %broadcast.1254 = f16[16,512,768]{2,1,0} broadcast(f16[768]{0} %convert.363), dimensions={2}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %param_5.937 = f16[8192,768]{1,0} parameter(5)
  %bitcast.294 = f16[16,512,768]{2,1,0} bitcast(f16[8192,768]{1,0} %param_5.937), metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum"}
  %add.357 = f16[16,512,768]{2,1,0} add(f16[16,512,768]{2,1,0} %broadcast.1254, f16[16,512,768]{2,1,0} %bitcast.294), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/add"}
  %multiply.778 = f16[16,512,768]{2,1,0} multiply(f16[16,512,768]{2,1,0} %select.64, f16[16,512,768]{2,1,0} %add.357), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
  %convert.362 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %multiply.778), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast_2"}
  %param_4.1001 = f16[16,512,768]{2,1,0} parameter(4)
  %convert.360 = f32[16,512,768]{2,1,0} convert(f16[16,512,768]{2,1,0} %param_4.1001), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/Cast"}
  %param_3.1313 = f32[16,512]{1,0} parameter(3)
  %constant_829 = f32[] constant(0.00130208337), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/truediv_1"}
  %broadcast.1253 = f32[16,512]{1,0} broadcast(f32[] %constant_829), dimensions={}
  %multiply.777 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_3.1313, f32[16,512]{1,0} %broadcast.1253), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %constant_830 = f32[] constant(1e-12), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %broadcast.1251 = f32[16,512]{1,0} broadcast(f32[] %constant_830), dimensions={}, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/add"}
  %add.356 = f32[16,512]{1,0} add(f32[16,512]{1,0} %multiply.777, f32[16,512]{1,0} %broadcast.1251), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add"}
  %rsqrt.61 = f32[16,512]{1,0} rsqrt(f32[16,512]{1,0} %add.356), metadata={op_type="Rsqrt" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/Rsqrt"}
  %broadcast.1250 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %rsqrt.61), dimensions={0,1}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %param_2.1901 = f32[768]{0} parameter(2)
  %broadcast.1249 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_2.1901), dimensions={2}, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.776 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %broadcast.1250, f32[16,512,768]{2,1,0} %broadcast.1249), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul"}
  %multiply.775 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %convert.360, f32[16,512,768]{2,1,0} %multiply.776), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_1"}
  %param_1.1768 = f32[768]{0} parameter(1)
  %broadcast.1247 = f32[16,512,768]{2,1,0} broadcast(f32[768]{0} %param_1.1768), dimensions={2}, metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %param_0.1254 = f32[16,512]{1,0} parameter(0)
  %multiply.774 = f32[16,512]{1,0} multiply(f32[16,512]{1,0} %param_0.1254, f32[16,512]{1,0} %broadcast.1253), metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %broadcast.1245 = f32[16,512,768]{2,1,0} broadcast(f32[16,512]{1,0} %multiply.774), dimensions={0,1}, metadata={op_type="SquaredDifference" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/SquaredDifference"}
  %multiply.773 = f32[16,512,768]{2,1,0} multiply(f32[16,512,768]{2,1,0} %multiply.776, f32[16,512,768]{2,1,0} %broadcast.1245), metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2"}
  %subtract.292 = f32[16,512,768]{2,1,0} subtract(f32[16,512,768]{2,1,0} %broadcast.1247, f32[16,512,768]{2,1,0} %multiply.773), metadata={op_type="Sub" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/sub"}
  %add.354 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %multiply.775, f32[16,512,768]{2,1,0} %subtract.292), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/add_1"}
  %add.353 = f32[16,512,768]{2,1,0} add(f32[16,512,768]{2,1,0} %convert.362, f32[16,512,768]{2,1,0} %add.354), metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/add_1"}
  %constant_1548 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  ROOT %reduce.102 = f32[16,512]{1,0} reduce(f32[16,512,768]{2,1,0} %add.353, f32[] %constant_1548), dimensions={2}, to_apply=%model_bert_pretrainer_bert_encoder_1_transformer_layer_1_output_layer_norm_moments_mean-reduction.705, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mean"}
}

%fused_computation.397 (param_0.1028: f32[16], param_1.1432: f32[2], param_2.1353: f16[16,8]) -> f32[16,2] {
  %param_2.1353 = f16[16,8]{1,0} parameter(2)
  %slice.21 = f16[16,2]{1,0} slice(f16[16,8]{1,0} %param_2.1353), slice={[0:16], [0:2]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}
  %param_1.1432 = f32[2]{0} parameter(1)
  %convert.408 = f16[2]{0} convert(f32[2]{0} %param_1.1432), metadata={op_type="Cast" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd/Cast"}
  %broadcast.1453 = f16[16,2]{1,0} broadcast(f16[2]{0} %convert.408), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %add.427 = f16[16,2]{1,0} add(f16[16,2]{1,0} %slice.21, f16[16,2]{1,0} %broadcast.1453), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/classification/predictions/transform/logits/BiasAdd"}
  %convert.407 = f32[16,2]{1,0} convert(f16[16,2]{1,0} %add.427), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_4"}
  %param_0.1028 = f32[16]{0} parameter(0)
  %broadcast.1452 = f32[16,2]{1,0} broadcast(f32[16]{0} %param_0.1028), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.309 = f32[16,2]{1,0} subtract(f32[16,2]{1,0} %convert.407, f32[16,2]{1,0} %broadcast.1452), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  ROOT %exponential.2 = f32[16,2]{1,0} exponential(f32[16,2]{1,0} %subtract.309), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
}

%fused_computation.399 (param_0.1252: s32[16,76], param_1.1766: f32[1216,30522], param_2.1899: f32[1216], param_3.1312: f32[16,76], param_4.1000: f32[]) -> f16[1216,30528] {
  %param_4.1000 = f32[] parameter(4)
  %constant_1069 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %compare.96 = pred[] compare(f32[] %param_4.1000, f32[] %constant_1069), direction=EQ, metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %constant_1071 = f32[] constant(1024), metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %divide.73 = f32[] divide(f32[] %constant_1071, f32[] %param_4.1000), metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %select.94 = f32[] select(pred[] %compare.96, f32[] %constant_1069, f32[] %divide.73), metadata={op_type="DivNoNan" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/div_no_nan/div_no_nan"}
  %broadcast.1611 = f32[16,76]{1,0} broadcast(f32[] %select.94), dimensions={}, metadata={op_type="Tile" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/Tile_1"}
  %param_3.1312 = f32[16,76]{1,0} parameter(3)
  %convert.485 = s32[16,76]{1,0} convert(f32[16,76]{1,0} %param_3.1312), metadata={op_type="Cast" op_name="model/Cast"}
  %convert.484 = f32[16,76]{1,0} convert(s32[16,76]{1,0} %convert.485), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast"}
  %multiply.902 = f32[16,76]{1,0} multiply(f32[16,76]{1,0} %broadcast.1611, f32[16,76]{1,0} %convert.484), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/mul/Mul"}
  %bitcast.320 = f32[1216]{0} bitcast(f32[16,76]{1,0} %multiply.902), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/mul"}
  %broadcast.1610 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %bitcast.320), dimensions={0}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/mul"}
  %param_1.1766 = f32[1216,30522]{1,0} parameter(1)
  %param_2.1899 = f32[1216]{0} parameter(2)
  %broadcast.1609 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %param_2.1899), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %divide.72 = f32[1216,30522]{1,0} divide(f32[1216,30522]{1,0} %param_1.1766, f32[1216,30522]{1,0} %broadcast.1609), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %param_0.1252 = s32[16,76]{1,0} parameter(0)
  %convert.483 = f32[16,76]{1,0} convert(s32[16,76]{1,0} %param_0.1252), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_2"}
  %convert.482 = s64[16,76]{1,0} convert(f32[16,76]{1,0} %convert.483), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_3"}
  %bitcast.319 = s64[1216]{0} bitcast(s64[16,76]{1,0} %convert.482), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int64_Cast_3"}
  %broadcast.1608 = s64[1216,30522]{1,0} broadcast(s64[1216]{0} %bitcast.319), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %iota.16 = s64[1216,30522]{1,0} iota(), iota_dimension=1, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.95 = pred[1216,30522]{1,0} compare(s64[1216,30522]{1,0} %broadcast.1608, s64[1216,30522]{1,0} %iota.16), direction=EQ, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1070 = f32[] constant(1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1607 = f32[1216,30522]{1,0} broadcast(f32[] %constant_1070), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1606 = f32[1216,30522]{1,0} broadcast(f32[] %constant_1069), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %select.93 = f32[1216,30522]{1,0} select(pred[1216,30522]{1,0} %compare.95, f32[1216,30522]{1,0} %broadcast.1607, f32[1216,30522]{1,0} %broadcast.1606), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1068 = s64[] constant(0), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1604 = s64[1216]{0} broadcast(s64[] %constant_1068), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.94 = pred[1216]{0} compare(s64[1216]{0} %broadcast.1604, s64[1216]{0} %bitcast.319), direction=LE, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1066 = s64[] constant(30522), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1603 = s64[1216]{0} broadcast(s64[] %constant_1066), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %compare.93 = pred[1216]{0} compare(s64[1216]{0} %bitcast.319, s64[1216]{0} %broadcast.1603), direction=LT, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %and.13 = pred[1216]{0} and(pred[1216]{0} %compare.94, pred[1216]{0} %compare.93), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1602 = f32[1216]{0} broadcast(f32[] %constant_1069), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1065 = f32[] constant(nan), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1601 = f32[1216]{0} broadcast(f32[] %constant_1065), dimensions={}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %select.92 = f32[1216]{0} select(pred[1216]{0} %and.13, f32[1216]{0} %broadcast.1602, f32[1216]{0} %broadcast.1601), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %broadcast.1600 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %select.92), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %add.464 = f32[1216,30522]{1,0} add(f32[1216,30522]{1,0} %select.93, f32[1216,30522]{1,0} %broadcast.1600), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.324 = f32[1216,30522]{1,0} subtract(f32[1216,30522]{1,0} %divide.72, f32[1216,30522]{1,0} %add.464), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %multiply.901 = f32[1216,30522]{1,0} multiply(f32[1216,30522]{1,0} %broadcast.1610, f32[1216,30522]{1,0} %subtract.324), metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/mul"}
  %convert.481 = f16[1216,30522]{1,0} convert(f32[1216,30522]{1,0} %multiply.901), metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/Cast_1/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast"}
  %constant_1546 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  ROOT %pad.21 = f16[1216,30528]{1,0} pad(f16[1216,30522]{1,0} %convert.481, f16[] %constant_1546), padding=0_0x0_6, metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/MatMul/MatMul"}
}

%fused_computation.400 (param_0.1251: f16[16,12,512,64], param_1.1786: f16[16,12,512,64], param_2.1917: f16[16,12,512,64], param_3.1325: f16[16,12,512,64]) -> (f32[16,12,64], f32[16,12,64], f32[16,12,64], f32[16,12,64]) {
  %param_0.1251 = f16[16,12,512,64]{3,2,1,0} parameter(0)
  %transpose.183 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_0.1251), dimensions={0,2,1,3}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum/Einsum"}
  %convert.678 = f32[16,512,12,64]{3,1,2,0} convert(f16[16,512,12,64]{3,1,2,0} %transpose.183), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Sum"}
  %bitcast.414 = f32[16,12,512,64]{3,2,1,0} bitcast(f32[16,512,12,64]{3,1,2,0} %convert.678), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Sum"}
  %constant_1543 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.103 = f32[16,12,64]{2,1,0} reduce(f32[16,12,512,64]{3,2,1,0} %bitcast.414, f32[] %constant_1543), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_key_add_Sum-reduction.1628, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Sum"}
  %param_1.1786 = f16[16,12,512,64]{3,2,1,0} parameter(1)
  %transpose.211.clone.1 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_1.1786), dimensions={0,2,1,3}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/Mul"}
  %convert.757.clone.1 = f32[16,512,12,64]{3,1,2,0} convert(f16[16,512,12,64]{3,1,2,0} %transpose.211.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Sum"}
  %bitcast.442.clone.1 = f32[16,12,512,64]{3,2,1,0} bitcast(f32[16,512,12,64]{3,1,2,0} %convert.757.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Sum"}
  %reduce.107.clone.1 = f32[16,12,64]{2,1,0} reduce(f32[16,12,512,64]{3,2,1,0} %bitcast.442.clone.1, f32[] %constant_1543), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_query_add_Sum-reduction.1390, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/query/add/Sum"}
  %param_2.1917 = f16[16,12,512,64]{3,2,1,0} parameter(2)
  %transpose.205.clone.1 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_2.1917), dimensions={0,2,1,3}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum/Einsum"}
  %convert.750.clone.1 = f32[16,512,12,64]{3,1,2,0} convert(f16[16,512,12,64]{3,1,2,0} %transpose.205.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add/Sum"}
  %bitcast.436.clone.1 = f32[16,12,512,64]{3,2,1,0} bitcast(f32[16,512,12,64]{3,1,2,0} %convert.750.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add/Sum"}
  %reduce.106.clone.1 = f32[16,12,64]{2,1,0} reduce(f32[16,12,512,64]{3,2,1,0} %bitcast.436.clone.1, f32[] %constant_1543), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_key_add_Sum-reduction.1370, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/key/add/Sum"}
  %param_3.1325 = f16[16,12,512,64]{3,2,1,0} parameter(3)
  %transpose.189.clone.1 = f16[16,512,12,64]{3,1,2,0} transpose(f16[16,12,512,64]{3,2,1,0} %param_3.1325), dimensions={0,2,1,3}, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/Mul"}
  %convert.684.clone.1 = f32[16,512,12,64]{3,1,2,0} convert(f16[16,512,12,64]{3,1,2,0} %transpose.189.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Sum"}
  %bitcast.420.clone.1 = f32[16,12,512,64]{3,2,1,0} bitcast(f32[16,512,12,64]{3,1,2,0} %convert.684.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Sum"}
  %reduce.104.clone.1 = f32[16,12,64]{2,1,0} reduce(f32[16,12,512,64]{3,2,1,0} %bitcast.420.clone.1, f32[] %constant_1543), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_query_add_Sum-reduction.1648, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/query/add/Sum"}
  ROOT %tuple.163 = (f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}) tuple(f32[16,12,64]{2,1,0} %reduce.103, f32[16,12,64]{2,1,0} %reduce.107.clone.1, f32[16,12,64]{2,1,0} %reduce.106.clone.1, f32[16,12,64]{2,1,0} %reduce.104.clone.1)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_value_add_Sum-reduction.1665 (x.1666: f32[], y.1667: f32[]) -> f32[] {
  %x.1666 = f32[] parameter(0)
  %y.1667 = f32[] parameter(1)
  ROOT %add.1668 = f32[] add(f32[] %x.1666, f32[] %y.1667)
}

%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_value_add_Sum-reduction.1407 (x.1408: f32[], y.1409: f32[]) -> f32[] {
  %x.1408 = f32[] parameter(0)
  %y.1409 = f32[] parameter(1)
  ROOT %add.1410 = f32[] add(f32[] %x.1408, f32[] %y.1409)
}

%fused_computation.402 (param_0.1247: f16[16,12,64,512], param_1.1782: f16[16,12,64,512]) -> (f32[12,64], f32[12,64]) {
  %param_0.1247 = f16[16,12,64,512]{3,2,1,0} parameter(0)
  %transpose.195 = f16[16,512,12,64]{1,3,2,0} transpose(f16[16,12,64,512]{3,2,1,0} %param_0.1247), dimensions={0,3,1,2}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum_1"}
  %convert.690 = f32[16,512,12,64]{1,3,2,0} convert(f16[16,512,12,64]{1,3,2,0} %transpose.195), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Sum"}
  %bitcast.426 = f32[16,12,64,512]{3,2,1,0} bitcast(f32[16,512,12,64]{1,3,2,0} %convert.690), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Sum"}
  %constant_1539 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.105 = f32[12,64]{1,0} reduce(f32[16,12,64,512]{3,2,1,0} %bitcast.426, f32[] %constant_1539), dimensions={0,3}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_value_add_Sum-reduction.1665, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Sum"}
  %param_1.1782 = f16[16,12,64,512]{3,2,1,0} parameter(1)
  %transpose.217.clone.1 = f16[16,512,12,64]{1,3,2,0} transpose(f16[16,12,64,512]{3,2,1,0} %param_1.1782), dimensions={0,3,1,2}, metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum_1"}
  %convert.766.clone.1 = f32[16,512,12,64]{1,3,2,0} convert(f16[16,512,12,64]{1,3,2,0} %transpose.217.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add/Sum"}
  %bitcast.448.clone.1 = f32[16,12,64,512]{3,2,1,0} bitcast(f32[16,512,12,64]{1,3,2,0} %convert.766.clone.1), metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add/Sum"}
  %reduce.108.clone.1 = f32[12,64]{1,0} reduce(f32[16,12,64,512]{3,2,1,0} %bitcast.448.clone.1, f32[] %constant_1539), dimensions={0,3}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_value_add_Sum-reduction.1407, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/value/add/Sum"}
  ROOT %tuple.160 = (f32[12,64]{1,0}, f32[12,64]{1,0}) tuple(f32[12,64]{1,0} %reduce.105, f32[12,64]{1,0} %reduce.108.clone.1)
}

%max_F32.1964 (lhs.1965: f32[], rhs.1966: f32[]) -> f32[] {
  %lhs.1965 = f32[] parameter(0)
  %rhs.1966 = f32[] parameter(1)
  ROOT %maximum.1967 = f32[] maximum(f32[] %lhs.1965, f32[] %rhs.1966)
}

%fused_computation.407 (param_0.1245: f32[30522], param_1.1765: f16[1216,30528]) -> f32[16,76] {
  %param_1.1765 = f16[1216,30528]{1,0} parameter(1)
  %slice.43 = f16[1216,30522]{1,0} slice(f16[1216,30528]{1,0} %param_1.1765), slice={[0:1216], [0:30522]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}
  %param_0.1245 = f32[30522]{0} parameter(0)
  %convert.815 = f16[30522]{0} convert(f32[30522]{0} %param_0.1245), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/BiasAdd/Cast"}
  %broadcast.2101 = f16[1216,30522]{1,0} broadcast(f16[30522]{0} %convert.815), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %add.602 = f16[1216,30522]{1,0} add(f16[1216,30522]{1,0} %slice.43, f16[1216,30522]{1,0} %broadcast.2101), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %convert.814 = f32[1216,30522]{1,0} convert(f16[1216,30522]{1,0} %add.602), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast_1"}
  %bitcast.454 = f32[16,76,30522]{2,1,0} bitcast(f32[1216,30522]{1,0} %convert.814), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/Cast_1"}
  %constant_1537 = f32[] constant(-inf), metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  ROOT %reduce.109 = f32[16,76]{1,0} reduce(f32[16,76,30522]{2,1,0} %bitcast.454, f32[] %constant_1537), dimensions={2}, to_apply=%max_F32.1964, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
}

%add_float_.1024 (x.1025: f32[], y.1026: f32[]) -> f32[] {
  %x.1025 = f32[] parameter(0)
  %y.1026 = f32[] parameter(1)
  ROOT %add.1027 = f32[] add(f32[] %x.1025, f32[] %y.1026)
}

%fused_computation.408 (param_0.1253: f32[1216], param_1.1767: f32[30522], param_2.1900: f16[1216,30528]) -> (f32[1216], f32[1216,30522]) {
  %param_2.1900 = f16[1216,30528]{1,0} parameter(2)
  %slice.31.clone.1 = f16[1216,30522]{1,0} slice(f16[1216,30528]{1,0} %param_2.1900), slice={[0:1216], [0:30522]}, metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}
  %param_1.1767 = f32[30522]{0} parameter(1)
  %convert.436.clone.1 = f16[30522]{0} convert(f32[30522]{0} %param_1.1767), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/BiasAdd/Cast"}
  %broadcast.1555.clone.1 = f16[1216,30522]{1,0} broadcast(f16[30522]{0} %convert.436.clone.1), dimensions={1}, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %add.458.clone.1 = f16[1216,30522]{1,0} add(f16[1216,30522]{1,0} %slice.31.clone.1, f16[1216,30522]{1,0} %broadcast.1555.clone.1), metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/BiasAdd"}
  %convert.435.clone.1 = f32[1216,30522]{1,0} convert(f16[1216,30522]{1,0} %add.458.clone.1), metadata={op_type="Cast" op_name="model/bert_pretrain_loss_and_metric_layer/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast_1"}
  %param_0.1253 = f32[1216]{0} parameter(0)
  %broadcast.1554.clone.1 = f32[1216,30522]{1,0} broadcast(f32[1216]{0} %param_0.1253), dimensions={0}, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %subtract.318.clone.1 = f32[1216,30522]{1,0} subtract(f32[1216,30522]{1,0} %convert.435.clone.1, f32[1216,30522]{1,0} %broadcast.1554.clone.1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %exponential.3.clone.1 = f32[1216,30522]{1,0} exponential(f32[1216,30522]{1,0} %subtract.318.clone.1), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %constant_1547 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.110 = f32[1216]{0} reduce(f32[1216,30522]{1,0} %exponential.3.clone.1, f32[] %constant_1547), dimensions={1}, to_apply=%add_float_.1024, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  ROOT %tuple.145 = (f32[1216]{0}, f32[1216,30522]{1,0}) tuple(f32[1216]{0} %reduce.110, f32[1216,30522]{1,0} %exponential.3.clone.1)
}

%add_float_.829 (x.830: f32[], y.831: f32[]) -> f32[] {
  %x.830 = f32[] parameter(0)
  %y.831 = f32[] parameter(1)
  ROOT %add.832 = f32[] add(f32[] %x.830, f32[] %y.831)
}

%fused_computation.409 (param_0.1236: f32[16,2]) -> (f32[16], f32[16]) {
  %param_0.1236 = f32[16,2]{1,0} parameter(0)
  %constant_1544 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.111 = f32[16]{0} reduce(f32[16,2]{1,0} %param_0.1236, f32[] %constant_1544), dimensions={1}, to_apply=%add_float_.829, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %log.0 = f32[16]{0} log(f32[16]{0} %reduce.111), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  ROOT %tuple.148 = (f32[16]{0}, f32[16]{0}) tuple(f32[16]{0} %log.0, f32[16]{0} %reduce.111)
}

ENTRY %cluster_0__XlaCompiledKernel_true__XlaHasReferenceVars_false__XlaNumConstantArgs_120__XlaNumResourceArgs_146_.3712 (arg0.1: f16[16,512,3072], arg1.2: f16[16,512,3072], arg2.3: f16[16,12,512,512], arg3.4: f16[16,12,512,512], arg4.5: f16[16,512,768], arg5.6: f16[16,512,768], arg6.7: f16[16,512,768], arg7.8: f16[16,512,768], arg8.9: f16[16,512,768], arg9.10: s32[16,512], arg10.11: s32[16,76], arg11.12: s32[16,76], arg12.13: f32[16,76], arg13.14: s32[16,1], arg14.15: s32[16,512], arg15.16: s32[16,512], arg16.17: f32[], arg17.18: f32[], arg18.19: f32[], arg19.20: s64[], arg20.21: f32[768], arg21.22: f32[768], arg22.23: f32[768], arg23.24: f32[768,768], arg24.25: f32[512,768], arg25.26: f32[3072], arg26.27: f32[768,3072], arg27.28: f32[768], arg28.29: f32[3072,768], arg29.30: f32[768], arg30.31: f32[768], arg31.32: f32[768], arg32.33: f32[12,64,768], arg33.34: f32[12,64], arg34.35: f32[768,12,64], arg35.36: f32[12,64], arg36.37: f32[768,12,64], arg37.38: f32[12,64], arg38.39: f32[768,12,64], arg39.40: f32[768], arg40.41: f32[768], arg41.42: f32[3072], arg42.43: f32[768,3072], arg43.44: f32[768], arg44.45: f32[3072,768], arg45.46: f32[768], arg46.47: f32[768], arg47.48: f32[768], arg48.49: f32[12,64,768], arg49.50: f32[12,64], arg50.51: f32[768,12,64], arg51.52: f32[12,64], arg52.53: f32[768,12,64], arg53.54: f32[12,64], arg54.55: f32[768,12,64], arg55.56: f32[768], arg56.57: f32[768], arg57.58: f32[2,768], arg58.59: f32[2], arg59.60: f32[768,2], arg60.61: f32[30522], arg61.62: f32[30522,768], arg62.63: f32[768], arg63.64: f32[768], arg64.65: f32[768], arg65.66: f32[768,768], arg66.67: f32[], arg67.68: f32[], arg68.69: f32[2], arg69.70: f32[2], arg70.71: f32[768,2], arg71.72: f32[768,2], arg72.73: f32[768], arg73.74: f32[768], arg74.75: f32[768,768], arg75.76: f32[768,768], arg76.77: f32[], arg77.78: f32[], arg78.79: f32[30522], arg79.80: f32[30522], arg80.81: f32[], arg81.82: f32[768], arg82.83: f32[768], arg83.84: f32[768], arg84.85: f32[768], arg85.86: f32[768,768], arg86.87: f32[768,768], arg87.88: f32[768], arg88.89: f32[768], arg89.90: f32[768], arg90.91: f32[768], arg91.92: f32[768], arg92.93: f32[768], arg93.94: f32[3072,768], arg94.95: f32[3072,768], arg95.96: f32[768], arg96.97: f32[768], arg97.98: f32[768,3072], arg98.99: f32[768,3072], arg99.100: f32[3072], arg100.101: f32[3072], arg101.102: f32[768], arg102.103: f32[768], arg103.104: f32[768], arg104.105: f32[768], arg105.106: f32[12,64,768], arg106.107: f32[12,64,768], arg107.108: f32[768], arg108.109: f32[768], arg109.110: f32[768,12,64], arg110.111: f32[768,12,64], arg111.112: f32[12,64], arg112.113: f32[12,64], arg113.114: f32[768,12,64], arg114.115: f32[768,12,64], arg115.116: f32[12,64], arg116.117: f32[12,64], arg117.118: f32[768,12,64], arg118.119: f32[768,12,64], arg119.120: f32[12,64], arg120.121: f32[12,64], arg121.122: f32[768], arg122.123: f32[768], arg123.124: f32[768], arg124.125: f32[768], arg125.126: f32[3072,768], arg126.127: f32[3072,768], arg127.128: f32[768], arg128.129: f32[768], arg129.130: f32[768,3072], arg130.131: f32[768,3072], arg131.132: f32[3072], arg132.133: f32[3072], arg133.134: f32[768], arg134.135: f32[768], arg135.136: f32[768], arg136.137: f32[768], arg137.138: f32[12,64,768], arg138.139: f32[12,64,768], arg139.140: f32[768], arg140.141: f32[768], arg141.142: f32[12,64], arg142.143: f32[12,64], arg143.144: f32[768,12,64], arg144.145: f32[768,12,64], arg145.146: f32[768,12,64], arg146.147: f32[768,12,64], arg147.148: f32[12,64], arg148.149: f32[12,64], arg149.150: f32[768,12,64], arg150.151: f32[768,12,64], arg151.152: f32[12,64], arg152.153: f32[12,64], arg153.154: f32[768], arg154.155: f32[768], arg155.156: f32[768], arg156.157: f32[768], arg157.158: f32[2,768], arg158.159: f32[2,768], arg159.160: f32[512,768], arg160.161: f32[512,768], arg161.162: f32[30522,768], arg162.163: f32[30522,768]) -> (f32[768], f32[768], f32[768], f32[768,768], f32[512,768], f32[3072], f32[768,3072], f32[768], f32[3072,768], f32[768], f32[768], f32[768], f32[12,64,768], f32[12,64], f32[768,12,64], f32[12,64], f32[768,12,64], f32[12,64], f32[768,12,64], f32[768], f32[768], f32[3072], f32[768,3072], f32[768], f32[3072,768], f32[768], f32[768], f32[768], f32[12,64,768], f32[12,64], f32[768,12,64], f32[12,64], f32[768,12,64], f32[12,64], f32[768,12,64], f32[768], f32[768], f32[2,768], f32[2], f32[768,2], f32[30522], f32[30522,768], f32[768], f32[768], f32[768], f32[768,768], f32[], f32[], f32[2], f32[2], f32[768,2], f32[768,2], f32[768], f32[768], f32[768,768], f32[768,768], f32[], f32[], f32[30522], f32[30522], f32[], f32[768], f32[768], f32[768], f32[768], f32[768,768], f32[768,768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[768], f32[3072,768], f32[3072,768], f32[768], f32[768], f32[768,3072], f32[768,3072], f32[3072], f32[3072], f32[768], f32[768], f32[768], f32[768], f32[12,64,768], f32[12,64,768], f32[768], f32[768], f32[768,12,64], f32[768,12,64], f32[12,64], f32[12,64], f32[768,12,64], f32[768,12,64], f32[12,64], f32[12,64], f32[768,12,64], f32[768,12,64], f32[12,64], f32[12,64], f32[768], f32[768], f32[768], f32[768], f32[3072,768], f32[3072,768], f32[768], f32[768], f32[768,3072], f32[768,3072], f32[3072], f32[3072], f32[768], f32[768], f32[768], f32[768], f32[12,64,768], f32[12,64,768], f32[768], f32[768], f32[12,64], f32[12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[768,12,64], f32[12,64], f32[12,64], f32[768,12,64], f32[768,12,64], f32[12,64], f32[12,64], f32[768], f32[768], f32[768], f32[768], f32[2,768], f32[2,768], f32[512,768], f32[512,768], f32[30522,768], f32[30522,768]) {
  %arg64.65 = f32[768]{0} parameter(64), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg17.18 = f32[] parameter(17), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg16.17 = f32[] parameter(16), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg18.19 = f32[] parameter(18), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg19.20 = s64[] parameter(19), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.225 = f32[] fusion(f32[] %arg17.18, f32[] %arg16.17, f32[] %arg18.19, s64[] %arg19.20), kind=kLoop, calls=%fused_computation.225, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_4/update_0/ResourceApplyAdam"}
  %arg87.88 = f32[768]{0} parameter(87), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg29.30 = f32[768]{0} parameter(29), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg30.31 = f32[768]{0} parameter(30), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg20.21 = f32[768]{0} parameter(20), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg14.15 = s32[16,512]{1,0} parameter(14), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg61.62 = f32[30522,768]{1,0} parameter(61), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg15.16 = s32[16,512]{1,0} parameter(15), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.374 = f16[8192,8]{1,0} fusion(s32[16,512]{1,0} %arg15.16), kind=kLoop, calls=%fused_computation.374, metadata={op_type="MatMul" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul"}
  %arg57.58 = f32[2,768]{1,0} parameter(57), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.373 = f16[8,768]{1,0} fusion(f32[2,768]{1,0} %arg57.58), kind=kLoop, calls=%fused_computation.373, metadata={op_type="MatMul" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul"}
  %custom-call = f16[8192,768]{1,0} custom-call(f16[8192,8]{1,0} %fusion.374, f16[8,768]{1,0} %fusion.373), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %arg24.25 = f32[512,768]{1,0} parameter(24), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.371 = (f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) fusion(s32[16,512]{1,0} %arg14.15, f32[30522,768]{1,0} %arg61.62, f16[8192,768]{1,0} %custom-call, f32[512,768]{1,0} %arg24.25), kind=kInput, calls=%fused_computation.371, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/mean"}
  %get-tuple-element.282 = f16[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.371), index=1
  %arg21.22 = f32[768]{0} parameter(21), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg8.9 = f16[16,512,768]{2,1,0} parameter(8), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.281 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.371), index=0
  %fusion.368 = f32[16,512]{1,0} fusion(f32[16,512]{1,0} %get-tuple-element.281, f16[16,512,768]{2,1,0} %get-tuple-element.282), kind=kInput, calls=%fused_computation.368, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/moments/variance"}
  %fusion.366 = f16[16,512,768]{2,1,0} fusion(f32[768]{0} %arg20.21, f16[16,512,768]{2,1,0} %get-tuple-element.282, f32[768]{0} %arg21.22, f16[16,512,768]{2,1,0} %arg8.9, f32[16,512]{1,0} %get-tuple-element.281, f32[16,512]{1,0} %fusion.368), kind=kLoop, calls=%fused_computation.366, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/dropout/dropout/Mul_1"}
  %bitcast.37 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %fusion.366)
  %arg34.35 = f32[768,12,64]{2,1,0} parameter(34), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.388 = f16[768,768]{1,0} fusion(f32[768,12,64]{2,1,0} %arg34.35), kind=kLoop, calls=%fused_computation.388
  %custom-call.1 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.37, f16[768,768]{1,0} %fusion.388), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg33.34 = f32[12,64]{1,0} parameter(33), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.364 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.1, f32[12,64]{1,0} %arg33.34), kind=kLoop, calls=%fused_computation.364
  %arg36.37 = f32[768,12,64]{2,1,0} parameter(36), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.387 = f16[768,768]{1,0} fusion(f32[768,12,64]{2,1,0} %arg36.37), kind=kLoop, calls=%fused_computation.387
  %custom-call.2 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.37, f16[768,768]{1,0} %fusion.387), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg35.36 = f32[12,64]{1,0} parameter(35), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.389 = f16[16,12,64,512]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.2, f32[12,64]{1,0} %arg35.36), kind=kLoop, calls=%fused_computation.389
  %custom-call.3 = f16[16,12,512,512]{3,2,1,0} custom-call(f16[16,12,512,64]{3,2,1,0} %fusion.364, f16[16,12,64,512]{3,2,1,0} %fusion.389), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %arg9.10 = s32[16,512]{1,0} parameter(9), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.361 = f16[16,12,512,512]{2,3,1,0} fusion(f16[16,12,512,512]{3,2,1,0} %custom-call.3, s32[16,512]{1,0} %arg9.10), kind=kLoop, calls=%fused_computation.361, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/add"}
  %bitcast = f16[16,12,512,512]{3,2,1,0} bitcast(f16[16,12,512,512]{2,3,1,0} %fusion.361), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %constant_414 = f16[] constant(-inf), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %reduce.1 = f16[16,12,512]{2,1,0} reduce(f16[16,12,512,512]{3,2,1,0} %bitcast, f16[] %constant_414), dimensions={2}, to_apply=%max_half_.415, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %fusion.360 = f16[16,12,512,512]{2,3,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.361, f16[16,12,512]{2,1,0} %reduce.1), kind=kLoop, calls=%fused_computation.360, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %fusion.359 = f32[16,12,512,512]{3,2,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.360), kind=kLoop, calls=%fused_computation.359, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %constant_193 = f32[] constant(0), metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_3"}
  %reduce.2 = f32[16,12,512]{2,1,0} reduce(f32[16,12,512,512]{3,2,1,0} %fusion.359, f32[] %constant_193), dimensions={2}, to_apply=%add_float_.425, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Softmax"}
  %arg3.4 = f16[16,12,512,512]{3,2,1,0} parameter(3), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.357 = f16[16,12,512,512]{3,2,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.360, f32[16,12,512]{2,1,0} %reduce.2, f16[16,12,512,512]{3,2,1,0} %arg3.4), kind=kLoop, calls=%fused_computation.357, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/dropout_3/dropout/Mul_1"}
  %arg38.39 = f32[768,12,64]{2,1,0} parameter(38), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.386 = f16[768,768]{1,0} fusion(f32[768,12,64]{2,1,0} %arg38.39), kind=kLoop, calls=%fused_computation.386
  %custom-call.4 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.37, f16[768,768]{1,0} %fusion.386), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg37.38 = f32[12,64]{1,0} parameter(37), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.390 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.4, f32[12,64]{1,0} %arg37.38), kind=kLoop, calls=%fused_computation.390
  %custom-call.5 = f16[16,12,512,64]{3,2,1,0} custom-call(f16[16,12,512,512]{3,2,1,0} %fusion.357, f16[16,12,512,64]{3,2,1,0} %fusion.390), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.355 = f16[8192,768]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.5), kind=kLoop, calls=%fused_computation.355
  %arg32.33 = f32[12,64,768]{2,1,0} parameter(32), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.385 = f16[768,768]{1,0} fusion(f32[12,64,768]{2,1,0} %arg32.33), kind=kLoop, calls=%fused_computation.385
  %custom-call.6 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.355, f16[768,768]{1,0} %fusion.385), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg31.32 = f32[768]{0} parameter(31), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg7.8 = f16[16,512,768]{2,1,0} parameter(7), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.353 = (f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) fusion(f16[16,512,768]{2,1,0} %fusion.366, f16[8192,768]{1,0} %custom-call.6, f32[768]{0} %arg31.32, f16[16,512,768]{2,1,0} %arg7.8), kind=kInput, calls=%fused_computation.353, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/mean"}
  %get-tuple-element.279 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.353), index=0
  %arg39.40 = f32[768]{0} parameter(39), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg40.41 = f32[768]{0} parameter(40), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.280 = f16[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.353), index=1
  %fusion.350 = f32[16,512]{1,0} fusion(f32[16,512]{1,0} %get-tuple-element.279, f16[16,512,768]{2,1,0} %get-tuple-element.280), kind=kInput, calls=%fused_computation.350, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/moments/variance"}
  %fusion.347 = f16[8192,768]{1,0} fusion(f32[16,512]{1,0} %get-tuple-element.279, f32[768]{0} %arg39.40, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f16[16,512,768]{2,1,0} %get-tuple-element.280), kind=kLoop, calls=%fused_computation.347
  %arg26.27 = f32[768,3072]{1,0} parameter(26), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %convert.261 = f16[768,3072]{1,0} convert(f32[768,3072]{1,0} %arg26.27), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/einsum/Einsum/Cast"}
  %custom-call.7 = f16[8192,3072]{1,0} custom-call(f16[8192,768]{1,0} %fusion.347, f16[768,3072]{1,0} %convert.261), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg25.26 = f32[3072]{0} parameter(25), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.345 = f16[16,512,3072]{2,1,0} fusion(f16[8192,3072]{1,0} %custom-call.7, f32[3072]{0} %arg25.26), kind=kLoop, calls=%fused_computation.345, metadata={op_type="Tanh" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/activation/Gelu/Tanh"}
  %arg1.2 = f16[16,512,3072]{2,1,0} parameter(1), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.344 = f16[8192,3072]{1,0} fusion(f16[16,512,3072]{2,1,0} %fusion.345, f16[16,512,3072]{2,1,0} %arg1.2, f16[8192,3072]{1,0} %custom-call.7, f32[3072]{0} %arg25.26), kind=kLoop, calls=%fused_computation.344
  %arg28.29 = f32[3072,768]{1,0} parameter(28), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %convert.263 = f16[3072,768]{1,0} convert(f32[3072,768]{1,0} %arg28.29), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum/Cast"}
  %custom-call.8 = f16[8192,768]{1,0} custom-call(f16[8192,3072]{1,0} %fusion.344, f16[3072,768]{1,0} %convert.263), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %arg27.28 = f32[768]{0} parameter(27), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg6.7 = f16[16,512,768]{2,1,0} parameter(6), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.391 = f32[16,512]{1,0} fusion(f32[16,512]{1,0} %get-tuple-element.279, f32[768]{0} %arg39.40, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f16[16,512,768]{2,1,0} %get-tuple-element.280, f16[8192,768]{1,0} %custom-call.8, f32[768]{0} %arg27.28, f16[16,512,768]{2,1,0} %arg6.7), kind=kInput, calls=%fused_computation.391, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/mean"}
  %fusion.341 = (f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) fusion(f32[16,512]{1,0} %fusion.391, f32[16,512]{1,0} %get-tuple-element.279, f32[768]{0} %arg39.40, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f16[16,512,768]{2,1,0} %get-tuple-element.280, f16[8192,768]{1,0} %custom-call.8, f32[768]{0} %arg27.28, f16[16,512,768]{2,1,0} %arg6.7), kind=kInput, calls=%fused_computation.341, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/moments/variance"}
  %get-tuple-element.275 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.341), index=0
  %fusion.339 = f16[16,512,768]{2,1,0} fusion(f32[768]{0} %arg29.30, f32[768]{0} %arg30.31, f32[16,512]{1,0} %get-tuple-element.279, f32[768]{0} %arg39.40, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f16[16,512,768]{2,1,0} %get-tuple-element.280, f16[8192,768]{1,0} %custom-call.8, f32[768]{0} %arg27.28, f16[16,512,768]{2,1,0} %arg6.7, f32[16,512]{1,0} %fusion.391, f32[16,512]{1,0} %get-tuple-element.275), kind=kLoop, calls=%fused_computation.339, metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast_2"}
  %bitcast.48 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %fusion.339)
  %arg50.51 = f32[768,12,64]{2,1,0} parameter(50), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.384 = f16[768,768]{1,0} fusion(f32[768,12,64]{2,1,0} %arg50.51), kind=kLoop, calls=%fused_computation.384
  %custom-call.9 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.48, f16[768,768]{1,0} %fusion.384), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg49.50 = f32[12,64]{1,0} parameter(49), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.337 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.9, f32[12,64]{1,0} %arg49.50), kind=kLoop, calls=%fused_computation.337
  %arg52.53 = f32[768,12,64]{2,1,0} parameter(52), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.383 = f16[768,768]{1,0} fusion(f32[768,12,64]{2,1,0} %arg52.53), kind=kLoop, calls=%fused_computation.383
  %custom-call.10 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.48, f16[768,768]{1,0} %fusion.383), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg51.52 = f32[12,64]{1,0} parameter(51), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.393 = f16[16,12,64,512]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.10, f32[12,64]{1,0} %arg51.52), kind=kLoop, calls=%fused_computation.393
  %custom-call.11 = f16[16,12,512,512]{3,2,1,0} custom-call(f16[16,12,512,64]{3,2,1,0} %fusion.337, f16[16,12,64,512]{3,2,1,0} %fusion.393), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.335 = f16[16,12,512,512]{2,3,1,0} fusion(f16[16,12,512,512]{3,2,1,0} %custom-call.11, s32[16,512]{1,0} %arg9.10), kind=kLoop, calls=%fused_computation.335, metadata={op_type="AddV2" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/add"}
  %bitcast.2 = f16[16,12,512,512]{3,2,1,0} bitcast(f16[16,12,512,512]{2,3,1,0} %fusion.335), metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %reduce.3 = f16[16,12,512]{2,1,0} reduce(f16[16,12,512,512]{3,2,1,0} %bitcast.2, f16[] %constant_414), dimensions={2}, to_apply=%max_half_.591, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %fusion.334 = f16[16,12,512,512]{2,3,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.335, f16[16,12,512]{2,1,0} %reduce.3), kind=kLoop, calls=%fused_computation.334, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %fusion.333 = f32[16,12,512,512]{3,2,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.334), kind=kLoop, calls=%fused_computation.333, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %reduce.4 = f32[16,12,512]{2,1,0} reduce(f32[16,12,512,512]{3,2,1,0} %fusion.333, f32[] %constant_193), dimensions={2}, to_apply=%add_float_.601, metadata={op_type="Softmax" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Softmax"}
  %arg2.3 = f16[16,12,512,512]{3,2,1,0} parameter(2), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.331 = f16[16,12,512,512]{3,2,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.334, f32[16,12,512]{2,1,0} %reduce.4, f16[16,12,512,512]{3,2,1,0} %arg2.3), kind=kLoop, calls=%fused_computation.331, metadata={op_type="Mul" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/dropout_3/dropout/Mul_1"}
  %arg54.55 = f32[768,12,64]{2,1,0} parameter(54), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.382 = f16[768,768]{1,0} fusion(f32[768,12,64]{2,1,0} %arg54.55), kind=kLoop, calls=%fused_computation.382
  %custom-call.12 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.48, f16[768,768]{1,0} %fusion.382), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg53.54 = f32[12,64]{1,0} parameter(53), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.394 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.12, f32[12,64]{1,0} %arg53.54), kind=kLoop, calls=%fused_computation.394
  %custom-call.13 = f16[16,12,512,64]{3,2,1,0} custom-call(f16[16,12,512,512]{3,2,1,0} %fusion.331, f16[16,12,512,64]{3,2,1,0} %fusion.394), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.329 = f16[8192,768]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.13), kind=kLoop, calls=%fused_computation.329
  %arg48.49 = f32[12,64,768]{2,1,0} parameter(48), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.381 = f16[768,768]{1,0} fusion(f32[12,64,768]{2,1,0} %arg48.49), kind=kLoop, calls=%fused_computation.381
  %custom-call.14 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.329, f16[768,768]{1,0} %fusion.381), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg47.48 = f32[768]{0} parameter(47), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg5.6 = f16[16,512,768]{2,1,0} parameter(5), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.327 = (f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) fusion(f16[16,512,768]{2,1,0} %fusion.339, f16[8192,768]{1,0} %custom-call.14, f32[768]{0} %arg47.48, f16[16,512,768]{2,1,0} %arg5.6), kind=kInput, calls=%fused_computation.327, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/mean"}
  %get-tuple-element.273 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.327), index=0
  %arg55.56 = f32[768]{0} parameter(55), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg56.57 = f32[768]{0} parameter(56), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.274 = f16[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.327), index=1
  %fusion.324 = f32[16,512]{1,0} fusion(f32[16,512]{1,0} %get-tuple-element.273, f16[16,512,768]{2,1,0} %get-tuple-element.274), kind=kInput, calls=%fused_computation.324, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/moments/variance"}
  %fusion.321 = f16[8192,768]{1,0} fusion(f32[16,512]{1,0} %get-tuple-element.273, f32[768]{0} %arg55.56, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f16[16,512,768]{2,1,0} %get-tuple-element.274), kind=kLoop, calls=%fused_computation.321
  %arg42.43 = f32[768,3072]{1,0} parameter(42), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %convert.298 = f16[768,3072]{1,0} convert(f32[768,3072]{1,0} %arg42.43), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/einsum/Einsum/Cast"}
  %custom-call.15 = f16[8192,3072]{1,0} custom-call(f16[8192,768]{1,0} %fusion.321, f16[768,3072]{1,0} %convert.298), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %arg41.42 = f32[3072]{0} parameter(41), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.319 = f16[16,512,3072]{2,1,0} fusion(f16[8192,3072]{1,0} %custom-call.15, f32[3072]{0} %arg41.42), kind=kLoop, calls=%fused_computation.319, metadata={op_type="Tanh" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/activation/Gelu/Tanh"}
  %arg0.1 = f16[16,512,3072]{2,1,0} parameter(0), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.318 = f16[8192,3072]{1,0} fusion(f16[16,512,3072]{2,1,0} %fusion.319, f16[16,512,3072]{2,1,0} %arg0.1, f16[8192,3072]{1,0} %custom-call.15, f32[3072]{0} %arg41.42), kind=kLoop, calls=%fused_computation.318
  %arg44.45 = f32[3072,768]{1,0} parameter(44), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %convert.300 = f16[3072,768]{1,0} convert(f32[3072,768]{1,0} %arg44.45), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum/Cast"}
  %custom-call.16 = f16[8192,768]{1,0} custom-call(f16[8192,3072]{1,0} %fusion.318, f16[3072,768]{1,0} %convert.300), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %arg43.44 = f32[768]{0} parameter(43), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg4.5 = f16[16,512,768]{2,1,0} parameter(4), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.395 = f32[16,512]{1,0} fusion(f32[16,512]{1,0} %get-tuple-element.273, f32[768]{0} %arg55.56, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f16[16,512,768]{2,1,0} %get-tuple-element.274, f16[8192,768]{1,0} %custom-call.16, f32[768]{0} %arg43.44, f16[16,512,768]{2,1,0} %arg4.5), kind=kInput, calls=%fused_computation.395, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/mean"}
  %arg45.46 = f32[768]{0} parameter(45), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg46.47 = f32[768]{0} parameter(46), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.315 = (f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) fusion(f32[16,512]{1,0} %fusion.395, f32[16,512]{1,0} %get-tuple-element.273, f32[768]{0} %arg55.56, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f16[16,512,768]{2,1,0} %get-tuple-element.274, f16[8192,768]{1,0} %custom-call.16, f32[768]{0} %arg43.44, f16[16,512,768]{2,1,0} %arg4.5), kind=kInput, calls=%fused_computation.315, metadata={op_type="Mean" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/moments/variance"}
  %get-tuple-element.269 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.315), index=0
  %arg11.12 = s32[16,76]{1,0} parameter(11), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %constant_25 = s32[16]{0} constant({...}), metadata={op_type="AddV2" op_name="model/bert_pretrainer/cls/predictions/add"}
  %fusion.312 = f16[1216,768]{1,0} fusion(f32[16,512]{1,0} %fusion.395, f32[768]{0} %arg45.46, f32[768]{0} %arg46.47, f32[16,512]{1,0} %get-tuple-element.269, f32[16,512]{1,0} %get-tuple-element.273, f32[768]{0} %arg55.56, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f16[16,512,768]{2,1,0} %get-tuple-element.274, f16[8192,768]{1,0} %custom-call.16, f32[768]{0} %arg43.44, f16[16,512,768]{2,1,0} %arg4.5, s32[16,76]{1,0} %arg11.12, s32[16]{0} %constant_25), kind=kLoop, calls=%fused_computation.312, metadata={op_type="GatherV2" op_name="model/bert_pretrainer/cls/predictions/GatherV2"}
  %arg65.66 = f32[768,768]{1,0} parameter(65), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %convert.913 = f16[768,768]{1,0} convert(f32[768,768]{1,0} %arg65.66), metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/dense/MatMul/Cast"}
  %fusion.311 = f16[1216,768]{1,0} fusion(f32[768]{0} %arg64.65), kind=kLoop, calls=%fused_computation.311, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd"}
  %custom-call.18 = f16[1216,768]{1,0} custom-call(f16[1216,768]{1,0} %fusion.312, f16[768,768]{1,0} %convert.913, f16[1216,768]{1,0} %fusion.311), custom_call_target="__cublas$gemm", metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"114\"}"
  %fusion.307 = (f32[1216]{0}, f16[1216,768]{1,0}, f16[1216,768]{1,0}) fusion(f16[1216,768]{1,0} %custom-call.18), kind=kInput, calls=%fused_computation.307, metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/mean"}
  %get-tuple-element.266 = f16[1216,768]{1,0} get-tuple-element((f32[1216]{0}, f16[1216,768]{1,0}, f16[1216,768]{1,0}) %fusion.307), index=2
  %arg63.64 = f32[768]{0} parameter(63), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.264 = f32[1216]{0} get-tuple-element((f32[1216]{0}, f16[1216,768]{1,0}, f16[1216,768]{1,0}) %fusion.307), index=0
  %get-tuple-element.265 = f16[1216,768]{1,0} get-tuple-element((f32[1216]{0}, f16[1216,768]{1,0}, f16[1216,768]{1,0}) %fusion.307), index=1
  %fusion.304 = f32[1216]{0} fusion(f32[1216]{0} %get-tuple-element.264, f16[1216,768]{1,0} %get-tuple-element.265), kind=kInput, calls=%fused_computation.304, metadata={op_type="Mean" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/moments/variance"}
  %arg10.11 = s32[16,76]{1,0} parameter(10), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg60.61 = f32[30522]{0} parameter(60), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg62.63 = f32[768]{0} parameter(62), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.302 = f16[1216,768]{1,0} fusion(f32[768]{0} %arg62.63, f16[1216,768]{1,0} %get-tuple-element.265, f32[768]{0} %arg63.64, f32[1216]{0} %get-tuple-element.264, f32[1216]{0} %fusion.304), kind=kLoop, calls=%fused_computation.302, metadata={op_type="Cast" op_name="model/bert_pretrainer/cls/predictions/transform/LayerNorm/Cast_1"}
  %fusion.379 = f16[30528,768]{1,0} fusion(f32[30522,768]{1,0} %arg61.62), kind=kLoop, calls=%fused_computation.379, metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}
  %custom-call.19 = f16[1216,30528]{1,0} custom-call(f16[1216,768]{1,0} %fusion.302, f16[30528,768]{1,0} %fusion.379), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="model/bert_pretrainer/cls/predictions/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %fusion.300 = f32[1216]{0} fusion(f32[30522]{0} %arg60.61, f16[1216,30528]{1,0} %custom-call.19), kind=kInput, calls=%fused_computation.300, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %fusion.408 = (f32[1216]{0}, f32[1216,30522]{1,0}) fusion(f32[1216]{0} %fusion.300, f32[30522]{0} %arg60.61, f16[1216,30528]{1,0} %custom-call.19), kind=kInput, calls=%fused_computation.408, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %get-tuple-element.263 = f32[1216,30522]{1,0} get-tuple-element((f32[1216]{0}, f32[1216,30522]{1,0}) %fusion.408), index=1
  %get-tuple-element.262 = f32[1216]{0} get-tuple-element((f32[1216]{0}, f32[1216,30522]{1,0}) %fusion.408), index=0
  %arg12.13 = f32[16,76]{1,0} parameter(12), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.407 = f32[16,76]{1,0} fusion(f32[30522]{0} %arg60.61, f16[1216,30528]{1,0} %custom-call.19), kind=kInput, calls=%fused_computation.407, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
  %fusion.3 = s64[16,76]{1,0} fusion(f32[16,76]{1,0} %fusion.407, f32[30522]{0} %arg60.61, f16[1216,30528]{1,0} %custom-call.19), kind=kInput, calls=%fused_computation.3, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax"}
  %log.1030 = f32[1216]{0} log(f32[1216]{0} %get-tuple-element.262), metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %fusion.7 = f32[1216]{0} fusion(f32[1216]{0} %log.1030, s32[16,76]{1,0} %arg10.11, f32[1216]{0} %fusion.300, f32[30522]{0} %arg60.61, f16[1216,30528]{1,0} %custom-call.19), kind=kInput, calls=%fused_computation.7, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits"}
  %fusion.2 = (f32[], f32[], f32[]) fusion(s32[16,76]{1,0} %arg10.11, s64[16,76]{1,0} %fusion.3, f32[16,76]{1,0} %arg12.13, f32[1216]{0} %fusion.7), kind=kInput, calls=%fused_computation.2, metadata={op_type="Sum" op_name="model/bert_pretrain_loss_and_metric_layer/Sum_2"}
  %get-tuple-element.260 = f32[] get-tuple-element((f32[], f32[], f32[]) %fusion.2), index=1
  %fusion.399 = f16[1216,30528]{1,0} fusion(s32[16,76]{1,0} %arg10.11, f32[1216,30522]{1,0} %get-tuple-element.263, f32[1216]{0} %get-tuple-element.262, f32[16,76]{1,0} %arg12.13, f32[] %get-tuple-element.260), kind=kLoop, calls=%fused_computation.399, metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/MatMul/MatMul"}
  %custom-call.20 = f16[1216,768]{1,0} custom-call(f16[1216,30528]{1,0} %fusion.399, f16[30528,768]{1,0} %fusion.379), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/MatMul/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"110\"}"
  %fusion.293 = (f32[1216]{0}, f32[1216]{0}) fusion(f32[768]{0} %arg63.64, f32[1216]{0} %fusion.304, f16[1216,768]{1,0} %custom-call.20, f32[1216]{0} %get-tuple-element.264, f16[1216,768]{1,0} %get-tuple-element.265), kind=kInput, calls=%fused_computation.293, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/LayerNorm/batchnorm/mul_2/Sum"}
  %get-tuple-element.256 = f32[1216]{0} get-tuple-element((f32[1216]{0}, f32[1216]{0}) %fusion.293), index=0
  %get-tuple-element.257 = f32[1216]{0} get-tuple-element((f32[1216]{0}, f32[1216]{0}) %fusion.293), index=1
  %fusion.19 = (f32[768]{0}, f16[1216,768]{1,0}, f32[768]{0}, f32[768]{0}) fusion(f16[1216,768]{1,0} %get-tuple-element.266, f16[1216,768]{1,0} %custom-call.18, f32[1216]{0} %get-tuple-element.256, f32[1216]{0} %get-tuple-element.264, f16[1216,768]{1,0} %get-tuple-element.265, f32[1216]{0} %get-tuple-element.257, f32[768]{0} %arg63.64, f32[1216]{0} %fusion.304, f16[1216,768]{1,0} %custom-call.20), kind=kInput, calls=%fused_computation.19, metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/BiasAdd/BiasAddGrad"}
  %get-tuple-element.252 = f32[768]{0} get-tuple-element((f32[768]{0}, f16[1216,768]{1,0}, f32[768]{0}, f32[768]{0}) %fusion.19), index=0
  %arg88.89 = f32[768]{0} parameter(88), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg84.85 = f32[768]{0} parameter(84), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.255 = f32[768]{0} get-tuple-element((f32[768]{0}, f16[1216,768]{1,0}, f32[768]{0}, f32[768]{0}) %fusion.19), index=3
  %arg83.84 = f32[768]{0} parameter(83), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg82.83 = f32[768]{0} parameter(82), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.254 = f32[768]{0} get-tuple-element((f32[768]{0}, f16[1216,768]{1,0}, f32[768]{0}, f32[768]{0}) %fusion.19), index=2
  %arg81.82 = f32[768]{0} parameter(81), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg104.105 = f32[768]{0} parameter(104), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg58.59 = f32[2]{0} parameter(58), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.290 = f16[16,768]{1,0} fusion(f32[16,512]{1,0} %fusion.395, f32[768]{0} %arg45.46, f32[768]{0} %arg46.47, f32[16,512]{1,0} %get-tuple-element.269, f32[16,512]{1,0} %get-tuple-element.273, f32[768]{0} %arg55.56, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f16[16,512,768]{2,1,0} %get-tuple-element.274, f16[8192,768]{1,0} %custom-call.16, f32[768]{0} %arg43.44, f16[16,512,768]{2,1,0} %arg4.5), kind=kLoop, calls=%fused_computation.290, metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/Cast_3"}
  %arg23.24 = f32[768,768]{1,0} parameter(23), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %convert.231 = f16[768,768]{1,0} convert(f32[768,768]{1,0} %arg23.24), metadata={op_type="Cast" op_name="model/bert_pretrainer/bert_encoder_1/pooler_transform/MatMul/Cast"}
  %arg22.23 = f32[768]{0} parameter(22), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.289 = f16[16,768]{1,0} fusion(f32[768]{0} %arg22.23), kind=kLoop, calls=%fused_computation.289, metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd"}
  %custom-call.23 = f16[16,768]{1,0} custom-call(f16[16,768]{1,0} %fusion.290, f16[768,768]{1,0} %convert.231, f16[16,768]{1,0} %fusion.289), custom_call_target="__cublas$gemm", metadata={op_type="BiasAdd" op_name="model/bert_pretrainer/bert_encoder_1/pooler_transform/BiasAdd"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":1,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"114\"}"
  %tanh.758 = f16[16,768]{1,0} tanh(f16[16,768]{1,0} %custom-call.23), metadata={op_type="Tanh" op_name="model/bert_pretrainer/bert_encoder_1/pooler_transform/Tanh"}
  %arg59.60 = f32[768,2]{1,0} parameter(59), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.288 = f16[768,8]{1,0} fusion(f32[768,2]{1,0} %arg59.60), kind=kLoop, calls=%fused_computation.288, metadata={op_type="MatMul" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}
  %custom-call.24 = f16[16,8]{1,0} custom-call(f16[16,768]{1,0} %tanh.758, f16[768,8]{1,0} %fusion.288), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"115\"}"
  %fusion.286 = f32[16]{0} fusion(f32[2]{0} %arg58.59, f16[16,8]{1,0} %custom-call.24), kind=kLoop, calls=%fused_computation.286, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %fusion.397 = f32[16,2]{1,0} fusion(f32[16]{0} %fusion.286, f32[2]{0} %arg58.59, f16[16,8]{1,0} %custom-call.24), kind=kLoop, calls=%fused_computation.397, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %fusion.409 = (f32[16]{0}, f32[16]{0}) fusion(f32[16,2]{1,0} %fusion.397), kind=kLoop, calls=%fused_computation.409, metadata={op_type="SparseSoftmaxCrossEntropyWithLogits" op_name="model/bert_pretrain_loss_and_metric_layer/SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits"}
  %get-tuple-element.268 = f32[16]{0} get-tuple-element((f32[16]{0}, f32[16]{0}) %fusion.409), index=1
  %arg13.14 = s32[16,1]{1,0} parameter(13), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.283 = f16[16,2]{1,0} fusion(f32[16,2]{1,0} %fusion.397, f32[16]{0} %get-tuple-element.268, s32[16,1]{1,0} %arg13.14), kind=kLoop, calls=%fused_computation.283, metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrain_loss_and_metric_layer/Cast_4/ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_float_Cast"}
  %constant_242 = f16[] constant(0), metadata={op_type="GreaterEqual" op_name="model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_1/dropout/GreaterEqual"}
  %pad.4 = f16[16,8]{1,0} pad(f16[16,2]{1,0} %fusion.283, f16[] %constant_242), padding=0_0x0_6, metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}
  %custom-call.25 = f16[16,768]{1,0} custom-call(f16[16,8]{1,0} %pad.4, f16[768,8]{1,0} %fusion.288), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"115\"}"
  %fusion.282 = f16[16,768]{1,0} fusion(f16[16,768]{1,0} %custom-call.25, f16[16,768]{1,0} %tanh.758), kind=kLoop, calls=%fused_computation.282, metadata={op_type="TanhGrad" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/TanhGrad"}
  %custom-call.26 = f16[16,768]{1,0} custom-call(f16[16,768]{1,0} %fusion.282, f16[768,768]{1,0} %convert.231), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"112\"}"
  %get-tuple-element.253 = f16[1216,768]{1,0} get-tuple-element((f32[768]{0}, f16[1216,768]{1,0}, f32[768]{0}, f32[768]{0}) %fusion.19), index=1
  %custom-call.21 = f16[1216,768]{1,0} custom-call(f16[1216,768]{1,0} %get-tuple-element.253, f16[768,768]{1,0} %convert.913), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"115\"}"
  %fusion.291 = f16[8192,768]{1,0} fusion(f16[1216,768]{1,0} %custom-call.21, s32[16,76]{1,0} %arg11.12, s32[16]{0} %constant_25), kind=kInput, calls=%fused_computation.291, metadata={op_type="UnsortedSegmentSum" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/UnsortedSegmentSum"}
  %fusion.278 = (f32[16,512]{1,0}, f32[16,512]{1,0}) fusion(f32[768]{0} %arg46.47, f32[16,512]{1,0} %get-tuple-element.269, f16[16,768]{1,0} %custom-call.26, f16[8192,768]{1,0} %fusion.291, f32[16,512]{1,0} %fusion.395, f32[16,512]{1,0} %get-tuple-element.273, f32[768]{0} %arg55.56, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f16[16,512,768]{2,1,0} %get-tuple-element.274, f16[8192,768]{1,0} %custom-call.16, f32[768]{0} %arg43.44, f16[16,512,768]{2,1,0} %arg4.5), kind=kInput, calls=%fused_computation.278, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output_layer_norm/batchnorm/mul_2/Sum"}
  %get-tuple-element.250 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}) %fusion.278), index=0
  %get-tuple-element.270 = f32[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.315), index=1
  %get-tuple-element.251 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}) %fusion.278), index=1
  %fusion.276 = f16[16,512,768]{2,1,0} fusion(f16[16,512,768]{2,1,0} %arg4.5, f32[16,512]{1,0} %get-tuple-element.250, f32[16,512,768]{2,1,0} %get-tuple-element.270, f32[16,512]{1,0} %get-tuple-element.251, f32[768]{0} %arg46.47, f32[16,512]{1,0} %get-tuple-element.269, f16[16,768]{1,0} %custom-call.26, f16[8192,768]{1,0} %fusion.291), kind=kLoop, calls=%fused_computation.276, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout_2/dropout/Mul_1"}
  %bitcast.73 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %fusion.276)
  %custom-call.27 = f16[8192,3072]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.73, f16[3072,768]{1,0} %convert.300), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %fusion.275 = f16[16,512,3072]{2,1,0} fusion(f16[16,512,3072]{2,1,0} %fusion.319, f16[8192,3072]{1,0} %custom-call.27, f16[16,512,3072]{2,1,0} %arg0.1, f16[8192,3072]{1,0} %custom-call.15, f32[3072]{0} %arg41.42), kind=kLoop, calls=%fused_computation.275, metadata={op_type="AddN" op_name="AddN_6"}
  %bitcast.75 = f16[8192,3072]{1,0} bitcast(f16[16,512,3072]{2,1,0} %fusion.275)
  %custom-call.28 = f16[8192,768]{1,0} custom-call(f16[8192,3072]{1,0} %bitcast.75, f16[768,3072]{1,0} %convert.298), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %fusion.271 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) fusion(f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f32[16,512]{1,0} %get-tuple-element.273, f16[16,512,768]{2,1,0} %get-tuple-element.274, f16[8192,768]{1,0} %custom-call.28, f32[16,512]{1,0} %get-tuple-element.250, f32[16,512,768]{2,1,0} %get-tuple-element.270, f32[16,512]{1,0} %get-tuple-element.251, f32[768]{0} %arg46.47, f32[16,512]{1,0} %get-tuple-element.269, f16[16,768]{1,0} %custom-call.26, f16[8192,768]{1,0} %fusion.291), kind=kInput, calls=%fused_computation.271, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention_layer_norm/batchnorm/mul_2/Sum"}
  %get-tuple-element.245 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.271), index=0
  %get-tuple-element.246 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.271), index=1
  %get-tuple-element.247 = f32[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.271), index=2
  %fusion.269 = f16[16,512,768]{2,1,0} fusion(f16[16,512,768]{2,1,0} %arg5.6, f32[16,512]{1,0} %get-tuple-element.245, f32[16,512]{1,0} %get-tuple-element.273, f16[16,512,768]{2,1,0} %get-tuple-element.274, f32[16,512]{1,0} %get-tuple-element.246, f32[16,512,768]{2,1,0} %get-tuple-element.247, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324), kind=kLoop, calls=%fused_computation.269, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/dropout/dropout/Mul_1"}
  %fusion.97 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) fusion(f16[16,512,768]{2,1,0} %fusion.269, f32[16,512,768]{2,1,0} %get-tuple-element.247, f32[16,512]{1,0} %get-tuple-element.269, f32[16,512]{1,0} %fusion.395, f32[16,512]{1,0} %get-tuple-element.273, f32[768]{0} %arg55.56, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324, f16[16,512,768]{2,1,0} %get-tuple-element.274, f16[8192,768]{1,0} %custom-call.16, f32[768]{0} %arg43.44, f16[16,512,768]{2,1,0} %arg4.5, f16[16,768]{1,0} %custom-call.26, f16[8192,768]{1,0} %fusion.291), kind=kInput, calls=%fused_computation.97, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/attention_output/add/Sum"}
  %get-tuple-element.286 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.97), index=3
  %arg103.104 = f32[768]{0} parameter(103), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg102.103 = f32[768]{0} parameter(102), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.287 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.97), index=4
  %arg101.102 = f32[768]{0} parameter(101), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg108.109 = f32[768]{0} parameter(108), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.283 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.97), index=0
  %arg107.108 = f32[768]{0} parameter(107), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg92.93 = f32[768]{0} parameter(92), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.285 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.97), index=2
  %arg91.92 = f32[768]{0} parameter(91), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg90.91 = f32[768]{0} parameter(90), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.284 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.97), index=1
  %arg89.90 = f32[768]{0} parameter(89), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg155.156 = f32[768]{0} parameter(155), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %bitcast.80 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %fusion.269)
  %fusion.268 = f16[768,768]{0,1} fusion(f32[12,64,768]{2,1,0} %arg48.49), kind=kLoop, calls=%fused_computation.268
  %custom-call.29 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.80, f16[768,768]{0,1} %fusion.268), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.258 = f16[16,12,64,512]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.29), kind=kLoop, calls=%fused_computation.258
  %custom-call.35 = f16[16,12,64,512]{3,2,1,0} custom-call(f16[16,12,64,512]{3,2,1,0} %fusion.258, f16[16,12,512,512]{3,2,1,0} %fusion.331), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.257 = f16[8192,768]{1,0} fusion(f16[16,12,64,512]{3,2,1,0} %custom-call.35), kind=kLoop, calls=%fused_computation.257
  %fusion.256 = f16[768,768]{0,1} fusion(f32[768,12,64]{2,1,0} %arg54.55), kind=kLoop, calls=%fused_computation.256
  %custom-call.36 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.257, f16[768,768]{0,1} %fusion.256), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.378 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.29), kind=kLoop, calls=%fused_computation.378
  %fusion.267 = f16[16,12,64,512]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.12, f32[12,64]{1,0} %arg53.54), kind=kLoop, calls=%fused_computation.267
  %custom-call.30 = f16[16,12,512,512]{3,2,1,0} custom-call(f16[16,12,512,64]{3,2,1,0} %fusion.378, f16[16,12,64,512]{3,2,1,0} %fusion.267), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum_1/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.265 = f32[16,12,512,512]{3,2,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.334, f32[16,12,512]{2,1,0} %reduce.4, f16[16,12,512,512]{3,2,1,0} %custom-call.30, f16[16,12,512,512]{3,2,1,0} %arg2.3), kind=kLoop, calls=%fused_computation.265, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Sum"}
  %reduce.5 = f32[16,12,512]{2,1,0} reduce(f32[16,12,512,512]{3,2,1,0} %fusion.265, f32[] %constant_193), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_1_self_attention_softmax_Sum-reduction.1354, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/Sum"}
  %fusion.264 = f16[16,12,512,512]{3,2,1,0} fusion(f32[16,12,512]{2,1,0} %reduce.5, f16[16,12,512,512]{2,3,1,0} %fusion.334, f32[16,12,512]{2,1,0} %reduce.4, f16[16,12,512,512]{3,2,1,0} %custom-call.30, f16[16,12,512,512]{3,2,1,0} %arg2.3), kind=kLoop, calls=%fused_computation.264, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/softmax/mul_1"}
  %custom-call.33 = f16[16,12,512,64]{3,2,1,0} custom-call(f16[16,12,512,512]{3,2,1,0} %fusion.264, f16[16,12,512,64]{3,2,1,0} %fusion.337), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum/Einsum_1"}, backend_config="{\"alpha_real\":0.125,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.260 = f16[8192,768]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.33), kind=kLoop, calls=%fused_computation.260
  %fusion.259 = f16[768,768]{0,1} fusion(f32[768,12,64]{2,1,0} %arg52.53), kind=kLoop, calls=%fused_computation.259
  %custom-call.34 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.260, f16[768,768]{0,1} %fusion.259), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.263 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.10, f32[12,64]{1,0} %arg51.52), kind=kLoop, calls=%fused_computation.263
  %custom-call.31 = f16[16,12,512,64]{3,2,1,0} custom-call(f16[16,12,512,512]{3,2,1,0} %fusion.264, f16[16,12,512,64]{3,2,1,0} %fusion.263), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/self_attention/einsum/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.262 = f16[8192,768]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.31), kind=kLoop, calls=%fused_computation.262
  %fusion.261 = f16[768,768]{0,1} fusion(f32[768,12,64]{2,1,0} %arg50.51), kind=kLoop, calls=%fused_computation.261
  %custom-call.32 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.262, f16[768,768]{0,1} %fusion.261), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.251 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) fusion(f32[768]{0} %arg30.31, f32[16,512]{1,0} %get-tuple-element.275, f32[16,512]{1,0} %fusion.391, f32[16,512]{1,0} %get-tuple-element.279, f32[768]{0} %arg39.40, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f16[16,512,768]{2,1,0} %get-tuple-element.280, f16[8192,768]{1,0} %custom-call.8, f32[768]{0} %arg27.28, f16[16,512,768]{2,1,0} %arg6.7, f16[8192,768]{1,0} %custom-call.36, f16[8192,768]{1,0} %custom-call.34, f16[8192,768]{1,0} %custom-call.32, f32[16,512]{1,0} %get-tuple-element.245, f32[16,512]{1,0} %get-tuple-element.273, f16[16,512,768]{2,1,0} %get-tuple-element.274, f32[16,512]{1,0} %get-tuple-element.246, f32[16,512,768]{2,1,0} %get-tuple-element.247, f32[768]{0} %arg56.57, f32[16,512]{1,0} %fusion.324), kind=kInput, calls=%fused_computation.251, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/mul_2/Sum"}
  %get-tuple-element.238 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.251), index=0
  %get-tuple-element.276 = f32[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.341), index=1
  %get-tuple-element.239 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.251), index=1
  %get-tuple-element.242 = f16[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.251), index=2
  %fusion.249 = f16[16,512,768]{2,1,0} fusion(f16[16,512,768]{2,1,0} %arg6.7, f32[16,512]{1,0} %get-tuple-element.238, f32[16,512,768]{2,1,0} %get-tuple-element.276, f32[16,512]{1,0} %get-tuple-element.239, f32[768]{0} %arg30.31, f32[16,512]{1,0} %get-tuple-element.275, f16[16,512,768]{2,1,0} %get-tuple-element.242), kind=kLoop, calls=%fused_computation.249, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout_2/dropout/Mul_1"}
  %bitcast.94 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %fusion.249)
  %custom-call.37 = f16[8192,3072]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.94, f16[3072,768]{1,0} %convert.263), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %fusion.248 = f16[16,512,3072]{2,1,0} fusion(f16[16,512,3072]{2,1,0} %fusion.345, f16[8192,3072]{1,0} %custom-call.37, f16[16,512,3072]{2,1,0} %arg1.2, f16[8192,3072]{1,0} %custom-call.7, f32[3072]{0} %arg25.26), kind=kLoop, calls=%fused_computation.248, metadata={op_type="AddN" op_name="AddN_13"}
  %bitcast.96 = f16[8192,3072]{1,0} bitcast(f16[16,512,3072]{2,1,0} %fusion.248)
  %custom-call.38 = f16[8192,768]{1,0} custom-call(f16[8192,3072]{1,0} %bitcast.96, f16[768,3072]{1,0} %convert.261), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"103\"}"
  %fusion.244 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) fusion(f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f32[16,512]{1,0} %get-tuple-element.279, f16[16,512,768]{2,1,0} %get-tuple-element.280, f16[8192,768]{1,0} %custom-call.38, f32[16,512]{1,0} %get-tuple-element.238, f32[16,512,768]{2,1,0} %get-tuple-element.276, f32[16,512]{1,0} %get-tuple-element.239, f32[768]{0} %arg30.31, f32[16,512]{1,0} %get-tuple-element.275, f16[16,512,768]{2,1,0} %get-tuple-element.242), kind=kInput, calls=%fused_computation.244, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention_layer_norm/batchnorm/mul_2/Sum"}
  %get-tuple-element.235 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.244), index=0
  %get-tuple-element.236 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.244), index=1
  %get-tuple-element.237 = f32[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f32[16,512,768]{2,1,0}) %fusion.244), index=2
  %fusion.242 = f16[16,512,768]{2,1,0} fusion(f16[16,512,768]{2,1,0} %arg7.8, f32[16,512]{1,0} %get-tuple-element.235, f32[16,512]{1,0} %get-tuple-element.279, f16[16,512,768]{2,1,0} %get-tuple-element.280, f32[16,512]{1,0} %get-tuple-element.236, f32[16,512,768]{2,1,0} %get-tuple-element.237, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350), kind=kLoop, calls=%fused_computation.242, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/dropout/dropout/Mul_1"}
  %bitcast.101 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %fusion.242)
  %fusion.241 = f16[768,768]{0,1} fusion(f32[12,64,768]{2,1,0} %arg32.33), kind=kLoop, calls=%fused_computation.241
  %custom-call.39 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %bitcast.101, f16[768,768]{0,1} %fusion.241), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.231 = f16[16,12,64,512]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.39), kind=kLoop, calls=%fused_computation.231
  %custom-call.45 = f16[16,12,64,512]{3,2,1,0} custom-call(f16[16,12,64,512]{3,2,1,0} %fusion.231, f16[16,12,512,512]{3,2,1,0} %fusion.357), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.230 = f16[8192,768]{1,0} fusion(f16[16,12,64,512]{3,2,1,0} %custom-call.45), kind=kLoop, calls=%fused_computation.230
  %fusion.229 = f16[768,768]{0,1} fusion(f32[768,12,64]{2,1,0} %arg38.39), kind=kLoop, calls=%fused_computation.229
  %custom-call.46 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.230, f16[768,768]{0,1} %fusion.229), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.377 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.39), kind=kLoop, calls=%fused_computation.377
  %fusion.240 = f16[16,12,64,512]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.4, f32[12,64]{1,0} %arg37.38), kind=kLoop, calls=%fused_computation.240
  %custom-call.40 = f16[16,12,512,512]{3,2,1,0} custom-call(f16[16,12,512,64]{3,2,1,0} %fusion.377, f16[16,12,64,512]{3,2,1,0} %fusion.240), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum_1/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.238 = f32[16,12,512,512]{3,2,1,0} fusion(f16[16,12,512,512]{2,3,1,0} %fusion.360, f32[16,12,512]{2,1,0} %reduce.2, f16[16,12,512,512]{3,2,1,0} %custom-call.40, f16[16,12,512,512]{3,2,1,0} %arg3.4), kind=kLoop, calls=%fused_computation.238, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Sum"}
  %reduce.6 = f32[16,12,512]{2,1,0} reduce(f32[16,12,512,512]{3,2,1,0} %fusion.238, f32[] %constant_193), dimensions={2}, to_apply=%gradient_tape_model_bert_pretrainer_bert_encoder_1_transformer_layer_0_self_attention_softmax_Sum-reduction.1612, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/Sum"}
  %fusion.237 = f16[16,12,512,512]{3,2,1,0} fusion(f32[16,12,512]{2,1,0} %reduce.6, f16[16,12,512,512]{2,3,1,0} %fusion.360, f32[16,12,512]{2,1,0} %reduce.2, f16[16,12,512,512]{3,2,1,0} %custom-call.40, f16[16,12,512,512]{3,2,1,0} %arg3.4), kind=kLoop, calls=%fused_computation.237, metadata={op_type="Mul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/softmax/mul_1"}
  %custom-call.43 = f16[16,12,512,64]{3,2,1,0} custom-call(f16[16,12,512,512]{3,2,1,0} %fusion.237, f16[16,12,512,64]{3,2,1,0} %fusion.364), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum/Einsum_1"}, backend_config="{\"alpha_real\":0.125,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"3\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.233 = f16[8192,768]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.43), kind=kLoop, calls=%fused_computation.233
  %fusion.232 = f16[768,768]{0,1} fusion(f32[768,12,64]{2,1,0} %arg36.37), kind=kLoop, calls=%fused_computation.232
  %custom-call.44 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.233, f16[768,768]{0,1} %fusion.232), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.236 = f16[16,12,512,64]{3,2,1,0} fusion(f16[8192,768]{1,0} %custom-call.2, f32[12,64]{1,0} %arg35.36), kind=kLoop, calls=%fused_computation.236
  %custom-call.41 = f16[16,12,512,64]{3,2,1,0} custom-call(f16[16,12,512,512]{3,2,1,0} %fusion.237, f16[16,12,512,64]{3,2,1,0} %fusion.236), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/einsum/Einsum"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"2\"],\"rhs_contracting_dimensions\":[\"2\"],\"lhs_batch_dimensions\":[\"0\",\"1\"],\"rhs_batch_dimensions\":[\"0\",\"1\"]},\"batch_size\":\"192\"}"
  %fusion.235 = f16[8192,768]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.41), kind=kLoop, calls=%fused_computation.235
  %fusion.234 = f16[768,768]{0,1} fusion(f32[768,12,64]{2,1,0} %arg34.35), kind=kLoop, calls=%fused_computation.234
  %custom-call.42 = f16[8192,768]{1,0} custom-call(f16[8192,768]{1,0} %fusion.235, f16[768,768]{0,1} %fusion.234), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"104\"}"
  %fusion.207 = (f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) fusion(f32[768]{0} %arg21.22, f32[16,512]{1,0} %fusion.368, f32[16,512]{1,0} %get-tuple-element.281, f16[16,512,768]{2,1,0} %get-tuple-element.282, f16[8192,768]{1,0} %custom-call.46, f16[8192,768]{1,0} %custom-call.44, f16[8192,768]{1,0} %custom-call.42, f32[16,512]{1,0} %get-tuple-element.235, f32[16,512]{1,0} %get-tuple-element.279, f16[16,512,768]{2,1,0} %get-tuple-element.280, f32[16,512]{1,0} %get-tuple-element.236, f32[16,512,768]{2,1,0} %get-tuple-element.237, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f16[16,512,768]{2,1,0} %arg8.9), kind=kInput, calls=%fused_computation.207, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/mul_2/Sum"}
  %get-tuple-element.232 = f16[16,512,768]{2,1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.207), index=2
  %fusion.227 = (f32[768]{0}, f32[768]{0}) fusion(f16[16,512,768]{2,1,0} %get-tuple-element.232, f32[16,512]{1,0} %fusion.368, f32[16,512]{1,0} %get-tuple-element.281, f16[16,512,768]{2,1,0} %get-tuple-element.282), kind=kInput, calls=%fused_computation.227, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/embeddings/layer_norm/batchnorm/sub/Sum"}
  %get-tuple-element.229 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}) %fusion.227), index=1
  %arg156.157 = f32[768]{0} parameter(156), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg153.154 = f32[768]{0} parameter(153), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.228 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}) %fusion.227), index=0
  %arg154.155 = f32[768]{0} parameter(154), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.217 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) fusion(f32[768]{0} %arg21.22, f32[] %fusion.225, f32[768]{0} %arg155.156, f32[] %arg17.18, f32[768]{0} %get-tuple-element.229, f32[768]{0} %arg156.157, f32[] %arg18.19, f32[768]{0} %arg153.154, f32[768]{0} %get-tuple-element.228, f32[768]{0} %arg154.155), kind=kLoop, calls=%fused_computation.217, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_3/update_0/ResourceApplyAdam"}
  %get-tuple-element.227 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.217), index=4
  %get-tuple-element.226 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.217), index=3
  %fusion.15 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) fusion(f32[768]{0} %arg64.65, f32[] %fusion.225, f32[768]{0} %arg87.88, f32[] %arg17.18, f32[768]{0} %get-tuple-element.252, f32[768]{0} %arg88.89, f32[] %arg18.19, f32[768]{0} %arg63.64, f32[768]{0} %arg84.85, f32[768]{0} %get-tuple-element.255, f32[768]{0} %arg83.84, f32[768]{0} %arg62.63, f32[768]{0} %arg82.83, f32[768]{0} %get-tuple-element.254, f32[768]{0} %arg81.82, f32[768]{0} %arg56.57, f32[768]{0} %arg104.105, f32[768]{0} %get-tuple-element.286, f32[768]{0} %arg103.104, f32[768]{0} %arg55.56, f32[768]{0} %arg102.103, f32[768]{0} %get-tuple-element.287, f32[768]{0} %arg101.102, f32[768]{0} %arg47.48, f32[768]{0} %arg108.109, f32[768]{0} %get-tuple-element.283, f32[768]{0} %arg107.108, f32[768]{0} %arg46.47, f32[768]{0} %arg92.93, f32[768]{0} %get-tuple-element.285, f32[768]{0} %arg91.92, f32[768]{0} %arg45.46, f32[768]{0} %arg90.91, f32[768]{0} %get-tuple-element.284, f32[768]{0} %arg89.90, f32[768]{0} %arg20.21, f32[768]{0} %get-tuple-element.227, f32[768]{0} %get-tuple-element.226), kind=kLoop, calls=%fused_computation.15, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_43/update_0/ResourceApplyAdam"}
  %get-tuple-element.204 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=24
  %get-tuple-element.135 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.217), index=0
  %arg95.96 = f32[768]{0} parameter(95), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.191 = (f32[768]{0}, f32[768]{0}, f32[768]{0}) fusion(f16[16,512,768]{2,1,0} %fusion.249, f16[16,512,768]{2,1,0} %fusion.242, f16[16,512,768]{2,1,0} %fusion.276), kind=kInput, calls=%fused_computation.191, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/add/Sum"}
  %get-tuple-element.290 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.191), index=2
  %arg96.97 = f32[768]{0} parameter(96), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg136.137 = f32[768]{0} parameter(136), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.181 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) fusion(f16[16,512,768]{2,1,0} %get-tuple-element.242, f32[16,512]{1,0} %get-tuple-element.275, f32[16,512]{1,0} %fusion.391, f32[16,512]{1,0} %get-tuple-element.279, f32[768]{0} %arg39.40, f32[768]{0} %arg40.41, f32[16,512]{1,0} %fusion.350, f16[16,512,768]{2,1,0} %get-tuple-element.280, f16[8192,768]{1,0} %custom-call.8, f32[768]{0} %arg27.28, f16[16,512,768]{2,1,0} %arg6.7, f32[16,512,768]{2,1,0} %get-tuple-element.237), kind=kInput, calls=%fused_computation.181, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output_layer_norm/batchnorm/sub/Sum"}
  %get-tuple-element.277 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.181), index=2
  %arg135.136 = f32[768]{0} parameter(135), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg134.135 = f32[768]{0} parameter(134), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.278 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.181), index=3
  %arg133.134 = f32[768]{0} parameter(133), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg140.141 = f32[768]{0} parameter(140), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.289 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.191), index=1
  %arg139.140 = f32[768]{0} parameter(139), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg124.125 = f32[768]{0} parameter(124), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.241 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.181), index=1
  %arg123.124 = f32[768]{0} parameter(123), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg122.123 = f32[768]{0} parameter(122), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.240 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.181), index=0
  %arg121.122 = f32[768]{0} parameter(121), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg128.129 = f32[768]{0} parameter(128), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.288 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.191), index=0
  %arg127.128 = f32[768]{0} parameter(127), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg73.74 = f32[768]{0} parameter(73), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg72.73 = f32[768]{0} parameter(72), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.111 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) fusion(f32[768]{0} %arg43.44, f32[] %fusion.225, f32[768]{0} %arg95.96, f32[] %arg17.18, f32[768]{0} %get-tuple-element.290, f32[768]{0} %arg96.97, f32[] %arg18.19, f32[768]{0} %arg40.41, f32[768]{0} %arg136.137, f32[768]{0} %get-tuple-element.277, f32[768]{0} %arg135.136, f32[768]{0} %arg39.40, f32[768]{0} %arg134.135, f32[768]{0} %get-tuple-element.278, f32[768]{0} %arg133.134, f32[768]{0} %arg31.32, f32[768]{0} %arg140.141, f32[768]{0} %get-tuple-element.289, f32[768]{0} %arg139.140, f32[768]{0} %arg30.31, f32[768]{0} %arg124.125, f32[768]{0} %get-tuple-element.241, f32[768]{0} %arg123.124, f32[768]{0} %arg29.30, f32[768]{0} %arg122.123, f32[768]{0} %get-tuple-element.240, f32[768]{0} %arg121.122, f32[768]{0} %arg27.28, f32[768]{0} %arg128.129, f32[768]{0} %get-tuple-element.288, f32[768]{0} %arg127.128, f32[768]{0} %arg22.23, f32[768]{0} %arg73.74, f32[768]{0} %arg72.73, f16[16,768]{1,0} %fusion.282), kind=kLoop, calls=%fused_computation.111, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_34/update_0/ResourceApplyAdam"}
  %get-tuple-element.223 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=21
  %arg74.75 = f32[768,768]{1,0} parameter(74), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.47 = f16[768,768]{1,0} custom-call(f16[16,768]{1,0} %fusion.290, f16[16,768]{1,0} %fusion.282), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/pooler_transform/MatMul_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"114\"}"
  %arg75.76 = f32[768,768]{1,0} parameter(75), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg86.87 = f32[768,768]{1,0} parameter(86), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.63 = f16[768,768]{1,0} custom-call(f16[1216,768]{1,0} %fusion.312, f16[1216,768]{1,0} %get-tuple-element.253), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/transform/dense/MatMul_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"115\"}"
  %arg85.86 = f32[768,768]{1,0} parameter(85), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.209 = (f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) fusion(f32[768,768]{1,0} %arg23.24, f32[] %fusion.225, f32[768,768]{1,0} %arg74.75, f32[] %arg17.18, f16[768,768]{1,0} %custom-call.47, f32[768,768]{1,0} %arg75.76, f32[] %arg18.19, f32[768,768]{1,0} %arg65.66, f32[768,768]{1,0} %arg86.87, f16[768,768]{1,0} %custom-call.63, f32[768,768]{1,0} %arg85.86), kind=kLoop, calls=%fused_computation.209, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_37/update_0/ResourceApplyAdam"}
  %get-tuple-element.129 = f32[768,768]{1,0} get-tuple-element((f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) %fusion.209), index=0
  %arg159.160 = f32[512,768]{1,0} parameter(159), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg160.161 = f32[512,768]{1,0} parameter(160), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.230 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.207), index=0
  %get-tuple-element.231 = f32[16,512]{1,0} get-tuple-element((f32[16,512]{1,0}, f32[16,512]{1,0}, f16[16,512,768]{2,1,0}) %fusion.207), index=1
  %fusion.206 = f16[16,512,768]{2,1,0} fusion(f32[16,512]{1,0} %get-tuple-element.230, f32[16,512]{1,0} %get-tuple-element.231, f16[16,512,768]{2,1,0} %get-tuple-element.232, f32[768]{0} %arg21.22, f32[16,512]{1,0} %get-tuple-element.281, f16[16,512,768]{2,1,0} %get-tuple-element.282, f32[16,512]{1,0} %fusion.368), kind=kLoop, calls=%fused_computation.206, metadata={op_type="Cast" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/Cast/Cast"}
  %fusion.202 = (f32[512,768]{1,0}, f32[512,768]{1,0}, f32[512,768]{1,0}) fusion(f32[512,768]{1,0} %arg24.25, f32[] %fusion.225, f32[512,768]{1,0} %arg159.160, f32[] %arg17.18, f32[512,768]{1,0} %arg160.161, f32[] %arg18.19, f16[16,512,768]{2,1,0} %fusion.206), kind=kLoop, calls=%fused_computation.202, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_1/update_0/ResourceApplyAdam"}
  %get-tuple-element.126 = f32[512,768]{1,0} get-tuple-element((f32[512,768]{1,0}, f32[512,768]{1,0}, f32[512,768]{1,0}) %fusion.202), index=0
  %arg131.132 = f32[3072]{0} parameter(131), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.201 = (f32[3072]{0}, f32[3072]{0}) fusion(f16[16,512,3072]{2,1,0} %fusion.248, f16[16,512,3072]{2,1,0} %fusion.275), kind=kInput, calls=%fused_computation.201, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/add/Sum"}
  %get-tuple-element.291 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}) %fusion.201), index=0
  %arg132.133 = f32[3072]{0} parameter(132), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg100.101 = f32[3072]{0} parameter(100), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.292 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}) %fusion.201), index=1
  %arg99.100 = f32[3072]{0} parameter(99), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.197 = (f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) fusion(f32[3072]{0} %arg25.26, f32[] %fusion.225, f32[3072]{0} %arg131.132, f32[] %arg17.18, f32[3072]{0} %get-tuple-element.291, f32[3072]{0} %arg132.133, f32[] %arg18.19, f32[3072]{0} %arg41.42, f32[3072]{0} %arg100.101, f32[3072]{0} %get-tuple-element.292, f32[3072]{0} %arg99.100), kind=kLoop, calls=%fused_computation.197, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_16/update_0/ResourceApplyAdam"}
  %get-tuple-element.123 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) %fusion.197), index=0
  %arg129.130 = f32[768,3072]{1,0} parameter(129), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.196 = f16[3072,8192]{0,1} fusion(f16[16,512,3072]{2,1,0} %fusion.248), kind=kLoop, calls=%fused_computation.196
  %custom-call.48 = f16[768,3072]{1,0} custom-call(f16[8192,768]{1,0} %fusion.347, f16[3072,8192]{0,1} %fusion.196), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/intermediate/einsum/Einsum_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"110\"}"
  %arg130.131 = f32[768,3072]{1,0} parameter(130), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg98.99 = f32[768,3072]{1,0} parameter(98), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.120 = f16[3072,8192]{0,1} fusion(f16[16,512,3072]{2,1,0} %fusion.275), kind=kLoop, calls=%fused_computation.120
  %custom-call.54 = f16[768,3072]{1,0} custom-call(f16[8192,768]{1,0} %fusion.321, f16[3072,8192]{0,1} %fusion.120), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/intermediate/einsum/Einsum_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"110\"}"
  %arg97.98 = f32[768,3072]{1,0} parameter(97), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.192 = (f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) fusion(f32[768,3072]{1,0} %arg26.27, f32[] %fusion.225, f32[768,3072]{1,0} %arg129.130, f32[] %arg17.18, f16[768,3072]{1,0} %custom-call.48, f32[768,3072]{1,0} %arg130.131, f32[] %arg18.19, f32[768,3072]{1,0} %arg42.43, f32[768,3072]{1,0} %arg98.99, f16[768,3072]{1,0} %custom-call.54, f32[768,3072]{1,0} %arg97.98), kind=kLoop, calls=%fused_computation.192, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_15/update_0/ResourceApplyAdam"}
  %get-tuple-element.120 = f32[768,3072]{1,0} get-tuple-element((f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) %fusion.192), index=0
  %get-tuple-element.220 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=18
  %arg125.126 = f32[3072,768]{1,0} parameter(125), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.186 = f16[768,8192]{0,1} fusion(f16[16,512,768]{2,1,0} %fusion.249), kind=kLoop, calls=%fused_computation.186
  %custom-call.49 = f16[3072,768]{1,0} custom-call(f16[8192,3072]{1,0} %fusion.344, f16[768,8192]{0,1} %fusion.186), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/output/einsum/Einsum_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"110\"}"
  %arg126.127 = f32[3072,768]{1,0} parameter(126), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg94.95 = f32[3072,768]{1,0} parameter(94), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.110 = f16[768,8192]{0,1} fusion(f16[16,512,768]{2,1,0} %fusion.276), kind=kLoop, calls=%fused_computation.110
  %custom-call.55 = f16[3072,768]{1,0} custom-call(f16[8192,3072]{1,0} %fusion.318, f16[768,8192]{0,1} %fusion.110), custom_call_target="__cublas$gemm", metadata={op_type="Einsum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_1/output/einsum/Einsum_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"1\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"110\"}"
  %arg93.94 = f32[3072,768]{1,0} parameter(93), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.182 = (f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) fusion(f32[3072,768]{1,0} %arg28.29, f32[] %fusion.225, f32[3072,768]{1,0} %arg125.126, f32[] %arg17.18, f16[3072,768]{1,0} %custom-call.49, f32[3072,768]{1,0} %arg126.127, f32[] %arg18.19, f32[3072,768]{1,0} %arg44.45, f32[3072,768]{1,0} %arg94.95, f16[3072,768]{1,0} %custom-call.55, f32[3072,768]{1,0} %arg93.94), kind=kLoop, calls=%fused_computation.182, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_17/update_0/ResourceApplyAdam"}
  %get-tuple-element.114 = f32[3072,768]{1,0} get-tuple-element((f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) %fusion.182), index=0
  %get-tuple-element.217 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=15
  %get-tuple-element.214 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=12
  %get-tuple-element.211 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=9
  %arg137.138 = f32[12,64,768]{2,1,0} parameter(137), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.168 = f16[768,8192]{0,1} fusion(f16[16,512,768]{2,1,0} %fusion.242), kind=kLoop, calls=%fused_computation.168
  %custom-call.50 = f16[768,768]{1,0} custom-call(f16[768,8192]{0,1} %fusion.168, f16[8192,768]{1,0} %fusion.355), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"112\"}"
  %arg138.139 = f32[12,64,768]{2,1,0} parameter(138), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg106.107 = f32[12,64,768]{2,1,0} parameter(106), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.92 = f16[768,8192]{0,1} fusion(f16[16,512,768]{2,1,0} %fusion.269), kind=kLoop, calls=%fused_computation.92
  %custom-call.56 = f16[768,768]{1,0} custom-call(f16[768,8192]{0,1} %fusion.92, f16[8192,768]{1,0} %fusion.329), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"112\"}"
  %arg105.106 = f32[12,64,768]{2,1,0} parameter(105), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.164 = (f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) fusion(f32[12,64,768]{2,1,0} %arg32.33, f32[] %fusion.225, f32[12,64,768]{2,1,0} %arg137.138, f32[] %arg17.18, f16[768,768]{1,0} %custom-call.50, f32[12,64,768]{2,1,0} %arg138.139, f32[] %arg18.19, f32[12,64,768]{2,1,0} %arg48.49, f32[12,64,768]{2,1,0} %arg106.107, f16[768,768]{1,0} %custom-call.56, f32[12,64,768]{2,1,0} %arg105.106), kind=kLoop, calls=%fused_computation.164, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_11/update_0/ResourceApplyAdam"}
  %get-tuple-element.102 = f32[12,64,768]{2,1,0} get-tuple-element((f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) %fusion.164), index=0
  %arg147.148 = f32[12,64]{1,0} parameter(147), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg148.149 = f32[12,64]{1,0} parameter(148), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.400 = (f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}) fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.41, f16[16,12,512,64]{3,2,1,0} %custom-call.33, f16[16,12,512,64]{3,2,1,0} %custom-call.31, f16[16,12,512,64]{3,2,1,0} %custom-call.43), kind=kInput, calls=%fused_computation.400, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/key/add/Sum"}
  %get-tuple-element.295 = f32[16,12,64]{2,1,0} get-tuple-element((f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}) %fusion.400), index=0
  %arg112.113 = f32[12,64]{1,0} parameter(112), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.402 = (f32[12,64]{1,0}, f32[12,64]{1,0}) fusion(f16[16,12,64,512]{3,2,1,0} %custom-call.45, f16[16,12,64,512]{3,2,1,0} %custom-call.35), kind=kInput, calls=%fused_computation.402, metadata={op_type="Sum" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/transformer/layer_0/self_attention/value/add/Sum"}
  %get-tuple-element.294 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.402), index=1
  %arg111.112 = f32[12,64]{1,0} parameter(111), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg120.121 = f32[12,64]{1,0} parameter(120), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg119.120 = f32[12,64]{1,0} parameter(119), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.296 = f32[16,12,64]{2,1,0} get-tuple-element((f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}) %fusion.400), index=1
  %arg116.117 = f32[12,64]{1,0} parameter(116), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg115.116 = f32[12,64]{1,0} parameter(115), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.297 = f32[16,12,64]{2,1,0} get-tuple-element((f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}) %fusion.400), index=2
  %arg142.143 = f32[12,64]{1,0} parameter(142), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.293 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.402), index=0
  %arg141.142 = f32[12,64]{1,0} parameter(141), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg152.153 = f32[12,64]{1,0} parameter(152), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg151.152 = f32[12,64]{1,0} parameter(151), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.298 = f32[16,12,64]{2,1,0} get-tuple-element((f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}, f32[16,12,64]{2,1,0}) %fusion.400), index=3
  %fusion.159 = (f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) fusion(f32[12,64]{1,0} %arg33.34, f32[] %fusion.225, f32[12,64]{1,0} %arg147.148, f32[] %arg17.18, f32[12,64]{1,0} %arg148.149, f32[] %arg18.19, f32[16,12,64]{2,1,0} %get-tuple-element.295, f32[12,64]{1,0} %arg53.54, f32[12,64]{1,0} %arg112.113, f32[12,64]{1,0} %get-tuple-element.294, f32[12,64]{1,0} %arg111.112, f32[12,64]{1,0} %arg51.52, f32[12,64]{1,0} %arg120.121, f32[12,64]{1,0} %arg119.120, f32[16,12,64]{2,1,0} %get-tuple-element.296, f32[12,64]{1,0} %arg49.50, f32[12,64]{1,0} %arg116.117, f32[12,64]{1,0} %arg115.116, f32[16,12,64]{2,1,0} %get-tuple-element.297, f32[12,64]{1,0} %arg37.38, f32[12,64]{1,0} %arg142.143, f32[12,64]{1,0} %get-tuple-element.293, f32[12,64]{1,0} %arg141.142, f32[12,64]{1,0} %arg35.36, f32[12,64]{1,0} %arg152.153, f32[12,64]{1,0} %arg151.152, f32[16,12,64]{2,1,0} %get-tuple-element.298), kind=kLoop, calls=%fused_computation.159, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_8/update_0/ResourceApplyAdam"}
  %get-tuple-element.99 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=0
  %arg145.146 = f32[768,12,64]{2,1,0} parameter(145), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.158 = f16[768,8192]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.41), kind=kLoop, calls=%fused_computation.158
  %custom-call.51 = f16[768,768]{1,0} custom-call(f16[768,8192]{1,0} %fusion.158, f16[8192,768]{1,0} %bitcast.37), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"113\"}"
  %arg146.147 = f32[768,12,64]{2,1,0} parameter(146), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg110.111 = f32[768,12,64]{2,1,0} parameter(110), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.62 = f16[768,8192]{1,0} fusion(f16[16,12,64,512]{3,2,1,0} %custom-call.35), kind=kLoop, calls=%fused_computation.62
  %custom-call.59 = f16[768,768]{1,0} custom-call(f16[768,8192]{1,0} %fusion.62, f16[8192,768]{1,0} %bitcast.48), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"113\"}"
  %arg109.110 = f32[768,12,64]{2,1,0} parameter(109), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg118.119 = f32[768,12,64]{2,1,0} parameter(118), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.72 = f16[768,8192]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.33), kind=kLoop, calls=%fused_computation.72
  %custom-call.58 = f16[768,768]{1,0} custom-call(f16[768,8192]{1,0} %fusion.72, f16[8192,768]{1,0} %bitcast.48), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"113\"}"
  %arg117.118 = f32[768,12,64]{2,1,0} parameter(117), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg114.115 = f32[768,12,64]{2,1,0} parameter(114), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.82 = f16[768,8192]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.31), kind=kLoop, calls=%fused_computation.82
  %custom-call.57 = f16[768,768]{1,0} custom-call(f16[768,8192]{1,0} %fusion.82, f16[8192,768]{1,0} %bitcast.48), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"113\"}"
  %arg113.114 = f32[768,12,64]{2,1,0} parameter(113), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg144.145 = f32[768,12,64]{2,1,0} parameter(144), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.138 = f16[768,8192]{1,0} fusion(f16[16,12,64,512]{3,2,1,0} %custom-call.45), kind=kLoop, calls=%fused_computation.138
  %custom-call.53 = f16[768,768]{1,0} custom-call(f16[768,8192]{1,0} %fusion.138, f16[8192,768]{1,0} %bitcast.37), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"113\"}"
  %arg143.144 = f32[768,12,64]{2,1,0} parameter(143), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg150.151 = f32[768,12,64]{2,1,0} parameter(150), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.148 = f16[768,8192]{1,0} fusion(f16[16,12,512,64]{3,2,1,0} %custom-call.43), kind=kLoop, calls=%fused_computation.148
  %custom-call.52 = f16[768,768]{1,0} custom-call(f16[768,8192]{1,0} %fusion.148, f16[8192,768]{1,0} %bitcast.37), custom_call_target="__cublas$gemm", backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"1\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"113\"}"
  %arg149.150 = f32[768,12,64]{2,1,0} parameter(149), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.154 = (f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) fusion(f32[768,12,64]{2,1,0} %arg34.35, f32[] %fusion.225, f32[768,12,64]{2,1,0} %arg145.146, f32[] %arg17.18, f16[768,768]{1,0} %custom-call.51, f32[768,12,64]{2,1,0} %arg146.147, f32[] %arg18.19, f32[768,12,64]{2,1,0} %arg54.55, f32[768,12,64]{2,1,0} %arg110.111, f16[768,768]{1,0} %custom-call.59, f32[768,12,64]{2,1,0} %arg109.110, f32[768,12,64]{2,1,0} %arg52.53, f32[768,12,64]{2,1,0} %arg118.119, f16[768,768]{1,0} %custom-call.58, f32[768,12,64]{2,1,0} %arg117.118, f32[768,12,64]{2,1,0} %arg50.51, f32[768,12,64]{2,1,0} %arg114.115, f16[768,768]{1,0} %custom-call.57, f32[768,12,64]{2,1,0} %arg113.114, f32[768,12,64]{2,1,0} %arg38.39, f32[768,12,64]{2,1,0} %arg144.145, f16[768,768]{1,0} %custom-call.53, f32[768,12,64]{2,1,0} %arg143.144, f32[768,12,64]{2,1,0} %arg36.37, f32[768,12,64]{2,1,0} %arg150.151, f16[768,768]{1,0} %custom-call.52, f32[768,12,64]{2,1,0} %arg149.150), kind=kLoop, calls=%fused_computation.154, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_7/update_0/ResourceApplyAdam"}
  %get-tuple-element.96 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=0
  %get-tuple-element.165 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=15
  %get-tuple-element.180 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=15
  %get-tuple-element.162 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=12
  %get-tuple-element.177 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=12
  %get-tuple-element.208 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=6
  %get-tuple-element.205 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=3
  %get-tuple-element.141 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) %fusion.197), index=3
  %get-tuple-element.144 = f32[768,3072]{1,0} get-tuple-element((f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) %fusion.192), index=3
  %get-tuple-element.69 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=0
  %get-tuple-element.147 = f32[3072,768]{1,0} get-tuple-element((f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) %fusion.182), index=3
  %get-tuple-element.201 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=21
  %get-tuple-element.198 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=18
  %get-tuple-element.195 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=15
  %get-tuple-element.150 = f32[12,64,768]{2,1,0} get-tuple-element((f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) %fusion.164), index=3
  %get-tuple-element.159 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=9
  %get-tuple-element.174 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=9
  %get-tuple-element.156 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=6
  %get-tuple-element.171 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=6
  %get-tuple-element.153 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=3
  %get-tuple-element.168 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=3
  %get-tuple-element.192 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=12
  %get-tuple-element.189 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=9
  %arg157.158 = f32[2,768]{1,0} parameter(157), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %bitcast.136 = f16[8192,768]{1,0} bitcast(f16[16,512,768]{2,1,0} %fusion.206), metadata={op_type="Reshape" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/word_embeddings/Reshape"}
  %custom-call.60 = f16[8,768]{1,0} custom-call(f16[8192,8]{1,0} %fusion.374, f16[8192,768]{1,0} %bitcast.136), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/bert_encoder_1/type_embeddings/MatMul/MatMul"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"108\"}"
  %arg158.159 = f32[2,768]{1,0} parameter(158), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.46 = (f32[2,768]{1,0}, f32[2,768]{1,0}, f32[2,768]{1,0}) fusion(f32[2,768]{1,0} %arg57.58, f32[] %fusion.225, f32[2,768]{1,0} %arg157.158, f32[] %arg17.18, f16[8,768]{1,0} %custom-call.60, f32[2,768]{1,0} %arg158.159, f32[] %arg18.19), kind=kLoop, calls=%fused_computation.46, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_2/update_0/ResourceApplyAdam"}
  %get-tuple-element.27 = f32[2,768]{1,0} get-tuple-element((f32[2,768]{1,0}, f32[2,768]{1,0}, f32[2,768]{1,0}) %fusion.46), index=0
  %arg68.69 = f32[2]{0} parameter(68), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg69.70 = f32[2]{0} parameter(69), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.42 = (f32[2]{0}, f32[2]{0}, f32[2]{0}) fusion(f32[2]{0} %arg58.59, f32[] %fusion.225, f32[2]{0} %arg68.69, f32[] %arg17.18, f32[2]{0} %arg69.70, f32[] %arg18.19, f16[16,2]{1,0} %fusion.283), kind=kLoop, calls=%fused_computation.42, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_40/update_0/ResourceApplyAdam"}
  %get-tuple-element.24 = f32[2]{0} get-tuple-element((f32[2]{0}, f32[2]{0}, f32[2]{0}) %fusion.42), index=0
  %arg70.71 = f32[768,2]{1,0} parameter(70), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.61 = f16[768,8]{1,0} custom-call(f16[16,768]{1,0} %tanh.758, f16[16,8]{1,0} %pad.4), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/classification/predictions/transform/logits/MatMul_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"115\"}"
  %arg71.72 = f32[768,2]{1,0} parameter(71), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.38 = (f32[768,2]{1,0}, f32[768,2]{1,0}, f32[768,2]{1,0}) fusion(f32[768,2]{1,0} %arg59.60, f32[] %fusion.225, f32[768,2]{1,0} %arg70.71, f32[] %arg17.18, f16[768,8]{1,0} %custom-call.61, f32[768,2]{1,0} %arg71.72, f32[] %arg18.19), kind=kLoop, calls=%fused_computation.38, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_39/update_0/ResourceApplyAdam"}
  %get-tuple-element.21 = f32[768,2]{1,0} get-tuple-element((f32[768,2]{1,0}, f32[768,2]{1,0}, f32[768,2]{1,0}) %fusion.38), index=0
  %arg78.79 = f32[30522]{0} parameter(78), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.37 = f32[30522]{0} fusion(s32[16,76]{1,0} %arg10.11, f32[1216,30522]{1,0} %get-tuple-element.263, f32[1216]{0} %get-tuple-element.262, f32[16,76]{1,0} %arg12.13, f32[] %get-tuple-element.260), kind=kInput, calls=%fused_computation.37, metadata={op_type="BiasAddGrad" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/BiasAdd/BiasAddGrad"}
  %arg79.80 = f32[30522]{0} parameter(79), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.33 = (f32[30522]{0}, f32[30522]{0}, f32[30522]{0}) fusion(f32[30522]{0} %arg60.61, f32[] %fusion.225, f32[30522]{0} %arg78.79, f32[] %arg17.18, f32[30522]{0} %fusion.37, f32[30522]{0} %arg79.80, f32[] %arg18.19), kind=kLoop, calls=%fused_computation.33, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update_41/update_0/ResourceApplyAdam"}
  %get-tuple-element.18 = f32[30522]{0} get-tuple-element((f32[30522]{0}, f32[30522]{0}, f32[30522]{0}) %fusion.33), index=0
  %arg161.162 = f32[30522,768]{1,0} parameter(161), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %custom-call.62 = f16[30528,768]{1,0} custom-call(f16[1216,30528]{1,0} %fusion.399, f16[1216,768]{1,0} %fusion.302), custom_call_target="__cublas$gemm", metadata={op_type="MatMul" op_name="gradient_tape/model/bert_pretrainer/cls/predictions/MatMul/MatMul_1"}, backend_config="{\"alpha_real\":1,\"alpha_imag\":0,\"beta\":0,\"dot_dimension_numbers\":{\"lhs_contracting_dimensions\":[\"0\"],\"rhs_contracting_dimensions\":[\"0\"],\"lhs_batch_dimensions\":[],\"rhs_batch_dimensions\":[]},\"batch_size\":\"1\",\"selected_algorithm\":\"110\"}"
  %fusion.32 = f32[30522,768]{1,0} fusion(f16[30528,768]{1,0} %custom-call.62, f16[16,512,768]{2,1,0} %fusion.206, s32[16,512]{1,0} %arg14.15), kind=kInput, calls=%fused_computation.32, metadata={op_type="UnsortedSegmentSum" op_name="AddN_20/inputs_1"}
  %arg162.163 = f32[30522,768]{1,0} parameter(162), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.28 = (f32[30522,768]{1,0}, f32[30522,768]{1,0}, f32[30522,768]{1,0}) fusion(f32[30522,768]{1,0} %arg61.62, f32[] %fusion.225, f32[30522,768]{1,0} %arg161.162, f32[] %arg17.18, f32[30522,768]{1,0} %fusion.32, f32[30522,768]{1,0} %arg162.163, f32[] %arg18.19), kind=kLoop, calls=%fused_computation.28, metadata={op_type="ResourceApplyAdam" op_name="Adam/Adam/update/update_0/ResourceApplyAdam"}
  %get-tuple-element.15 = f32[30522,768]{1,0} get-tuple-element((f32[30522,768]{1,0}, f32[30522,768]{1,0}, f32[30522,768]{1,0}) %fusion.28), index=0
  %get-tuple-element.186 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=6
  %get-tuple-element.183 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=3
  %get-tuple-element.6 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=0
  %get-tuple-element.138 = f32[768,768]{1,0} get-tuple-element((f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) %fusion.209), index=3
  %arg80.81 = f32[] parameter(80), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.267 = f32[16]{0} get-tuple-element((f32[16]{0}, f32[16]{0}) %fusion.409), index=0
  %fusion.10 = f32[] fusion(f32[16]{0} %get-tuple-element.267, s32[16,1]{1,0} %arg13.14, f32[16]{0} %fusion.286, f32[2]{0} %arg58.59, f16[16,8]{1,0} %custom-call.24), kind=kInput, calls=%fused_computation.10, metadata={op_type="Mean" op_name="model/bert_pretrain_loss_and_metric_layer/Mean"}
  %get-tuple-element.261 = f32[] get-tuple-element((f32[], f32[], f32[]) %fusion.2), index=2
  %arg76.77 = f32[] parameter(76), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg66.67 = f32[] parameter(66), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %arg77.78 = f32[] parameter(77), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %get-tuple-element.259 = f32[] get-tuple-element((f32[], f32[], f32[]) %fusion.2), index=0
  %fusion = (f32[], f32[], f32[], f32[]) fusion(f32[] %arg80.81, f32[] %fusion.10, f32[] %get-tuple-element.261, f32[] %get-tuple-element.260, f32[] %arg76.77, f32[] %arg66.67, f32[] %arg77.78, f32[] %get-tuple-element.259), kind=kLoop, calls=%fused_computation, metadata={op_type="AssignAddVariableOp" op_name="AssignAddVariableOp"}
  %get-tuple-element.2 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion), index=2
  %arg67.68 = f32[] parameter(67), parameter_replication={false}, metadata={op_name="XLA_Args"}
  %fusion.9 = s64[16]{0} fusion(f32[16]{0} %fusion.286, f32[2]{0} %arg58.59, f16[16,8]{1,0} %custom-call.24), kind=kLoop, calls=%fused_computation.9, metadata={op_type="ArgMax" op_name="model/bert_pretrain_loss_and_metric_layer/ArgMax_1"}
  %fusion.8 = f32[] fusion(f32[] %arg67.68, s32[16,1]{1,0} %arg13.14, s64[16]{0} %fusion.9), kind=kLoop, calls=%fused_computation.8, metadata={op_type="AssignAddVariableOp" op_name="model/bert_pretrain_loss_and_metric_layer/AssignAddVariableOp_4"}
  %get-tuple-element.25 = f32[2]{0} get-tuple-element((f32[2]{0}, f32[2]{0}, f32[2]{0}) %fusion.42), index=1
  %get-tuple-element.26 = f32[2]{0} get-tuple-element((f32[2]{0}, f32[2]{0}, f32[2]{0}) %fusion.42), index=2
  %get-tuple-element.22 = f32[768,2]{1,0} get-tuple-element((f32[768,2]{1,0}, f32[768,2]{1,0}, f32[768,2]{1,0}) %fusion.38), index=1
  %get-tuple-element.23 = f32[768,2]{1,0} get-tuple-element((f32[768,2]{1,0}, f32[768,2]{1,0}, f32[768,2]{1,0}) %fusion.38), index=2
  %get-tuple-element.224 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=22
  %get-tuple-element.225 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=23
  %get-tuple-element.130 = f32[768,768]{1,0} get-tuple-element((f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) %fusion.209), index=1
  %get-tuple-element.131 = f32[768,768]{1,0} get-tuple-element((f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) %fusion.209), index=2
  %get-tuple-element.1 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion), index=1
  %get-tuple-element.258 = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion), index=3
  %get-tuple-element.19 = f32[30522]{0} get-tuple-element((f32[30522]{0}, f32[30522]{0}, f32[30522]{0}) %fusion.33), index=1
  %get-tuple-element.20 = f32[30522]{0} get-tuple-element((f32[30522]{0}, f32[30522]{0}, f32[30522]{0}) %fusion.33), index=2
  %get-tuple-element = f32[] get-tuple-element((f32[], f32[], f32[], f32[]) %fusion), index=0
  %get-tuple-element.187 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=7
  %get-tuple-element.188 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=8
  %get-tuple-element.184 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=4
  %get-tuple-element.185 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=5
  %get-tuple-element.139 = f32[768,768]{1,0} get-tuple-element((f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) %fusion.209), index=4
  %get-tuple-element.140 = f32[768,768]{1,0} get-tuple-element((f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768,768]{1,0}) %fusion.209), index=5
  %get-tuple-element.7 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=1
  %get-tuple-element.8 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=2
  %get-tuple-element.202 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=22
  %get-tuple-element.203 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=23
  %get-tuple-element.199 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=19
  %get-tuple-element.200 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=20
  %get-tuple-element.148 = f32[3072,768]{1,0} get-tuple-element((f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) %fusion.182), index=4
  %get-tuple-element.149 = f32[3072,768]{1,0} get-tuple-element((f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) %fusion.182), index=5
  %get-tuple-element.70 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=1
  %get-tuple-element.71 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=2
  %get-tuple-element.145 = f32[768,3072]{1,0} get-tuple-element((f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) %fusion.192), index=4
  %get-tuple-element.146 = f32[768,3072]{1,0} get-tuple-element((f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) %fusion.192), index=5
  %get-tuple-element.142 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) %fusion.197), index=4
  %get-tuple-element.143 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) %fusion.197), index=5
  %get-tuple-element.193 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=13
  %get-tuple-element.194 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=14
  %get-tuple-element.190 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=10
  %get-tuple-element.191 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=11
  %get-tuple-element.151 = f32[12,64,768]{2,1,0} get-tuple-element((f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) %fusion.164), index=4
  %get-tuple-element.152 = f32[12,64,768]{2,1,0} get-tuple-element((f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) %fusion.164), index=5
  %get-tuple-element.196 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=16
  %get-tuple-element.197 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.15), index=17
  %get-tuple-element.169 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=4
  %get-tuple-element.170 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=5
  %get-tuple-element.154 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=4
  %get-tuple-element.155 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=5
  %get-tuple-element.175 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=10
  %get-tuple-element.176 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=11
  %get-tuple-element.160 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=10
  %get-tuple-element.161 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=11
  %get-tuple-element.172 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=7
  %get-tuple-element.173 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=8
  %get-tuple-element.157 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=7
  %get-tuple-element.158 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=8
  %get-tuple-element.218 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=16
  %get-tuple-element.219 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=17
  %get-tuple-element.215 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=13
  %get-tuple-element.216 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=14
  %get-tuple-element.115 = f32[3072,768]{1,0} get-tuple-element((f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) %fusion.182), index=1
  %get-tuple-element.116 = f32[3072,768]{1,0} get-tuple-element((f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}) %fusion.182), index=2
  %get-tuple-element.221 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=19
  %get-tuple-element.222 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=20
  %get-tuple-element.121 = f32[768,3072]{1,0} get-tuple-element((f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) %fusion.192), index=1
  %get-tuple-element.122 = f32[768,3072]{1,0} get-tuple-element((f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}) %fusion.192), index=2
  %get-tuple-element.124 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) %fusion.197), index=1
  %get-tuple-element.125 = f32[3072]{0} get-tuple-element((f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}, f32[3072]{0}) %fusion.197), index=2
  %get-tuple-element.209 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=7
  %get-tuple-element.210 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=8
  %get-tuple-element.206 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=4
  %get-tuple-element.207 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=5
  %get-tuple-element.103 = f32[12,64,768]{2,1,0} get-tuple-element((f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) %fusion.164), index=1
  %get-tuple-element.104 = f32[12,64,768]{2,1,0} get-tuple-element((f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}) %fusion.164), index=2
  %get-tuple-element.212 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=10
  %get-tuple-element.213 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.111), index=11
  %get-tuple-element.163 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=13
  %get-tuple-element.164 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=14
  %get-tuple-element.178 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=13
  %get-tuple-element.179 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=14
  %get-tuple-element.97 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=1
  %get-tuple-element.98 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=2
  %get-tuple-element.100 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=1
  %get-tuple-element.101 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=2
  %get-tuple-element.181 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=16
  %get-tuple-element.182 = f32[768,12,64]{2,1,0} get-tuple-element((f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}) %fusion.154), index=17
  %get-tuple-element.166 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=16
  %get-tuple-element.167 = f32[12,64]{1,0} get-tuple-element((f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}) %fusion.159), index=17
  %get-tuple-element.136 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.217), index=1
  %get-tuple-element.137 = f32[768]{0} get-tuple-element((f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}) %fusion.217), index=2
  %get-tuple-element.28 = f32[2,768]{1,0} get-tuple-element((f32[2,768]{1,0}, f32[2,768]{1,0}, f32[2,768]{1,0}) %fusion.46), index=1
  %get-tuple-element.29 = f32[2,768]{1,0} get-tuple-element((f32[2,768]{1,0}, f32[2,768]{1,0}, f32[2,768]{1,0}) %fusion.46), index=2
  %get-tuple-element.127 = f32[512,768]{1,0} get-tuple-element((f32[512,768]{1,0}, f32[512,768]{1,0}, f32[512,768]{1,0}) %fusion.202), index=1
  %get-tuple-element.128 = f32[512,768]{1,0} get-tuple-element((f32[512,768]{1,0}, f32[512,768]{1,0}, f32[512,768]{1,0}) %fusion.202), index=2
  %get-tuple-element.16 = f32[30522,768]{1,0} get-tuple-element((f32[30522,768]{1,0}, f32[30522,768]{1,0}, f32[30522,768]{1,0}) %fusion.28), index=1
  %get-tuple-element.17 = f32[30522,768]{1,0} get-tuple-element((f32[30522,768]{1,0}, f32[30522,768]{1,0}, f32[30522,768]{1,0}) %fusion.28), index=2
  ROOT %tuple.3711 = (f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768,768]{1,0}, f32[512,768]{1,0}, f32[3072]{0}, f32[768,3072]{1,0}, f32[768]{0}, f32[3072,768]{1,0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[12,64,768]{2,1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[768]{0}, f32[768]{0}, f32[3072]{0}, f32[768,3072]{1,0}, f32[768]{0}, f32[3072,768]{1,0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[12,64,768]{2,1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[768]{0}, f32[768]{0}, f32[2,768]{1,0}, f32[2]{0}, f32[768,2]{1,0}, f32[30522]{0}, f32[30522,768]{1,0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768,768]{1,0}, f32[], f32[], f32[2]{0}, f32[2]{0}, f32[768,2]{1,0}, f32[768,2]{1,0}, f32[768]{0}, f32[768]{0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[], f32[], f32[30522]{0}, f32[30522]{0}, f32[], f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768,768]{1,0}, f32[768,768]{1,0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[768]{0}, f32[768]{0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[3072]{0}, f32[3072]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[768]{0}, f32[768]{0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[3072,768]{1,0}, f32[3072,768]{1,0}, f32[768]{0}, f32[768]{0}, f32[768,3072]{1,0}, f32[768,3072]{1,0}, f32[3072]{0}, f32[3072]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[12,64,768]{2,1,0}, f32[12,64,768]{2,1,0}, f32[768]{0}, f32[768]{0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[768,12,64]{2,1,0}, f32[768,12,64]{2,1,0}, f32[12,64]{1,0}, f32[12,64]{1,0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[768]{0}, f32[2,768]{1,0}, f32[2,768]{1,0}, f32[512,768]{1,0}, f32[512,768]{1,0}, f32[30522,768]{1,0}, f32[30522,768]{1,0}) tuple(f32[768]{0} %get-tuple-element.204, f32[768]{0} %get-tuple-element.135, f32[768]{0} %get-tuple-element.223, f32[768,768]{1,0} %get-tuple-element.129, f32[512,768]{1,0} %get-tuple-element.126, f32[3072]{0} %get-tuple-element.123, f32[768,3072]{1,0} %get-tuple-element.120, f32[768]{0} %get-tuple-element.220, f32[3072,768]{1,0} %get-tuple-element.114, f32[768]{0} %get-tuple-element.217, f32[768]{0} %get-tuple-element.214, f32[768]{0} %get-tuple-element.211, f32[12,64,768]{2,1,0} %get-tuple-element.102, f32[12,64]{1,0} %get-tuple-element.99, f32[768,12,64]{2,1,0} %get-tuple-element.96, f32[12,64]{1,0} %get-tuple-element.165, f32[768,12,64]{2,1,0} %get-tuple-element.180, f32[12,64]{1,0} %get-tuple-element.162, f32[768,12,64]{2,1,0} %get-tuple-element.177, f32[768]{0} %get-tuple-element.208, f32[768]{0} %get-tuple-element.205, f32[3072]{0} %get-tuple-element.141, f32[768,3072]{1,0} %get-tuple-element.144, f32[768]{0} %get-tuple-element.69, f32[3072,768]{1,0} %get-tuple-element.147, f32[768]{0} %get-tuple-element.201, f32[768]{0} %get-tuple-element.198, f32[768]{0} %get-tuple-element.195, f32[12,64,768]{2,1,0} %get-tuple-element.150, f32[12,64]{1,0} %get-tuple-element.159, f32[768,12,64]{2,1,0} %get-tuple-element.174, f32[12,64]{1,0} %get-tuple-element.156, f32[768,12,64]{2,1,0} %get-tuple-element.171, f32[12,64]{1,0} %get-tuple-element.153, f32[768,12,64]{2,1,0} %get-tuple-element.168, f32[768]{0} %get-tuple-element.192, f32[768]{0} %get-tuple-element.189, f32[2,768]{1,0} %get-tuple-element.27, f32[2]{0} %get-tuple-element.24, f32[768,2]{1,0} %get-tuple-element.21, f32[30522]{0} %get-tuple-element.18, f32[30522,768]{1,0} %get-tuple-element.15, f32[768]{0} %get-tuple-element.186, f32[768]{0} %get-tuple-element.183, f32[768]{0} %get-tuple-element.6, f32[768,768]{1,0} %get-tuple-element.138, f32[] %get-tuple-element.2, f32[] %fusion.8, f32[2]{0} %get-tuple-element.25, f32[2]{0} %get-tuple-element.26, f32[768,2]{1,0} %get-tuple-element.22, f32[768,2]{1,0} %get-tuple-element.23, f32[768]{0} %get-tuple-element.224, f32[768]{0} %get-tuple-element.225, f32[768,768]{1,0} %get-tuple-element.130, f32[768,768]{1,0} %get-tuple-element.131, f32[] %get-tuple-element.1, f32[] %get-tuple-element.258, f32[30522]{0} %get-tuple-element.19, f32[30522]{0} %get-tuple-element.20, f32[] %get-tuple-element, f32[768]{0} %get-tuple-element.187, f32[768]{0} %get-tuple-element.188, f32[768]{0} %get-tuple-element.184, f32[768]{0} %get-tuple-element.185, f32[768,768]{1,0} %get-tuple-element.139, f32[768,768]{1,0} %get-tuple-element.140, f32[768]{0} %get-tuple-element.7, f32[768]{0} %get-tuple-element.8, f32[768]{0} %get-tuple-element.202, f32[768]{0} %get-tuple-element.203, f32[768]{0} %get-tuple-element.199, f32[768]{0} %get-tuple-element.200, f32[3072,768]{1,0} %get-tuple-element.148, f32[3072,768]{1,0} %get-tuple-element.149, f32[768]{0} %get-tuple-element.70, f32[768]{0} %get-tuple-element.71, f32[768,3072]{1,0} %get-tuple-element.145, f32[768,3072]{1,0} %get-tuple-element.146, f32[3072]{0} %get-tuple-element.142, f32[3072]{0} %get-tuple-element.143, f32[768]{0} %get-tuple-element.193, f32[768]{0} %get-tuple-element.194, f32[768]{0} %get-tuple-element.190, f32[768]{0} %get-tuple-element.191, f32[12,64,768]{2,1,0} %get-tuple-element.151, f32[12,64,768]{2,1,0} %get-tuple-element.152, f32[768]{0} %get-tuple-element.196, f32[768]{0} %get-tuple-element.197, f32[768,12,64]{2,1,0} %get-tuple-element.169, f32[768,12,64]{2,1,0} %get-tuple-element.170, f32[12,64]{1,0} %get-tuple-element.154, f32[12,64]{1,0} %get-tuple-element.155, f32[768,12,64]{2,1,0} %get-tuple-element.175, f32[768,12,64]{2,1,0} %get-tuple-element.176, f32[12,64]{1,0} %get-tuple-element.160, f32[12,64]{1,0} %get-tuple-element.161, f32[768,12,64]{2,1,0} %get-tuple-element.172, f32[768,12,64]{2,1,0} %get-tuple-element.173, f32[12,64]{1,0} %get-tuple-element.157, f32[12,64]{1,0} %get-tuple-element.158, f32[768]{0} %get-tuple-element.218, f32[768]{0} %get-tuple-element.219, f32[768]{0} %get-tuple-element.215, f32[768]{0} %get-tuple-element.216, f32[3072,768]{1,0} %get-tuple-element.115, f32[3072,768]{1,0} %get-tuple-element.116, f32[768]{0} %get-tuple-element.221, f32[768]{0} %get-tuple-element.222, f32[768,3072]{1,0} %get-tuple-element.121, f32[768,3072]{1,0} %get-tuple-element.122, f32[3072]{0} %get-tuple-element.124, f32[3072]{0} %get-tuple-element.125, f32[768]{0} %get-tuple-element.209, f32[768]{0} %get-tuple-element.210, f32[768]{0} %get-tuple-element.206, f32[768]{0} %get-tuple-element.207, f32[12,64,768]{2,1,0} %get-tuple-element.103, f32[12,64,768]{2,1,0} %get-tuple-element.104, f32[768]{0} %get-tuple-element.212, f32[768]{0} %get-tuple-element.213, f32[12,64]{1,0} %get-tuple-element.163, f32[12,64]{1,0} %get-tuple-element.164, f32[768,12,64]{2,1,0} %get-tuple-element.178, f32[768,12,64]{2,1,0} %get-tuple-element.179, f32[768,12,64]{2,1,0} %get-tuple-element.97, f32[768,12,64]{2,1,0} %get-tuple-element.98, f32[12,64]{1,0} %get-tuple-element.100, f32[12,64]{1,0} %get-tuple-element.101, f32[768,12,64]{2,1,0} %get-tuple-element.181, f32[768,12,64]{2,1,0} %get-tuple-element.182, f32[12,64]{1,0} %get-tuple-element.166, f32[12,64]{1,0} %get-tuple-element.167, f32[768]{0} %get-tuple-element.226, f32[768]{0} %get-tuple-element.227, f32[768]{0} %get-tuple-element.136, f32[768]{0} %get-tuple-element.137, f32[2,768]{1,0} %get-tuple-element.28, f32[2,768]{1,0} %get-tuple-element.29, f32[512,768]{1,0} %get-tuple-element.127, f32[512,768]{1,0} %get-tuple-element.128, f32[30522,768]{1,0} %get-tuple-element.16, f32[30522,768]{1,0} %get-tuple-element.17), metadata={op_name="XLA_Retvals"}
}

